---
title: Trusted Postgres Architect 23.35.0 release notes
navTitle: Version 23.35.0
originalFilepath: content/product_docs/docs/tpa/23/rel_notes/src/tpa_23.35.0_rel_notes.yml
---

Released: 25 November 2024

New features, enhancements, bug fixes, and other changes in Trusted Postgres Architect 23.35.0 include the following:

## Highlights

- Options for STIG/CIS compliance.
- Support for PGD Lightweight architecture
- Postgis is now a recognized extension.
- Docker `configure` creates named networks with static IP addresses.
- Support for RedHat Enterprise Linux 9 for ARM architectures.
- Support for PostgreSQL, EDB Postgres Extended, and EDB Postgres Advanced Server 17.

## Enhancements

<table class="table w-100"><thead><tr><th>Description</th><th width="10%">Addresses</th></tr></thead><tbody>
<tr><td><details><summary>Support STIG/CIS compliance</summary><hr/><p>TPA now supports command-line options to create a cluster configured to conform to many of the requirements of the STIG and CIS security standards. These options cause TPA to set postgresql.conf settings as defined in the relevant standards, to install required extensions, to configure other aspects of system behaviour such as filesystem permissions and user connection limits, and to check for other requirements such as FIPS crypto standards which TPA can't directly impose. The clusters thus generated are not certified by TPA to conform to the standards, but much of the groundwork of creating a conforming cluster is now automated.</p></details></td><td></td></tr>
<tr><td><details><summary>Add support for PGD Lightweight architecture</summary><hr/><p>TPA is now able to generate a PGD Lightweight architecture comprised of three nodes in two locations (2 nodes in Primary and one in Disaster Recovery) designed to ease migrations from physical replication. Users can now run <code>tpaexec configure lw -a Lightweight --postgresql 15</code>.</p></details></td><td></td></tr>
<tr><td><details><summary>Have <code>configure</code> create a user-defined network on Docker</summary><hr/><p>The configure command will now automatically add a named network and static IP addresses to config.yml when Docker is the selected platform. The network name is the same as the cluster name and the address range follows the existing semantics of the --network option with the exception that only one subnet is used for the whole cluster rather than one per location. If a subnet prefix is not specified by the user, TPA will attempt to select a prefix which results in a subnet large enough to fit the whole cluster. The key <code>ip_address</code> may now be used to specify a static IP for a Docker instance as long as a named network is specified in the config.yml.</p></details></td><td></td></tr>
<tr><td><details><summary>Added experimental support for using an existing Barman node as backup node in new cluster</summary><hr/><p>When using an existing Barman node as a backup node in a new cluster, users can set <code>barman_shared: true</code> in the Barman instance's vars with the platform set to <code>bare</code> and other information supplied as usual for bare instances. This change allows TPA to skip some configuration steps that would otherwise fail due to usermod issues, as the Barman user already has running processes from previous deployments. The shared Barman instance is treated as a bare instance, so the required access, including the Barman user's access to the target PostgreSQL instances, must be already in place. Copying the Barman user's keys from the original cluster to the new cluster can be used to achieve this, see the Barman section of the TPA documentation for detailed information.</p></details></td><td></td></tr>
<tr><td><details><summary>Add <code>postgis</code> to list of recognized extensions</summary><hr/><p>The PostGIS package will automatically be added when a user specifies <code>postgis</code> as an entry in either <code>postgres_extensions</code> or the list of extensions named under <code>postgres_databases</code>. Also enables the CRB (Code Ready Builder) repository for RHEL-compatible distributions so PostGIS dependencies can be installed.</p></details></td><td></td></tr>
<tr><td><details><summary>Enable EFM probes when a PEM agent is registered on an EFM node</summary><hr/><p>The <code>--efm-install-path</code> and <code>--efm-cluster-name</code> flags are set when a PEM server is registered on an EFM node. The <code>Streaming Replication</code>, <code>Failover Manager Node Status</code> and <code>Failover Manager Cluster Info</code> probes are enabled when a PEM agent is registered on an EFM node.</p></details></td><td></td></tr>
<tr><td><details><summary>Support RedHat Enterprise Linux 9 for ARM architectures</summary><hr/><p>Packages are now published targeting RHEL 9 ARM64, and TPA supports deployments using this architecture and OS. Also updated the list of supported AWS images to include the RedHat 9 ARM64 AMI provided by Amazon. The default <code>instance_type</code> for ARM64 EC2 instances has been updated from <code>a1</code> to <code>t4g</code>, which is the current generation processor available for burstable general purpose workloads.</p></details></td><td></td></tr>
<tr><td><details><summary>Support PostgreSQL, EDB Postgres Extended, and EDB Postgres Advanced Server 17</summary><hr/><p>Clusters can be configured to use PostgreSQL, EDB Postgres Extended and EDB Postgres Advanced Server version 17. Barman no longer needs to install the postgres server package to get the <code>pg_receivewal</code> binary when using EDB Postgres Advanced Server 17 or EDB Postgres Extended 17 since the binary has been added to the client package for these versions. TPA raises an architecture error when a cluster is configured with <code>repmgr</code> as the failover_manager as it is not available for Postgres 17. Updated documentation to reflect supported versions.</p></details></td><td></td></tr>
<tr><td><details><summary>Make <code>password_encryption</code> algorithm for <code>efm</code> Postgres user configurable.</summary><hr/><p>Expose a configurable <code>efm_user_password_encryption</code> variable which should be set to either <code>'md5'</code> or <code>'scram-sha-256'</code> depending on user requirements. This controls the <code>auth-method</code> for the <code>efm</code> Postgres user in <code>pg_hba.conf</code> and the algorithm used for generating it's encrypted password. In clusters deployed with <code>compliance</code> configured to <code>stig</code>, the 'efm' Postgres user's <code>auth-method</code> in <code>pg_hba.conf</code> will be set to <code>scram-sha-256</code> since FIPS-enabled operating systems do not allow <code>md5</code> to be used.</p></details></td><td></td></tr>
<tr><td><details><summary>Allow multiple addresses to be supplied with hostnames</summary><hr/><p>When using the <code>--hostnames-from</code> option to <code>tpaexec configure</code>, you can now include two ip addresses on each line, which will be included in the generated config.yml as public_ip and private_ip.</p></details></td><td></td></tr>
</tbody></table>


## Changes

<table class="table w-100"><thead><tr><th>Description</th><th width="10%">Addresses</th></tr></thead><tbody>
<tr><td><details><summary>Remove deprecated <code>PermissionStartOnly</code> in postgres.service.j2 template</summary><hr/><p><code>PermissionsStartOnly</code> has been deprecated and is now achieved via <code>ExecStartPost=+/bin/bash...</code> syntax</p></details></td><td></td></tr>
<tr><td><details><summary>The <code>barman</code> Postgres user is no longer a superuser</summary><hr/><p>Certain required privileges are granted to Postgres role, <code>barman_role</code>, which is then granted to the <code>barman</code> Postgres user. This avoids creating the <code>barman</code> user as a superuser. This role can also be granted to other Postgres users by adding it to their <code>granted_roles</code> list using <code>postgres/createuser</code>. The <code>barman_role</code> is created as part of the Barman tasks; if Barman is not used, this role will not be created. Therefore, the task that grants privileges to this role is only executed if the <code>barman_role</code> username is in the list of Postgres users that are created. The 'barman' user now has <code>NOSUPERUSER</code> explicitly specified as a role attribute. If a cluster was deployed with a previous TPA version (which created the 'barman' user as a superuser), deploying with this version will remove the <code>superuser</code> role attribute from the <code>barman</code> user.</p></details></td><td></td></tr>
<tr><td><details><summary>Add new option <code>harp_local_etcd_only</code> when using etcd with HARP</summary><hr/><p>Add new optional var <code>harp_local_etcd_only</code> available when using etcd with HARP. This option tells HARP manager to connect to local etcd node. This recommendation follows the best practices learnt by doing the same when <code>bdr</code> as consensus procotol is being used. The default mode of adding multiple endpoints can lead to performance issues in some cases. This option is added to give more control to the user.</p></details></td><td></td></tr>
<tr><td><details><summary>Improve postgres-monitor script</summary><hr/><p>Improve postgres-monitor script to better manage recoverable errors and add retries on network errors to ensure that it won't return failure when it just didn't allow enough time for postgres service to be fully started.</p></details></td><td></td></tr>
<tr><td><details><summary>Only add nodes with <code>efm</code> role to cluster <code>efm.nodes</code> file</summary><hr/><p>Previously the <code>pemserver</code> and <code>barman</code> nodes were added to the <code>Allowed node host list</code> in EFM when they were not relevant to EFM functions. Refactored the task that writes the <code>efm.node</code> configuration to only include those nodes that have <code>efm</code> in their list of roles.</p></details></td><td></td></tr>
</tbody></table>


## Bug Fixes

<table class="table w-100"><thead><tr><th>Description</th><th width="10%">Addresses</th></tr></thead><tbody>
<tr><td><details><summary>Fix tpaexec test for pgd-proxy config verification</summary><hr/><p>Fixed a bug whereby the test that ensures the current pgd-proxy configuration matches the expected configuration would fail for version &lt; 5.5.0. This fix ensures that TPA won't try to query configuration keys added in version 5.5.0.</p></details></td><td></td></tr>
<tr><td><details><summary>Fix case where <code>primary_slot_name</code> added for EFM compatibility interferes with <code>bdr_init_physical</code></summary><hr/><p>A <code>primary_slot_name</code> is configured on the primary node to ensure the old primary uses a physical slot for replication during an EFM switchover. However, 'bdr_init_physical' attempts to use it for node initialisation and hangs indefinitely since the slot does not exist in a PGD installation. This <code>primary_slot_name</code> is now conditionally set explicitly when the <code>failover_manager</code> is EFM to avoid setting it unnecessarily.</p></details></td><td></td></tr>
<tr><td><details><summary>Download correct <code>bash-completion</code> package version</summary><hr/><p>If the <code>pgdcli_package_version</code> is specified in <code>config.yml</code>, the <code>bash-completion</code> package is incorrectly named because the <code>packages_for</code> filter erroneously appends the <code>pgdcli_package_version</code> to the package name. This results in an attempt to download a nonexistant package. The <code>bash-completion</code> package is now appended to the list after the <code>packages_for</code> filter, since it's version is independent from the <code>pgdcli_package_version</code>.</p></details></td><td></td></tr>
<tr><td><details><summary>Fix an issue whereby in some cases error messages would be repeated even after successful tasks.</summary><hr/><p>TPA now clears the error message stack after each task to ensure messages are not spuriously repeated</p></details></td><td></td></tr>
<tr><td><details><summary>Fix issue that prevented the addition of replicas to Patroni clusters</summary><hr/><p>Fixed an issue whereby new replicas in Patroni clusters would fail with errors related to replication slots.</p></details></td><td></td></tr>
<tr><td><details><summary>Add <code>pem-agent</code> role on barman nodes at most once for M1 architecture</summary><hr/><p>If <code>--enable-pem</code> and <code>--enable-pg-backup-api</code> are passed to <code>tpaexec configure</code>, <code>pem-agent</code> is added twice to the <code>barman</code> node if it is also a <code>witness</code>. Fixed by consolidating both <code>if</code> statements together to only evaluate the conditions once.</p></details></td><td></td></tr>
<tr><td><details><summary>Set <code>pem_python_executable</code> outside of the <code>pkg</code> role</summary><hr/><p>Fixed a bug whereby if the user excluded the <code>pkg</code> selector, later PEM-related tasks would fail because the <code>pem_python_executable</code> fact had not been set.</p></details></td><td></td></tr>
</tbody></table>


