---
navTitle: Release notes
title: Release notes
---

## Release 2.1.0 (2022-5-17)

This is a minor release of HARP 2 that includes new features as well
as fixes for issues identified in previous versions.

### Enhancements

-   **Leader per location**

    Support for selecting a leader per location rather than relying on DCS
    like etcd to have separate setup in different locations.

    This still requires a majority of nodes to survive loss of a location,
    so an odd number of both locations and database nodes is recommended.

-   **Leader selection optimization for BDR DCS**

    The BDR DCS now uses a push notification from the consensus rather than
    through polling nodes. This change reduces the time for new leader selection and
    the load that HARP does on the BDR DCS since it doesn't need to poll in
    short intervals anymore.

-   **Rolling updates**

    TPA now restarts each HARP Proxy one by one and wait until they come back
    to reduce any downtime incurred by the application during software
    upgrades.

-   **Embedded PGBouncer deprecation**

    The support for embedding PGBouncer directly into HARP Proxy is now
    deprecated and will be removed in the next major release of HARP.

    It's now possible to configure TPA to put PGBouncer on the same node as
    HARP Proxy and point to that HARP Proxy.



## Release 2.0.3 (2022-3-31)

### Enhancements

-   **HARP Proxy supports read-only user dedicated TLS Certificate**
    You can specify a TLS certificate and key in the HARP Proxy DSN for the DCS read-only user. (78516, HNG-522)

### Bug fixes

-   HARP Proxy continues to try and connect to DCS instead of exiting after 50 seconds. (75406, HNG-548, HNG-560, HNG-561)

## Release 2.0.2 (2022-2-24)

This is a patch release of HARP 2 that includes fixes for issues identified
in previous versions.

### Enhancements

-   **Connection throttling for builtin proxy**

    You can now specify the maximum number of connections that can be used by `builtin` proxy. The proxy adjusts downward the number of connections to fit within your calculated system resource limits.  (75406, 79250, HNG-489, HNG-498, HNG-503, HNG-508)

-   **CAMO disabled for BDR DCS**

    HARP disables CAMO for its connection to the database to avoid performance degradation when using BDR for the Distributed Consensus System (DCS). (HNG-438)

-   **Improved security for HARP Proxy**

    You can specify a user with read-only DCS permissions for the `builtin` proxy. (75406, HNG-452)

-   **Start, stop, status hooks for managing Postgres**

    You can provide start, stop, and status commands in the HARP Manager configuration for starting postgres, stopping postgres, and retrieving the status of postgres. If you don't provide commands, then systemd is used by default. (HNG-492)

-   **PgBouncer has been removed as a dependency for HARP Proxy rpm and deb packages.**

    PgBouncer isn't installed unless you select `pgbouncer` for `harp_proxy_mode`. (HNG-511)

-   **HARP Manager has improved performance communicating with BDR DCS**

    HARP Manager communicates with BDR DCS only using a local Unix domain socket. (78516,HNG-494)

-   **Builtin proxy is now the default proxy**

    If pgbouncer was being used by default in a previous release, the `harp_proxy_mode` must now be specified as `pgbouncer` to continue as the proxy on upgrade. (HNG-511)

-   **Binaries now match service names**

    The `harp_manager` binary is now named `harp-manager`. The ` harp_proxy` binary is now named `harp-proxy`. Symlinks with the previous names are provided. (HNG-514)

-   **Improved Harp Manager defaults**

    Lag configuration defaults are now set to off by default. Duration of leader lease now has a default setting of 6 seconds. Leader lease renewal setting now defaults to 2 seconds.  (HNG-520)

### Bug fixes

-   HARP Manager now stops the database on exit. (HNG-497)
-   HARP Proxy no longer leaks connections when using the `builtin` proxy. (75406,HNG-445)
-   HARP Proxy no longer erroneously reports “splice: connection reset by peer” when connections are closed for `builtin` proxy. (75406, HNG-445,)
-   Harpctl now returns when querying for `builtin` or `pgbouncer` proxy status. (HNG-499)
-   `harpctl get cluster` output no longer contains leader and previous leader fields. (HNG-483)
-   Harpctl now validates proxy name when executing proxy related commands. (HNG-471)
-   Harpctl now reports correct routing status for leader. (HNG-441)
-   HARP configuration files now contain the correct configuration parameters for the corresponding proxy: `builtin` or `pgbouncer`. (78516, HNG-456)
-   TPAExec no longer creates a confusing DSN for DCS endpoint with a duplicate user. (78516, HNG-495)
-   `request_timeout` configuration parameter doesn't need unit specified. Units are in milliseconds. (78363, HNG-504)
-   The `listen_port` and `listen_host` settings can now be configured per proxy instance using TPAExec. (78848, HNG-456)
-   Subscriber only nodes, which can't become leader nodes, are no longer considered for leadership. (78516, HNG-411)

### Known issues

-   When a previously isolated shadow node returns back as an active cluster node, this triggers a raft election and leadership change.
-   Promoting a node can cause a different node to be promoted. A race for leadership occurs between the eligible nodes. The first eligible node becomes leader. Use the `--force` option with the `promote` command to have the desired node become leader.
-   Harpctl can't return the HARP Proxy version if HARP Proxy is configured with read-only user access for BDR DCS. The version information can't be stored by a user with read-only permissions. This leads to missing version information for proxy when using harpctl to query version information.
-   After fencing the database with the stop database option, if the HARP Manager restarts and BDR DCS is configured, the database is restarted but in a fenced state.
-   `use_unix_sock` doesn't work when deploying EDB Postgres Advanced Server. The default Unix socket directory isn't determined correctly for EDB Postgres Advanced Server.

## Release 2.0.1 (2022-1-31)

This is a patch release of HARP 2 that includes fixes for issues identified
in previous versions.

### Enhancements

-   BDR consensus now generally available

    HARP offers multiple options for Distributed Consensus Service (DCS) source: etcd and BDR. The BDR consensus option can be used in deployments where etcd isn't present. Use of the BDR consensus option is no longer considered beta and is now supported for use in production environments.

-   Transport layer proxy now generally available

    HARP offers multiple proxy options for routing connections between the client application and database: application layer (L7) and transport layer (L4). The network layer 4 or transport layer proxy simply forwards network packets, and layer 7 terminates network traffic. The transport layer proxy, previously called simple proxy, is no longer considered beta and is now supported for use in production environments.

## Release 2.0.0 (2021-12-01)

This is new major release of HARP that constitutes of complete rewrite of the
product.

### Engine

-   Complete rewrite of system in golang to optimize all operations
-   Cluster state can now be bootstrapped or revised via YAML

### Configuration

-   Rewritten in YAML
-   Configuration file changed from `harp.ini` to `config.yml`

### Enhancements

-   HARP Proxy deprecates need for HAProxy in supported architecture.

    The use of HARP Router to translate DCS contents into appropriate online or
    offline states for HTTP-based URI requests meant a load balancer or HAProxy
    was necessary to determine the lead master. HARP Proxy now does this
    automatically without periodic iterative status checks.

-   Utilizes DCS key subscription to respond directly to state changes.

    With relevant cluster state changes, the cluster responds immediately, resulting in improved failover and switchover times.

-   Compatibility with etcd SSL settings.

    It is now possible to communicate with etcd through SSL encryption.

-   Zero transaction lag on switchover.

    Transactions are not routed to the new lead node until all replicated transactions are replayed, thereby reducing the potential for conflicts.

-   Experimental BDR Consensus layer

    Using BDR Consensus as the Distributed Consensus Service (DCS) reduces the amount of change needed for implementations.

-   Experimental proxy

    Proxy implementation for increased session control.
