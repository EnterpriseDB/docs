---
title: "Using EDB Failover Manager for high availability "
navTitle: "Example: C1 architecture with EFM"
redirects:
- /pem/latest/pem_ha_setup/
- /pem/latest/pem_ha_setup/setup_ha_using_efm/
- /pem/latest/considerations/setup_ha_using_efm/
---

This page provides detailed instructions to install and configure a High Availability (HA) PEM deployment according to reference architecture C1.
This example uses EDB Failover Manager (EFM) for cluster management, EDB Postgres Advanced Server (EPAS) as the PEM backend database and Virtual IP (VIP) as the mechanism for routing traffic to the primary.
Please refer to [High Availability Patterns for PEM Deployment] for discussion of other options.

!!! Note
    This procedure is for setting up Failover Manager for a PEM server with a new installation, not with an existing one. 
    The provided commands apply to the configuration of RHEL-like systems with EPAS 17 and EFM 5.0.
    
The examples that follow use these IP addresses:

-   172.16.161.200 - PEM Primary
-   172.16.161.201 - PEM Standby 1
-   172.16.161.202 - PEM Standby 2
-   172.16.161.203 - EFM Witness Node  ??? why a witness when we already have three ???
-   172.16.161.245 - PEM VIP (used by agents and users to connect)

The following must use the VIP address:

-   The PEM agent binding of the monitored database servers
-   Accessing the PEM web client
-   Accessing the webserver services

## Initial package installation and Postgres configuration

1.  Install the following packages on the primary and all standbys.

    -   [EDB Postgres Advanced Server](/epas/latest/installing/) (backend database for PEM Server)
    -   [sslutils] (see PEM server documentation)
    -   [PEM Server](/pem/latest/installing/)
    -   [EDB Failover Manager](/efm/latest/installing/)

    ```shell
    sudo dnf -qy module disable postgresql
    sudo dnf -y install epel-release
    sudo dnf config-manager --set-enabled crb
    sudo dnf -y install edb-as17-server edb-pem edb-as17-server-sslutils, edb-efm50
    ```

1.  Initialize a Postgres database and start the service.

    ```shell
    sudo PGSETUP_INITDB_OPTIONS="-E UTF-8" /usr/edb/as17/bin/edb-as-17-setup initdb
    sudo systemctl start edb-as-17
    sudo systemctl enable edb-as-17
    ```

1.  Create a superuser that can login using a password.
    ```shell
    sudo su - enterprisedb -c psql edb -c 'create role pemserver login superuser password your-password-here;'
    ```

1.  Add the following line to the the `pg_hba.conf` file to permit the new user to connect from any of the server IPs.
    ```
    host  all  pemserver  172.16.161.1/24  scram-sha-256  ??? should this one also be ssl ???
    ```

1.  Add the following line to the the `pg_hba.conf` file to permit other PEM users to connect to the PEM backend through the web application.
    ```
    hostssl all    +pem_user   172.16.161.201/24  scram-sha-256
    ```

1.  Restart the Postgres server.
    ```shell
    sudo systemctl restart edb-as-17
    ```

1.  Open the following ports on the firewall of all servers:

    -   `8443` for PEM Server (HTTPS)
    -   `5444` for EPAS 
    -   `7800` for EFM
    -   `7908` for EFM Admin

    For example:

    ```shell
    sudo firewall-cmd --zone=public --add-port=5444/tcp --permanent 
    sudo firewall-cmd --zone=public --add-port=8443/tcp --permanent
    sudo firewall-cmd --zone=public --add-port=7800/tcp --permanent
    sudo firewall-cmd --zone=public --add-port=7809/tcp --permanent
    sudo firewall-cmd --reload      
    ```

1.  **On the standbys only**, install NGINX and EDB uWSGI.
    This is not required on the primary because it occurs automatically during the next step.

    ```shell
    dnf install nginx
    dnf install edb-uwsgi
    ```

## Configure PEM on the primary

Configure the PEM installation *on the primary server only*:

1. Manually assign the VIP to the primary. For example:

    ```shell
    sudo /usr/edb/efm-5.0/bin/efm_address add4 eth0 172.16.161.245/32
    ```
2. Run the PEM configuration script, specifying the VIP as the host and option 1 (Database and Web Services):

    ```shell
    /usr/edb/pem/bin/configure-pem-server.sh -t 1 -ho 172.16.161.245
    ```
    You will be prompted for various additional details. 
    For configuration options see, [Configuring the PEM server on Linux](/pem/latest/installing/configuring_the_pem_server_on_linux/).

3. Optionally, to synchronize PEM web application user preferences between instances, [configure central storage of user preferences](user_settings.md).

## Copy files from the primary to the standbys

During the previous step, various configuration files were created on the primary.
We now copy those files to the standbys.

Copy the following files from the primary node to the standby nodes at the same location, overwriting any existing files. Set the permissions on the files: ??? do this earlier ???

-   ??? NGINX and uWSGI ???
-   `/usr/edb/pem/share/.install-config`
-   `/usr/edb/pem/web/config_setup.py`

For example: ??? this isn't really an example???

```shell

mkdir -p        /var/lib/pemhome/.pem  ??? do we need this ???
chown pem:pem   /var/lib/pemhome/.pem
chmod 0700      /var/lib/pemhome/.pem
mkdir -p        /usr/edb/pem/logs
chown root:root /usr/edb/pem/logs
chmod 0755      /usr/edb/pem/logs
for file in /etc/httpd/conf.d/edb-pem.conf     \
                /etc/httpd/conf.d/edb-ssl-pem.conf \
                /root/.pem/agent1.crt \
                /usr/edb/pem/agent/etc/agent.cfg \
                /usr/edb/pem/share/.install-config \
                /usr/edb/pem/web/pem.wsgi \
                /usr/edb/pem/web/config_setup.py; do \
        chown root:root ${file}; \
        chmod 0644      ${file}; \
    done;
```

## Set up the primary node for streaming replication

1.  Create the replication role:

    ```shell
    psql -h 172.16.161.200 -p 5444 -U enterprisedb edb -c “CREATE ROLE repl REPLICATION LOGIN PASSWORD 'password'”;
    ```

    Give the password of your choice.

2.  Configure the following in the `postgresql.conf` file:

    ```ini
    wal_level = replica
    max_wal_senders = 10
    wal_keep_size = 500
    max_replication_slots = 10
    ```

    For more information on configuring parameters for streaming replication, see the [PostgreSQL documentation](https://www.postgresql.org/docs/17/warm-standby.html#STREAMING-REPLICATION).


3.  Add the following entry in the host-based authentication (`/var/lib/edb/as17/data/pg_hba.conf`) file to allow the replication user to connect from all the standbys:

    ```shell
    hostssl  replication  repl  172.16.161.201/24  scram-sha-256
    ```

5.  Restart the EPAS server.

    ```shell
    systemctl restart edb-as-17.service
    ```

## Set up the standby nodes for streaming replication

Uses the pg_basebackup utility to create the replicas of the PEM backend database server on the standby servers. 

1.  Stop the service for EPAS on all the standby nodes:

    ```shell
    systemctl stop edb-as-17.service
    ```

2.  Remove the data directory of the database server on all the standby nodes:

    ```shell
    sudo su - enterprisedb
        
    rm -rf /var/lib/edb/as17/data/*
    ```

3.  Create the `.pgpass` file in the home directory of the enterprisedb user on all the standby nodes: ??? explain that CHANGE_ME is the password from earlier ???

    ```shell
    sudo su - enterprisedb
        
    cat > ~/.pgpass << _EOF_
    172.16.161.200:5444:replication:repl:CHANGE_ME
    172.16.161.201:5444:replication:repl:CHANGE_ME
    172.16.161.202:5444:replication:repl:CHANGE_ME
    _EOF_
        
    chmod 600 ~/.pgpass
    ```

4.  Take the backup of the primary node on each of the standby nodes using pg_basebackup:

    ```shell
    sudo su - enterprisedb /usr/edb/as17/bin/pg_basebackup -h 172.16.161.200 \
    -D /var/lib/edb/as17/data -U repl -v -P -Fp -R -p 5444
    ```

    The `backup` command creates the `postgresql.auto.conf` and `standby.signal` files on the standby nodes. The `postgresql.auto.conf` file has the following content:

    ```shell
    # Do not edit this file manually
    # It will be overwritten by the ALTER SYSTEM command.
    primary_conninfo = ‘user=repl passfile=’’/var/lib/edb/.pgpass’’ channel_binding=prefer host=172.16.161.200 port=5444 sslmode=prefer sslcompression=0 ssl_min_protocol_version=TLSv1.2 gssencmode=prefer krbsvrname=postgres target_session_attrs=any’
    ```

5.  In the `postgresql.conf` file on each of the standby nodes, edit the following parameter:

    ```ini
    hot_standby = on
    ```

6.  Start the EPAS database server on each of the standby nodes:

    ```shell
    systemctl start edb-as-17
    ```

8.  Run the `configure-selinux.sh` script to configure the SELinux policy for PEM: ??? on all servers ???

```shell
    $ /usr/edb/pem/bin/configure-selinux.sh
    getenforce found, now executing 'getenforce' command
    Configure the httpd to work with the SELinux
    Allow the httpd to connect the database (httpd_can_network_connect_db = on)
    Allow the httpd to connect the network (httpd_can_network_connect = on)
    Allow the httpd to work with cgi (httpd_enable_cgi = on)
    Allow to read & write permission on the 'pem' user home directory
    SELinux policy is configured for PEM

    $ sudo chmod 640 /root/.pem/agent1.crt  ??? won't be agent1 ???
```

## Register agents and servers on the standbys

On each replica, perform the following steps.

1.  Register the PEM agent. Specifying the VIP and the PEM server host and being sure to include the `--pem-server` option which marks this agent as a PEM server agent.

1.  Register the Postgres instance with PEM.


## Set up EFM to manage failover on all hosts

1.  Prepare the primary node to support EFM:

    -   Create a database user efm to connect to the database servers.
    -   Grant the execute privileges on the functions related to WAL logs and the monitoring privileges to the user.
    -   Add entries in `pg_hba.conf` to allow the efm database user to connect to the database server from all nodes on all the hosts.
    -   Reload the configurations on all the database servers.
    
    For example:

    ```sql
        $ cat > /tmp/efm-role.sql << _EOF_
        -- Create a role for EFM
        CREATE ROLE efm LOGIN PASSWORD 'password';

        -- Give privilege to 'efm' user to connect to a database
        GRANT CONNECT ON DATABASE edb TO efm;

        -- Give privilege to 'efm' user to do backup operations
        GRANT EXECUTE ON FUNCTION pg_current_wal_lsn() TO efm;
        GRANT EXECUTE ON FUNCTION pg_last_wal_replay_lsn() TO efm;
        GRANT EXECUTE ON FUNCTION pg_wal_replay_resume() TO efm;
        GRANT EXECUTE ON FUNCTION pg_wal_replay_pause() TO efm;
        GRANT EXECUTE ON FUNCTION pg_reload_conf() TO efm;

        -- Grant monitoring privilege to the 'efm' user
        GRANT pg_monitor TO efm;
        _EOF_

        $ /usr/edb/as17/bin/psql -h 172.16.161.200 -p 5444 -U enterprisedb edb -f /tmp/efm-role.sql
        CREATE ROLE
        GRANT
        GRANT
        GRANT
        GRANT
        GRANT
        GRANT
        GRANT ROLE
        
        $ rm -f /tmp/efm-role.sql
        
        $ cat > /var/lib/edb/as17/data/pg_hba.conf <<< _EOF_
        hostssl      edb     efm     172.16.161.200/32     scram-sha-256
        hostssl      edb     efm     172.16.161.201/32     scram-sha-256
        hostssl      edb     efm     172.16.161.202/32     scram-sha-256
        hostssl      edb     efm     172.16.161.203/32     scram-sha-256
        _EOF_
        
        $ /usr/edb/as17/bin/psql -h 172.16.161.200 -p 5444 -U enterprisedb edb -c “SELECT pg_reload_conf();”
    ```

4.  Create an `efm.nodes` file on all nodes using the sample file (`/etc/edb/efm-5.0/efm.nodes.in`), and give read-write access to the efm OS user:

    ```shell
        $ sudo cp /etc/edb/efm-5.0/efm.nodes.in /etc/edb/efm-5.0/efm.nodes
        $ sudo chown efm:efm /etc/edb/efm-5.0/efm.nodes
        $ sudo chmod 600 /etc/edb/efm-5.0/efm.nodes
    ```

5.  Add the IP address and efm port of the primary node in the `/etc/edb/efm-5.0/efm.nodes` file on the standby nodes:

    ```shell
        $ sudo cat > /etc/edb/efm-5.0/efm.nodes <<< _EOF_
        172.16.161.200:7800
        _EOF_
    ```

6.  Create the `efm.properties` file on all the nodes using the sample file (`/etc/edb/efm-5.0/efm.properties.in`). Grant read access to all the users:

    ```shell
        $ sudo cp /etc/edb/efm-5.0/efm.properties.in /etc/edb/efm-5.0/efm.properties
        $ sudo chown efm:efm /etc/edb/efm-5.0/efm.properties
        $ sudo chmod a+r /etc/edb/efm-5.0/efm.properties
    ```

7.  Encrypt the efm user's password using the efm utility:

    ```shell
        $ export EFMPASS=password
        $ /usr/edb/efm-5.0/bin/efm encrypt efm --from-env
        096666746b05b081d1a98e43d94c9dad
    ```

8.  Edit the following parameters in the properties file:

    ```ini
        db.user=efm
        db.password.encrypted=096666746b05b081d1a98e43d94c9dad
        db.port=5444
        db.database=edb
        db.service.owner=enterprisedb
        db.service.name=edb-as-17
        db.bin=/usr/edb/as17/bin
        db.data.dir=/var/lib/edb/as17/data
        jdbc.sslmode=require
        user.email=username@example.com
        from.email=node1@efm-pem
        notification.level=INFO
        notification.text.prefix=[PEM/EFM] 
        bind.address=172.16.161.200:7800
        admin.port=7809
        is.witness=false
        local.period=10
        local.timeout=60
        local.timeout.final=10
        remote.timeout=10
        node.timeout=50
        encrypt.agent.messages=true
        stop.isolated.primary=true
        stop.failed.primary=true
        primary.shutdown.as.failure=false
        update.physical.slots.period=0
        ping.server.ip=8.8.8.8
        ping.server.command=/bin/ping -q -c3 -w5
        auto.allow.hosts=false
        stable.nodes.file=false
        db.reuse.connection.count=0
        auto.failover=true
        auto.reconfigure=true
        promotable=true
        use.replay.tiebreaker=true
        standby.restart.delay=0
        reconfigure.num.sync=false
        reconfigure.sync.primary=false
        minimum.standbys=0
        recovery.check.period=1
        restart.connection.timeout=60
        auto.resume.period=0
        virtual.ip=172.16.161.245
        virtual.ip.interface=ens33
        virtual.ip.prefix=24
        virtual.ip.single=true
        check.vip.before.promotion=true
        pgpool.enable=false
        sudo.command=sudo
        sudo.user.command=sudo -u %u   ??? not sure we need this anymore ???
        syslog.host=localhost
        syslog.port=514
        syslog.protocol=UDP
        syslog.facility=LOCAL1
        file.log.enabled=true
        syslog.enabled=false
        jgroups.loglevel=INFO
        efm.loglevel=INFO
        jvm.options=-Xmx128m
    ```

9.  Set the value of the `is.witness` configuration parameter on the witness node to `true`:

    ```ini
        is.witness=true
    ```

10. Enable and start the EFM service on the primary node:

    ```shell
        $ systemctl enable edb-efm-5.0
        $ systemctl start edb-efm-5.0
    ```

11. Allow the standbys to join the cluster started on the primary node:

    ```shell
        /usr/edb/efm-5.0/bin/efm allow-node  efm  172.16.161.201
        /usr/edb/efm-5.0/bin/efm allow-node  efm  172.16.161.202
        /usr/edb/efm-5.0/bin/efm allow-node  efm  172.16.161.203
    ```

12. Enable and start the EFM service on the standby nodes and the EFM witness node:

    ```shell
        $ systemctl enable edb-efm-5.0
        $ systemctl start edb-efm-5.0
    ```

13. Check the EFM cluster status from any node:

    ```shell
        $ sudo /usr/edb/efm-5.0/bin/efm cluster-status efm
        Cluster Status: efm
            Agent Type  Address              DB       VIP
            ----------------------------------------------------------------
            Primary     172.16.161.200      UP       172.16.161.245*
            Standby     172.16.161.201      UP       172.16.161.245
            Standby     172.16.161.202      UP       172.16.161.245
            Witness     172.16.161.203      N/A      172.16.161.245

        Allowed node host list:
            172.16.161.200 172.16.161.201 172.16.161.202 172.16.161.203

        Membership coordinator: 172.16.161.200

        Standby priority host list:
            172.16.161.201 172.16.161.202

        Promote Status:

            DB Type     Address              WAL Received LSN   WAL Replayed LSN   Info
            ---------------------------------------------------------------------------
            Primary     172.16.161.200                         0/F7A3808          
            Standby     172.16.161.201      0/F7A3808          0/F7A3808          
            Standby     172.16.161.202      0/F7A3808          0/F7A3808          

            Standby database(s) in sync with primary. It is safe to promote.
    ```

This status confirms that EFM is set up successfully and managing the failover for the PEM server.

In case of failover, any of the standbys are promoted as the primary node, and PEM agents connect to the new primary node. You can replace the failed primary node with a new standby using this procedure.

## Current limitations

The current limitations include:
-   Web console sessions for the users are lost during the switchover.
-   Background processes, started by the Backup, Restore, and Maintenance dialogs boxes, and their logs aren't shared between the systems. They are lost during switchover. 
