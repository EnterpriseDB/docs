---
title: Monitoring your analytical tables
navTitle: Monitoring your analytical tables
description: How to audit storage utilization and performance characteristics for PGAA-managed tables.
---

Postgres Analytics Accelerator (PGAA) provides built-in functions to help you understand the storage footprint, table formats, and metadata health of your data lake tables directly from the Postgres prompt.

## Listing analytical tables 

In environments with hundreds of standard Postgres tables, identifying which ones are managed by PGAA can be challenging. The `pgaa.list_analytics_tables()` function provides a global overview of all lakehouse-integrated tables.

```sql
SELECT * FROM pgaa.list_analytics_tables();
```

The function output provides the following insights:
- **Identity & format:** Displays the schema, table name, and storage format (e.g., Iceberg, Delta, or Parquet).
- **Storage location:** The exact path to where the data files reside.
- **Catalog metadata:** If using an external catalog, this function output shows the external catalog service name, namespace, and remote table name.
- **Replication status:** Displays the current state of data movement (primarily for PGD replication scenarios).
- **Storage metrics:**
    - `object_storage_snapshot_size_bytes`: The size of the latest live snapshot. This represents the actual volume of data scanned during a `SELECT *`.
    - ``object_storage_total_size_bytes``: The total footprint in the bucket, including metadata, manifests, and historical data files not used by the current version.

!!! Tip 
    If `object_storage_total_size_bytes` is significantly larger than the snapshot size, your table may have accumulated excessive historical versions. This is a primary indicator that you should perform a `VACUUM` or Compaction operation. See [Optimizing performance](optimize_performance) for more.

    
## Analyzing table statistics 

While `list_analytics_tables()` gives a high-level summary, `pgaa.lakehouse_table_stats()` provides a deep dive into a specific table's physical characteristics. This is essential for capacity planning and fine-tuning query performance.

```sql
SELECT * FROM pgaa.lakehouse_table_stats('my_schema.my_table'::regclass);
```


This function queries the underlying object storage to verify what is happening "under the hood" of a specific mapping. It helps you:
- **Distinguish live vs. dead data:** Identify exactly how much storage is being "wasted" by old transaction logs or uncompacted small files.
- **Monitor growth:** Track how snapshot sizes evolve over time as new data is ingested from external sources.
- **Cache awareness:** The results of this function are governed by the [pgaa.lakehouse_table_stats_cache_ttl_s](reference/configuration_parameters#pgaa.lakehouse_table_stats_cache_ttl_s) configuration parameter. If you need the absolute latest stats and aren't seeing them, ensure your cache TTL is set to 0.


Comparing `latest_snapshot_size` and `total_size` is essential for balancing performance and cost. The snapshot size represents "live" data—the actual volume scanned during a query—while the total size includes the entire bucket footprint, such as historical versions, transaction logs, and uncompacted rows.

In formats like Iceberg or Delta Lake, the total size often exceeds the snapshot size to support time-travel and rollbacks. A significant gap between these values indicates a buildup of historical overhead and serves as a signal to perform a `VACUUM` or compaction. Monitoring these metrics from the Postgres CLI helps you maintain a lean, high-performing data lake. See [Optimizing performance](optimize_performance) for more.

