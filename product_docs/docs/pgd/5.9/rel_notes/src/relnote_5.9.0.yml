# yaml-language-server: $schema=https://raw.githubusercontent.com/EnterpriseDB/docs/refs/heads/develop/tools/automation/generators/relgen/relnote-schema.json
product: EDB Postgres Distributed
version: 5.9.0
date: 19 August 2025
components:
  "BDR": 5.9.0
  "PGD CLI": 5.9.0
  "PGD Proxy": 5.9.0
  "Utilities": 5.9.0
intro: |
 This is a minor release of PGD 5, which includes several enhancements and bug fixes. This version is also a prerequisite for seamless upgrades to PGD 6.1.0, and it has been updated to include key infrastructure, such as a back-ported Connection Manager, to ensure a smooth transition to the latest major version.

highlights: |
 - This is the first PGD 5 version to support a direct, in-place upgrade to PGD 6, beginning with PGD 6.1.0
 - New Detach Partition function for PGD AutoPartition
 - Support EDB Postgres Advanced Server (EPAS) Interval Partitioning

relnotes:
- relnote: New drop_after_retention_period argument added to the bdr.autopartition function
  component: BDR
  details: |
    bdr.autopartition() now takes an additional boolean argument drop_after_retention_period which can be set to false if the user does not want the partition to be dropped, but only detached.
  jira: BDR-2409
  type: Feature
  impact: Medium

- relnote: Improve Raft snapshot export/import to reset Raft completely
  component: BDR
  details: |
    We've made improvements to how our Raft consensus mechanism handles snapshots. This ensures that in the rare event of a data consistency issue, restoring a snapshot will now fully reset the system's state, allowing operations to resume smoothly from a consistent starting point.
  jira:
  type: Enhancement
  impact: Medium

- relnote: EPAS Interval Partition Support for PGD
  component: BDR
  details: |
    A new enhancement allows partitions created by EDB Postgres Advanced Server (EPAS) AutoPartition to work correctly within a multi-node PGD environment. This fix ensures partitions are created consistently on each node and are visible across all nodes.
  jira:
  type: Enhancement
  impact: Medium

- relnote: Connection Manager Back-Port for PGD 5.9
  component: BDR
  details: |
    To streamline the upgrade process, the Connection Manager has been back-ported to PGD 5.9 as an optional feature that's disabled by default. This change allows for seamless upgrades to PGD 6 by having the necessary infrastructure in place. It also gives you the opportunity to test the Connection Manager in non-production environments before a full production upgrade.
  jira:
  type: Enhancement
  impact: Medium

- relnote: Enable proxy routing by default for subgroups
  component: BDR
  details: |
    Subgroups have proxy routing enabled by default from 5.9.0 however it doesn't impact the existing behavior of subgroups and how to connect to the nodes without proxy.
  jira:
  type: Enhancement
  impact: Medium

- relnote: Fix for PGD node upgrade fails with 'function max(pg_lsn) does not exist'
  component: BDR
  details: |
    We've resolved a bug that could cause a PGD node upgrade to fail with the error 'function max(pg_lsn) does not exist'.
  jira: BDR-6697
  type: Bug Fix
  impact: Medium

- relnote: Fix for Subscription Key Errors During Node Sync
  component: BDR
  details: |
    A fix has been implemented to resolve an issue that caused duplicate key value violates unique constraint "subscription_pkey" errors during node resynchronization. To ensure unique names and prevent manager crashes, subscription names now include the source node name, which provides a more robust and reliable resynchronization process.
  jira:
  type: Bug Fix
  impact: Medium

- relnote: PGD CLI cluster verify Command Fix for Witness-Only Groups
  component: PGD CLI
  details: |
    The pgd cluster verify command no longer displays a warning for witness-only groups that do not contain data nodes. This resolves an issue where the command incorrectly flagged these groups, ensuring that the verification output is now accurate for all cluster types.
  jira:
  type: Bug Fix
  impact: Medium

- relnote: Raft Fix for Parting Lagging Nodes
  component: BDR
  details: |
    Raft no longer fails to recover after a heavily-lagging node that was previously a leader is parted from the cluster. This fixes a bug where the Raft leader could crash with a "BDR node XXX not found" error, which previously required a manual, forceful reset of the Raft state. Now, Raft correctly handles this scenario and recovers automatically, ensuring cluster stability.
  jira: 
  addresses: 50099
  type: Bug Fix
  impact: Medium

- relnote: Fix for "Clock Has Moved Backwards" Error with Snowflake Sequences
  component: BDR
  details: |
    A race condition has been fixed that could cause a "clock has moved backwards" error when using Snowflake sequences, even when the system clock was functioning correctly. This fix ensures the sequence correctly handles concurrent access, preventing this error and improving the reliability of Snowflake sequence generation.
  jira: 49376, 43659
  type: Bug Fix
  impact: Medium

- relnote: Fix for `bdr_init_physical` Hangs with Synchronous Commit
  component: BDR
  details: |
    A bug has been fixed that could cause `bdr_init_physical` to hang when the upstream node had a synchronous commit scope. This issue, which prevented a new node from completing physical initialization, was caused by a specific interaction with synchronous commit settings. The fix ensures that `bdr_init_physical` now works reliably in all configurations, even before the new node joins the group and is considered for synchronous commits.
  jira: 
  addresses: 50599
  type: Bug Fix
  impact: Medium

- relnote: Fix a crash with pg_failover_slots
  component: BDR
  details: |
    Ensure that CDC hooks are no-op when recovery is in progress or the backend is not connected to a database. This can definitely happen if `pg_failover_slots` is active.
  jira:
  type: Bug Fix
  impact: Medium

- relnote: Synchronize roles and tablespaces during logical join
  component: BDR
  details: |
    Roles and tablespaces are now synchronized before the schema is restored from the join source node. 
    If there are already existing roles or tablespaces (or EPAS profiles), they will be updated to have 
    the same settings, passwords etc. as the ones from the join source node. 
    System roles (i.e. the ones created by initdb) are not synchronized.
  jira:
  type: Enhancement
  impact: Medium
- relnote: Replication of roles to witness nodes
  component: BDR
  details: |
    Roles are now replicated to witness nodes at node join. Roles also get replicated to witness nodes during normal operation of the cluster.
  jira:
  type: Enhancement
  impact: Medium
