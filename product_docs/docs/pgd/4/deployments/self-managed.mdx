---
title: "TPAexec"
---

TAKEN FROM: https://documentation.enterprisedb.com/tpa/release/22.13-1/

TPAexec is an orchestration tool that uses Ansible to build Postgres clusters as specified by TPA (Trusted Postgres Architecture), a set of reference architectures that document how to set up and operate Postgres in various scenarios. TPA represents the best practices followed by EDB (and formerly, 2ndQuadrant), and its recommendations are as applicable to quick testbed setups as to production environments.

What can TPAexec do?
TPAexec operates in four distinct stages to bring up a Postgres cluster:

# 1. Configuration: decide what kind of cluster you want
[tpa]$ tpaexec configure clustername --architecture M1 --platform aws

# 2. Provisioning: create the servers needed to host the cluster
[tpa]$ tpaexec provision clustername

# 3. Deployment: install and configure the necessary software
[tpa]$ tpaexec deploy clustername

# 4. Testing: make sure everything is working as expected
[tpa]$ tpaexec test clustername
You can run TPAexec from your laptop, an EC2 instance, or any machine that can reach the cluster's servers over the network.

Here's a list of capabilities and supported software.

Configuration
The tpaexec configure command generates a simple YAML configuration file to describe a cluster, based on the options you select. The configuration is ready for immediate use, and you can modify it to better suit your needs. Editing the configuration file is the usual way to make any configuration changes to your cluster, both before and after it's created.

At this stage, you must select an architecture and a platform for the cluster. An architecture is a recommended layout of servers and software to set up Postgres for a specific purpose. Examples include "M1" (Postgres with a primary and streaming replicas) and "BDR-Always-ON" (Postgres with BDR in an HA configuration). A platform is a means to host the servers to deploy any architecture, e.g., AWS, Docker, or bare-metal servers.

Provisioning
The tpaexec provision command creates instances and other resources required by the cluster. The details of the process depend on the architecture (e.g., M1) and platform (e.g., AWS) that you selected while configuring the cluster.

For example, given AWS access with the necessary privileges, TPAexec will provision EC2 instances, VPCs, subnets, routing tables, internet gateways, security groups, EBS volumes, elastic IPs, etc.

You can also "provision" existing servers by selecting the "bare" platform and providing connection details. Whether these are bare metal servers or those provisioned separately on a cloud platform, they can be used just as if they had been created by TPAexec.

You are not restricted to a single platform—you can spread your cluster out across some AWS instances (in multiple regions) and some on-premise servers, or servers in other data centres, as needed.

At the end of the provisioning stage, you will have the required number of instances with the basic operating system installed, which TPAexec can access via SSH (with sudo to root).

Deployment
The tpaexec deploy command installs and configures Postgres and other software on the provisioned servers (which may or may not have been created by TPAexec; but it doesn't matter who created them so long as SSH and sudo access is available). This includes setting up replication, backups, and so on.

At the end of the deployment stage, Postgres will be up and running.

Testing
The tpaexec test command executes various architecture and platform-specific tests against the deployed cluster to ensure that it is working as expected.

At the end of the testing stage, you will have a fully-functioning cluster.

Incremental changes
TPAexec is carefully designed so that provisioning, deployment, and testing are idempotent. You can run through them, make a change to config.yml, and run through the process again to deploy the change. If nothing has changed in the configuration or on the instances, then rerunning the entire process will not change anything either.

Extensible through Ansible
TPAexec supports a variety of configuration options, so you can do a lot just by editing config.yml and re-running provision/deploy/test. Should you need to go beyond what is already implemented, you can write hook scripts to extend the deployment process.

This mechanism places the full range of Ansible functionality at your disposal during every stage of the deployment. For example, any tasks in hooks/pre-deploy.yml will be executed before the main deployment; and there are also post-deploy and many other hooks.

Cluster management
Once your cluster is up and running, TPAexec provides convenient cluster management functions, including configuration changes, switchover, and zero-downtime minor-version upgrades. These features make it easier and safer to manage your cluster than making the changes by hand.

It's just Postgres
TPAexec can create complex clusters with many features configured, but the result is just Postgres. The installation follows some conventions designed to make life simpler, but there is no hidden magic or anything standing in the way between you and the database. You can do everything on a TPA cluster that you could do on any other Postgres installation.

Getting started
Follow the TPAexec installation instructions for your system, then configure your first cluster.

----------------------------------
EXISTING CONTENT 


The standard way of deploying EDB Distributed Postgres in self managed setting,
including physical and virtual machines, both self-hosted and in the cloud
(i.e. EC2) is to use EDB's deployment tool called TPAexec.

TPAexec is an orchestration tool which can be used to build Postgres clusters
according to a Trusted Postgres Architecture (TPA) specification.

TPA represents the best practices followed by EnterpriseDB and its
recommendations are as applicable to quick testbed setups as to production
environments.

## Quick Setup with TPAexec

The following steps will setup EDB Distributed Postgres with the Always-ON Silver
architecture using Amazon EC2.

First, we generate configuration file using the `configure` command:
```
$ tpaexec configure myedbdpcluster --architecture BDR-Always-ONO --layout Silver --platform aws
```

This will create a subdirectory directory in current working directory called
`myedbdpcluster`. In that directory there will be `config.yml` with configuration
TPAexec needs to crate the cluster. You can edit the `config.yml` as needed,
for example changing the ip address range used for servers, or adjusting locations
of nodes.

Next, we provision the cluster, in the case of the current example, this will
create the EC2 instances, configure VPC, etc:
```
tpaexec provision myedbdpcluster
```

Finally, we can deploy the needed packages, configuration and setup the actual
EDB Distributed Postgres cluster:
```
tpaexec deploy myedbdpcluster
```

After the successful run of the `deploy` command the cluster will be ready to use,
use can connect to it via `psql`, or any other database client.

It's also possible to run a test that ensures the cluster is running as expected:
```
tpaexec test myedbdpcluster
```

----------------
TAKEN FROM: https://documentation.enterprisedb.com/tpa/release/22.13-1/architecture-BDR-Always-ON/

BDR-Always-ON
BDR in an Always-ON configuration, intended for use in production.

In BDR-Always-ON architecture we have four variants, which can be selected with the --layout configure option:

bronze: 2×bdr+primary, bdr+witness, barman, 2×harp-proxy

silver: bronze, with bdr+witness promoted to bdr+primary, and barman moved to separate location

gold: two symmetric locations with 2×bdr+primary, 2×harp-proxy, and barman each; plus a bdr+witness in a third location

platinum: gold, but with one bdr+readonly (logical standby) added to each of the main locations

You can check EDB's Postgres-BDR Always On Architectures whitepaper for the detailed layout diagrams.

Cluster configuration
[tpa]$ tpaexec configure ~/clusters/bdr \
         --architecture BDR-Always-ON \
         --layout gold \
         --platform aws --region eu-west-1 --instance-type t3.micro \
         --distribution Debian-minimal
You must specify --architecture BDR-Always-ON. (In the example above, it is the only option required to produce a working configuration.)

You also must specify --layout layoutname to set one of the supported BDR use-case variations. The current options are bronze, silver, gold, and platinum. The bronze, gold and platinum layouts have a BDR witness node to ensure odd number of nodes for Raft consensus majority. Witness nodes do not participate in the data replication.

You may optionally specify --bdr-node-group groupname to set the name of the BDR node group (default: bdrgroup).

You may optionally specify --bdr-database dbname to set the name of the database with BDR enabled (default: bdrdb).

You may optionally specify --enable-camo to set the pair of BDR primary instances in each region to be each other's CAMO partners.

Please note we enable HARP2 by default in BDR-Always-ON architecture.

You may also specify any of the options described by tpaexec help configure-options.
