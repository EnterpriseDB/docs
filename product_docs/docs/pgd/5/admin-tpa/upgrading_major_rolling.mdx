---
title: Performing a Postgres major version rolling upgrade 
---

## Performing a Postgres major version rolling upgrade

This document outlines the procedure for performing a major version upgrade of a Postgres cluster using Postgres Distributed (PGD) as installed by Trusted Postgres Architect (TPA). The rolling upgrade process allows updating individual cluster nodes to a new major Postgres version while maintaining cluster availability and operational continuity. This approach minimizes downtime and ensures data integrity by allowing the rest of the cluster to remain operational as each node is upgraded sequentially. Upgrading your Postgres cluster to a newer major version is recommended to access improved features, performance enhancements, and security updates. This guide provides step-by-step instructions to facilitate a smooth and controlled upgrade process.

!!! Note
Ensure that your databases and configuration files are backed up before starting the upgrade process to help prevent data loss.
!!!

To perform the rolling upgrade of the Postgres major version on your PGD cluster, carry out the following steps on each node in the cluster:

- Confirm the current Postgres version.
- Check to see if the target node is the write leader of the cluster.
- If it is the write leader, perform a planned switchover to make another node write leader so you can upgrade the target node and ensure cluster availability.
- After confirming the target node is not the write leader, stop Postgres.
- Install the new Postgres version and bdr_pg_upgrade.
- Initialize the new Postgres version.
- Copy the configuration for the old Postgres version to the configuration for the new Postgres version.
- Rename the PGDATA directories.
- Stop all Postgres instances.
- Check that you can upgrade safely.
- Run the Postgres major version upgrade.
- Modify the Postgres service.
- Start Postgres.
- Validate the new Postgres version. 
- Test the upgrade directly against the newly upgraded node.
- Cleanup post-upgrade. 

We will look at these steps in more detail below, specifically for upgrading a node from Postgres 15 to Postgres 16. 

## Worked example

A three-node cluster (kaftan, kaolin, and kaboom) we [deployed on AWS using TPA](https://www.enterprisedb.com/docs/pgd/latest/quickstart/quick_start_aws/) is currently running Postgres 15 on a Linux OS (Debian in this case). We want to upgrade a single node to Postgres 16 using `bdr_pg_upgrade`, and then upgrade the rest of the cluster similarly. This walkthrough focuses on the detailed steps for the target node, kaboom. 

!!! Note
Some steps of this process will involve you running commands as the Postgres owner. We will refer to this user as `postgres` throughout when appropriate. If you are running EDB Postgres Advanced Server, you will need to substitute that user with `enterprisedb` in all relevant commands.
!!!

### Confirm the current Postgres version

Connect to any node that is still running Postgres 15 and use the following command to connect to PGD's `bdrdb` database:

```bash
sudo -u postgres psql bdrdb
```
Then, when connected to bdrdb, use the following query:

```sql
SELECT * FROM bdr.group_versions_details;
```

You should see output similar to this for your cluster:

```
  node_id   | node_name |        postgres_version        | bdr_version 
------------+-----------+--------------------------------+-------------
 3490219809 | kaftan    | 15.5 (Debian 15.5-1EDB.buster) | 5.3.0
 2710197610 | kaboom    | 15.5 (Debian 15.5-1EDB.buster) | 5.3.0
 2111777360 | kaolin    | 15.5 (Debian 15.5-1EDB.buster) | 5.3.0
(3 rows)
```

Confirm that the Postgres version is the expected version. Then, use the `exit` command to return to the node's command prompt.

### Plan upgrade order

The cluster must be available throughout the process (i.e., a *rolling* upgrade). To achieve continuous cluster availability, we must perform a [planned switchover](#performing-a-planned-switchover) of the write leader node before upgrading that node. We also want to keep the number of planned [switchovers](https://www.enterprisedb.com/docs/pgd/latest/cli/command_ref/pgd_switchover/) to a minimum for availability and efficiency. Accordingly, we will upgrade the current write leader last in our upgrade order, so we only have to perform one planned switchover.

To check to see which node is the current write leader, run the `pgd show-groups` command:

```bash
sudo -u postgres pgd show-groups
```

In our example, kaftan, is the current write leader:

```
Group        Group ID   Type   Parent Group Location Raft Routing Write Leader 
-----        --------   ----   ------------ -------- ---- ------- ------------ 
democluster  1935823863 global                       true false                
dc1_subgroup 1302278103 data   democluster  dc1      true true    kaftan   
```

The `pgd-show-groups` command shows all groups in the EDB Postgres Distributed cluster and their summary, including the current write leader.

Our upgrade plan can be to upgrade kaboom, upgrade kaolin, perform a planned switchover from kaftan to kaboom, and finally upgrade kaftan.

#### Performing a planned switchover

Since our target node in this walkthrough is kaboom, we won't need to perform a planned switchover yet. 

When you are ready to upgrade kaftan, switchover the write leader from kaftan to kaboom with the following command:

```bash
sudo -u postgres pgd switchover --group-name dc1_subgroup --node-name kaboom
```

Then, run `pgd show-groups` to ensure the switchover was successful.

```bash
sudo -u postgres pgd show-groups
```

You will see that kaboom is now the write leader:

```
Group        Group ID   Type   Parent Group Location Raft Routing Write Leader 
-----        --------   ----   ------------ -------- ---- ------- ------------ 
democluster  1935823863 global                       true false                
dc1_subgroup 1302278103 data   democluster  dc1      true true    kaboom  
```

It is then safe to stop Postgres on kaftan.

### Stop Postgres on the target node

If you are not already on the target node, use SSH to connect to the target node, in this case, kaboom, and then run:

```bash
sudo systemctl stop postgres
```

This command halts the server on the current node, kaboom. Your cluster will continue running using the other two nodes.

### Install the new Postgres version

Now, while still on the target node, kaboom, install the new version of Postgres (PG16) and the upgrade tool by running:

```bash
sudo apt install edb-bdr5-pg16 edb-bdr-utilities
```

### Initialize Postgres 16

Make a new data directory for the upgraded Postgres and give the user, `postgres`, ownership of the directory:

```bash
sudo mkdir /opt/postgres/datanew
sudo chown -R postgres:postgres /opt/postgres/datanew
```

Then initialize Postgres 16 in the new directory:

```bash
sudo -u postgres /usr/lib/postgresql/16/bin/initdb \
  -D /opt/postgres/datanew \
  -E UTF8 \
  --lc-collate=en_US.UTF-8 \
  --lc-ctype=en_US.UTF-8 \
  --data-checksums
```

This command creates a PG16 data directory for configuration, `/opt/postgres/datanew`.

### Copy configuration for Postgres 15 to Postgres 16

The next step copies the existing configuration (PG15) to the new PG16 data directory.

Copy over the `postgresql.conf`, `postgresql.auto.conf`, `pg_hba.conf` files, and the whole conf.d directory:

```bash
sudo -u postgres cp /opt/postgres/data/postgresql.conf /opt/postgres/datanew/
sudo -u postgres cp /opt/postgres/data/postgresql.auto.conf /opt/postgres/datanew/
sudo -u postgres cp /opt/postgres/data/pg_hba.conf /opt/postgres/datanew/
sudo -u postgres cp -r /opt/postgres/data/conf.d/ /opt/postgres/datanew/
```

### Rename the PGDATA directories

Next, swap the PG15 and PG16 data directories around by running: 

```bash
sudo mv /opt/postgres/data /opt/postgres/dataold
sudo mv /opt/postgres/datanew /opt/postgres/data
```

!!! Important
If something goes wrong at some point during the procedure, you may want to rollback/revert a node to the older major version. To do this, rename directories again so that the current data directory, `/opt/postgres/data`, becomes `/opt/postgres/datafailed` and the old data directory, `/opt/postgres/dataold`, becomes the current data directory:

```bash
sudo mv /opt/postgres/data /opt/postgres/datafailed
sudo mv /opt/postgres/dataold /opt/postgres/data
```

This should rollback/revert the node back to the previous major version of Postgres.
!!!

### Stop all Postgres instances

Although we stopped the Postgres service on the target node, kaboom, earlier, to be sure, run the stop command for both instances of Postgres (PG15 and PG16) on
the target node, kaboom:

```bash
sudo -u postgres /usr/lib/postgresql/15/bin/pg_ctl -D /opt/postgres/dataold stop
sudo -u postgres /usr/lib/postgresql/16/bin/pg_ctl -D /opt/postgres/data stop
```

!!! Note
When running the first or second command to stop the Postgres instances, you may receive the following error:

```bash
pg_ctl: PID file "/opt/postgres/data/postmaster.pid" does not exist
Is server running?
```
This error is expected when both instances of Postgres are already shut down and, therefore, does not prevent the upgrade from progressing.
!!!

### Check that you can upgrade safely

The `bdr_pg_upgrade` tool has a `--check` option, which dry runs some of the upgrade process. We can use this option to ensure the upgrade will go smoothly. 

However, first, we need a directory for the files created by `bdr_pg_upgrade`, which we can give ownership of to the user `postgres`. 

Accordingly, create an `/upgrade` directory in the `/home` directory and then give ownership of that directory to the user `postgres`:

```bash
sudo mkdir /home/upgrade
sudo chown postgres:postgres /home/upgrade
```
Next, navigate to `/home/upgrade` and then run:

```bash
sudo -u postgres /usr/bin/bdr_pg_upgrade \
  --old-bindir /usr/lib/postgresql/15/bin/ \
  --new-bindir /usr/lib/postgresql/16/bin/ \
  --old-datadir /opt/postgres/dataold/ \
  --new-datadir /opt/postgres/data/ \
  --database bdrdb \
  --check
```

If all goes well, you should see this output:

```
Performing BDR Postgres Checks
------------------------------
Collecting pre-upgrade new cluster control data             ok
Checking new cluster state is shutdown                      ok
Checking BDR versions                                       ok

Passed all bdr_pg_upgrade checks, now calling pg_upgrade

Performing Consistency Checks
-----------------------------
Checking cluster versions                                   ok
Checking database user is the install user                  ok
Checking database connection settings                       ok
Checking for prepared transactions                          ok
Checking for system-defined composite types in user tables  ok
Checking for reg* data types in user tables                 ok
Checking for contrib/isn with bigint-passing mismatch       ok
Checking for presence of required libraries                 ok
Checking database user is the install user                  ok
Checking for prepared transactions                          ok
Checking for new cluster tablespace directories             ok

*Clusters are compatible
```

!!! Note
If you didn't initialize Postgres 16 with checksums using the `--data-checksums` option, you will receive an error letting you know about the incompatibility:

```bash
old cluster uses data checksums but the new one does not
```
!!!

### Run the Postgres major version upgrade

We are now ready to run the upgrade. On the target node, run:

```bash
sudo -u postgres /usr/bin/bdr_pg_upgrade \
  --old-bindir /usr/lib/postgresql/15/bin/ \
  --new-bindir /usr/lib/postgresql/16/bin/ \
  --old-datadir /opt/postgres/dataold/ \
  --new-datadir /opt/postgres/data/ \
  --database bdrdb
```

You should see the following output:

```
Performing BDR Postgres Checks
------------------------------
Collecting pre-upgrade new cluster control data             ok
Checking new cluster state is shutdown                      ok
Checking BDR versions                                       ok
Starting old cluster (if shutdown)                          ok
Connecting to old cluster                                   ok
Checking if bdr schema exists                               ok
Turning DDL replication off                                 ok
Terminating connections to database                         ok
Disabling connections to database                           ok
Waiting for all slots to be flushed                         ok
Disconnecting from old cluster                              ok
Stopping old cluster                                        ok
Starting old cluster with BDR disabled                      ok
Connecting to old cluster                                   ok
Collecting replication origins                              ok
Collecting replication slots                                ok
Disconnecting from old cluster                              ok
Stopping old cluster                                        ok

Passed all bdr_pg_upgrade checks, now calling pg_upgrade

Performing Consistency Checks
-----------------------------
Checking cluster versions                                   ok
Checking database user is the install user                  ok
Checking database connection settings                       ok
Checking for prepared transactions                          ok
Checking for system-defined composite types in user tables  ok
Checking for reg* data types in user tables                 ok
Checking for contrib/isn with bigint-passing mismatch       ok
Creating dump of global objects                             ok
Creating dump of database schemas                           ok
Checking for presence of required libraries                 ok
Checking database user is the install user                  ok
Checking for prepared transactions                          ok
Checking for new cluster tablespace directories             ok

If pg_upgrade fails after this point, you must re-initdb the
new cluster before continuing.

Performing Upgrade
------------------
Analyzing all rows in the new cluster                       ok
Freezing all rows in the new cluster                        ok
Deleting files from new pg_xact                             ok
Copying old pg_xact to new server                           ok
Setting oldest XID for new cluster                          ok
Setting next transaction ID and epoch for new cluster       ok
Deleting files from new pg_multixact/offsets                ok
Copying old pg_multixact/offsets to new server              ok
Deleting files from new pg_multixact/members                ok
Copying old pg_multixact/members to new server              ok
Setting next multixact ID and offset for new cluster        ok
Resetting WAL archives                                      ok
Setting frozenxid and minmxid counters in new cluster       ok
Restoring global objects in the new cluster                 ok
Restoring database schemas in the new cluster               ok
Copying user relation files                                 ok
Setting next OID for new cluster                            ok
Sync data directory to disk                                 ok
Creating script to delete old cluster                       ok
Checking for extension updates                              notice

Your installation contains extensions that should be updated
with the ALTER EXTENSION command.  The file
    update_extensions.sql
when executed by psql by the database superuser will update
these extensions.


Upgrade Complete
----------------
Optimizer statistics are not transferred by pg_upgrade.
Once you start the new server, consider running:
    /usr/pgsql-15/bin/vacuumdb --all --analyze-in-stages

Running this script will delete the old cluster's data files:
    ./delete_old_cluster.sh

pg_upgrade complete, performing BDR post-upgrade steps
------------------------------------------------------
Collecting old cluster control data                         ok
Collecting new cluster control data                         ok
Checking LSN of new cluster                                 ok
Starting new cluster with BDR disabled                      ok
Connecting to new cluster                                   ok
Creating replication origin (bdr_bdrdb_rb69_bdr2)           ok
Advancing replication origin (bdr_bdrdb_rb69_bdr2, 0/1F4... ok
Creating replication origin (bdr_bdrdb_rb69_bdr1)           ok
Advancing replication origin (bdr_bdrdb_rb69_bdr1, 0/1E8... ok
Creating replication slot (bdr_bdrdb_rb69_bdr1)             ok
Creating replication slot (bdr_bdrdb_rb69)                  ok
Creating replication slot (bdr_bdrdb_rb69_bdr2)             ok
Stopping new cluster
```

### Modify the Postgres service

The Postgres service on the system is configured to start the old version 
of Postgres (PG15). We need to modify the `postgres.service` file to start the new 
version (PG16). This can be done using `sed` to replace the old version 
number "15" with "16" throughout the file. Once changed, we can tell the 
systemd daemon to reload the configuration. On the target node, run:

```bash
sudo sed -i -e  's/15/16/g' /etc/systemd/system/postgres.service
sudo systemctl daemon-reload
```

### Start Postgres

Finally, start the modified Postgres service by running:

```bash
sudo systemctl start postgres
```

### Validate the Postgres version

Repeating our first step, check the version of Postgres to confirm that we upgraded kaboom correctly. While still on kaboom, run:

```bash
sudo -u postgres psql bdrdb
```

```sql
SELECT * FROM bdr.group_versions_details;
```

You should see an output similar to this for your cluster.

```
  node_id   | node_name |        postgres_version        | bdr_version 
------------+-----------+--------------------------------+-------------
 3490219809 | kaftan    | 15.5 (Debian 15.5-1EDB.buster) | 5.3.0
 2710197610 | kaboom    | 16.1 (Debian 16.1-1EDB.buster) | 5.3.0
 2111777360 | kaolin    | 15.5 (Debian 15.5-1EDB.buster) | 5.3.0
(3 rows)
```

Confirm that kaboom is running the upgraded Postgres version. 

### Test the upgrade

Now that the upgrade is complete on kaboom, you should test your database(s) thoroughly to ensure the upgrade has been successful. Being still connected to kaboom ensures that your tests run specifically against the new version without interference from cluster routing mechanisms.

```bash
sudo -u postgres psql <database_name>
```

Next, execute your test suite, including application transactions, queries, and other operations critical to your environment. Pay particular attention to performance metrics and compatibility with the new version. The insights gained from this controlled upgrade can inform your approach, helping to ensure a smoother transition for all nodes.

### Clean up post-upgrade

We want to run a vacuum over to the database at this point as best practice. When the upgrade ran, you may have noticed the post-upgrade report included:

```
Once you start the new server, consider running:
    /usr/lib/postgresql/16/bin/vacuumdb --all --analyze-in-stages
```

Let's do this now. On the target node, run:

```bash
sudo -u postgres /usr/lib/postgresql/16/bin/vacuumdb --all --analyze-in-stages
```

Lastly, if you are sure you do not need to revert this node, you can clean up the old data directly folder as well, `dataold`:

```bash
sudo rm -r /opt/postgres/dataold
```

### Next steps

To complete upgrading the cluster for this worked example, repeat the previous steps starting with [stopping postgres](#stop-postgres-on-the-target-node) on kaolin, [perform a planned switchover](#performing-a-planned-switchover) from kaftan to a kaboom that has been [thoroughly tested](#test-the-upgrade), and repeat the upgrade steps one last time on kaftan. Throughout the rest of the procedure, be sure to apply any lessons learned or adjustments identified during the [node testing phase](#test-the-upgrade).
After completing the upgrade on all nodes, while connected to one of the nodes, you can once again check your versions in the PGD database using:

```bash
sudo -u postgres psql bdrdb
```

Then run the SQL query:

```sql
SELECT * FROM bdr.group_versions_details;
```
You should see output similar to the following:

```
  node_id   | node_name |        postgres_version        | bdr_version 
------------+-----------+--------------------------------+-------------
 3490219809 | kaftan    | 16.1 (Debian 16.1-1EDB.buster) | 5.3.0
 2710197610 | kaboom    | 16.1 (Debian 16.1-1EDB.buster) | 5.3.0
 2111777360 | kaolin    | 16.1 (Debian 16.1-1EDB.buster) | 5.3.0
(3 rows)
```

This shows that all the nodes have been successfully upgraded to the new Postgres version.

#### Reconcile with TPA

We used TPA to build our cluster in this worked example. So after all the nodes have been upgraded, we still need to [reconcile](https://www.enterprisedb.com/docs/tpa/latest/reference/reconciling-local-changes/) the upgraded version of Postgres with TPA to use TPA to manage the cluster in the future.

To do this, return to the server's command line where your TPA cluster directory resides. In this worked example, our TPA cluster directory is `/home/ubuntu/democluster` on the instance where we originally deployed the cluster using TPA.

After navigating to your cluster directory, use a code editor to edit `config.yml` and change `cluster vars:` from `postgres_version: '15'` to `postgres_version: '16'`.

Unless already added to your .bashrc or .bash_profile, ensure the TPA tools are accessible in your command line session by adding TPA's binary directory to your PATH.

```bash
export PATH=$PATH:/opt/EDB/TPA/bin
```
Finally, redeploy the cluster:

```bash
tpaexec deploy democluster
```

This final step should apply the configuration changes to the cluster managed by TPA. If the deployment is successful, the reconciliation of the new version of Postgres with TPA and the upgrade procedure as a whole is complete.


