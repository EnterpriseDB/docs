---
title: "Supported Failover and Failure Scenarios"
---

<div id="supported_scenarios" class="registered_link"></div>


Failover Manager monitors a cluster for failures that may or may not result in failover.

Failover Manager supports a very specific and limited set of failover scenarios. Failover can occur:

-   if the Master database crashes or is shutdown.
-   if the node hosting the Master database crashes or becomes unreachable.

Failover Manager makes every attempt to verify the accuracy of these conditions. If agents cannot confirm that the Master database or node has failed, Failover Manager will not perform any failover actions on the cluster.

Failover Manager also supports a *no* *auto*-*failover* mode for situations where you want Failover Manager to monitor and detect failover conditions, but not perform an automatic failover to a Standby. In this mode, a notification is sent to the administrator when failover conditions are met. To disable automatic failover, modify the cluster properties file, setting the [auto.failover](04_configuring_efm/01_cluster_properties/#auto_failover) parameter to false.

Failover Manager will alert an administrator to situations that require administrator intervention, but that do not merit promoting a Standby database to Master.

<div id="master_db_down" class="registered_link"></div>



## Master Database is Down

If the agent running on the Master database node detects a failure of the Master database, Failover Manager begins the process of confirming the failure.

![*Confirming the Failure of the Master Database.*](images/supported_scenarios_master_db_down.png)

If the agent on the Master node detects that the Master database has failed, all agents attempt to connect directly to the Master database. If an agent can connect to the database, Failover Manager sends a notification about the state of the Master node. If no agent can connect, the Master agent declares database failure and releases the VIP (if applicable).

If no agent can reach the virtual IP address or the database server, Failover Manager starts the failover process. The Standby agent on the most up-to-date node runs a fencing script (if applicable), promotes the Standby database to Master database, and assigns the virtual IP address to the Standby node. Any additional Standby nodes are configured to replicate from the new master unless auto.reconfigure is set to false. If applicable, the agent runs a post-promotion script.

**Returning the Node to the Cluster**

To recover from this scenario without restarting the entire cluster, you should:

1.  Restart the database on the original Master node as a Standby database.
2.  Invoke the efm resume command on the original Master node.

**Returning the Node to the Role of Master**

After returning the node to the cluster as a Standby, you can easily return the node to the role of Master:

1.  If the cluster has more than one Standby node, use the efm allow-node command to set the node's failover priority to 1.
2.  Invoke the [efm promote -switchover command](#efm_promote) to promote the node to its original role of Master node.

<div id="standby_down" class="registered_link"></div>



## Standby Database is Down

If a Standby agent detects a failure of its database, the agent notifies the other agents; the other agents confirm the state of the database.

![*Confirming the failure of a Standby Database.*](images/supported_scenarios_standby_db_down.png)

After returning the Standby database to a healthy state, invoke the efm resume command to return the Standby to the cluster.

<div id="master_agent_exits" class="registered_link"></div>



## Master Agent Exits or Node Fails

If the Failover Manager Master agent crashes or the node fails, a Standby agent will detect the failure and (if appropriate) initiate a failover.

![*Confirming the failure of the Master Agent.*](images/supported_scenarios_master_agent_exits.png)

If an agent detects that the Master agent has left, all agents attempt to connect directly to the Master database. If any agent can connect to the database, an agent sends a notification about the failure of the Master agent. If no agent can connect, the agents attempt to ping the virtual IP address to determine if it has been released.

If no agent can reach the virtual IP address or the database server, Failover Manager starts the failover process. The Standby agent on the most up-to-date node runs a fencing script (if applicable), promotes the Standby database to Master database, and assigns the virtual IP address to the Standby node; if applicable, the agent runs a post-promotion script. Any additional Standby nodes are configured to replicate from the new master unless auto.reconfigure is set to false.

If this scenario has occurred because the master has been isolated from network, the Master agent will detect the isolation and release the virtual IP address and create the recovery.conf file. Failover Manager will perform the previously listed steps on the remaining nodes of the cluster.

To recover from this scenario without restarting the entire cluster, you should:

1.  Restart the original Master node.
2.  Bring the original Master database up as a Standby node.
3.  Start the service on the original Master node.

Please note that stopping an agent does not signal the cluster that the agent has failed.

<div id="standby_exits" class="registered_link"></div>



## Standby Agent Exits or Node Fails

If a Standby agent exits or a Standby node fails, the other agents will detect that it is no longer connected to the cluster.

![*Failure of Standby Agent.*](images/supported_scenarios_standby_agent_exits.png)

When the failure is detected, the agents attempt to contact the database that resides on the node; if the agents confirm that there is a problem, Failover Manager sends the appropriate notification to the administrator.

If there is only one Master and one Standby remaining, there is no failover protection in the case of a Master node failure. In the case of a Master database failure, the Master and Standby agents can agree that the database failed and proceed with failover.

<div id="dedicated_witness_agent" class="registered_link"></div>



## Dedicated Witness Agent Exits / Node Fails

The following scenario details the actions taken if a dedicated Witness (a node that is not hosting a database) fails.

![*Confirming the Failure of a dedicated Witness.*](images/supported_scenarios_witness_agent_exits.png)

When an agent detects that the Witness node cannot be reached, Failover Manager notifies the administrator of the state of the Witness.

**Note**: If there is only one Master and one Standby remaining, there is no failover protection in the case of a Master node failure. In the case of a Master database failure, the Master and Standby agents can agree that the database failed and proceed with failover.

<div id="node_isolated" class="registered_link"></div>



## Nodes Become Isolated from the Cluster

The following scenario details the actions taken if one or more nodes (a minority of the cluster) become isolated from the majority of the cluster.

![*If members of the cluster become isolated.*](images/supported_scenarios_node_becomes_isolated.png)

If one or more nodes (but less than half of the cluster) become isolated from the rest of the cluster, the remaining cluster behaves as if the nodes have failed. The agents attempt to discern if the Master node is among the isolated nodes; it is, the Master fences itself off from the cluster, while a Standby node (from within the cluster majority) is promoted to replace it. Other Standby nodes are configured to replicate from the new master unless auto.reconfigure is set to false.

Failover Manager then notifies an administrator, and the isolated nodes rejoin the cluster when they are able. When the nodes rejoin the cluster, the failover priority may change.
