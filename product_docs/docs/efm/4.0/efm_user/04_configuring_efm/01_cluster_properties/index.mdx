---
title: "The Cluster Properties File"
---

<div id="cluster_properties" class="registered_link"></div>


Each node in a cluster has a properties file (by default, named `efm.properties`) that contains the properties of the individual node on which it resides. The installer creates a file template for the properties file named `efm.properties.in` in the `/etc/edb/efm-4.0` directory.

After completing the installation, you must make a working copy of the template before modifying the file contents:

<div class="parsed-literal">

\# cp /etc/edb/efm-/efm.properties.in /etc/edb/efm-/efm.properties

</div>

After copying the template file, change the owner of the file to `efm`:

`# chown efm:efm efm.properties`

**Please note:** : By default, expects the cluster properties file to be named `efm.properties`. If you name the properties file something other than `efm.properties`, you must modify the service script or unit file to instruct to use a different name.

After creating the cluster properties file, add (or modify) configuration parameter values as required. For detailed information about each property, see [Specifying Cluster Properties](../04_configuring_efm/01_cluster_properties/#specifying_cluster_properties).

The property files are owned by `root`. The service script expects to find the files in the `/etc/edb/efm-4.0 directory`. If you move the property file to another location, you must create a symbolic link that specifies the new location.

**Please note:** : All user scripts referenced in the properties file will be invoked as the user.

<div id="specifying_cluster_properties" class="registered_link"></div>

## Specifying Cluster Properties

You can use the properties listed in the cluster properties file to specify connection properties and behaviors for your cluster. Modifications to property settings will be applied when starts. If you modify a property value you must restart to apply the changes.

Property values are case-sensitive. Note that while Postgres uses quoted strings in parameter values, does not allow quoted strings in property values. For example, while you might specify an IP address in a Postgres configuration parameter as:

> `listen_addresses='192.168.2.47'`

requires that the value *not* be enclosed in quotes:

> `bind.address=192.168.2.54:7800`

Use the properties in the `efm.properties` file to specify connection, administrative, and operational details for .

**Legends**: In the following table:

-   `A`: Required on Agent node
-   `W`: Required on Witness node
-   `Y` : Yes

<table><caption>Cluster Properties</caption><colgroup><col style="width: 31%" /><col style="width: 5%" /><col style="width: 5%" /><col style="width: 17%" /><col style="width: 42%" /></colgroup><thead><tr class="header"><th><strong>Property Name</strong></th><th><strong>A</strong></th><th><strong>W</strong></th><th><strong>Default Value</strong></th><th><strong>Comments</strong></th></tr></thead><tbody><tr class="odd"><td><a href="#db.user">db.user</a></td><td>Y</td><td>Y</td><td></td><td>Username for the database</td></tr><tr class="even"><td><a href="#db.password.encrypted">db.password.encrypted</a></td><td>Y</td><td>Y</td><td></td><td>Password encrypted using 'efm encrypt'</td></tr><tr class="odd"><td><a href="#db.port">db.port</a></td><td>Y</td><td>Y</td><td></td><td>This value must be same for all the agents</td></tr><tr class="even"><td><a href="#db.database">db.database</a></td><td>Y</td><td>Y</td><td></td><td>Database name</td></tr><tr class="odd"><td><a href="#db.service.owner">db.service.owner</a></td><td>Y</td><td></td><td></td><td>Owner of $PGDATA dir for db.database</td></tr><tr class="even"><td><a href="#db.service.name">db.service.name</a></td><td></td><td></td><td></td><td>Required if running the database as a service</td></tr><tr class="odd"><td><a href="#db.bin">db.bin</a></td><td>Y</td><td></td><td></td><td>Directory containing the pg_controldata/pg_ctl commands such as '/usr/edb/as12/bin'</td></tr><tr class="even"><td><a href="#db.data.dir">db.data.dir</a></td><td>Y</td><td></td><td></td><td>Same as the output of query 'show data_directory;'</td></tr><tr class="odd"><td><a href="#db.config.dir">db.config.dir</a></td><td></td><td></td><td></td><td>Same as the output of query 'show config_file;'. Should be specified if it is not same as <em>db.data.dir</em></td></tr><tr class="even"><td><a href="#jdbc.sslmode">jdbc.sslmode</a></td><td>Y</td><td>Y</td><td>disable</td><td>See the <a href="#jdbc.note">note</a></td></tr><tr class="odd"><td><a href="#user.email">user.email</a></td><td></td><td></td><td></td><td>This value must be same for all the agents; can be left blank if using a notification script</td></tr><tr class="even"><td><a href="#from.email">from.email</a></td><td></td><td></td><td><a href="mailto:efm@localhost">efm@localhost</a></td><td>Leave blank to use the default '<a href="mailto:efm@localhost">efm@localhost</a>'</td></tr><tr class="odd"><td><a href="#notification.level">notification.level</a></td><td>Y</td><td>Y</td><td>INFO</td><td>See the <a href="#notifications">list of notifications</a></td></tr><tr class="even"><td><a href="#notification.text.prefix">notification.text.prefix</a></td><td></td><td></td><td></td><td></td></tr><tr class="odd"><td><a href="#script.notification">script.notification</a></td><td></td><td></td><td></td><td>Required if user.email property is not used; both parameters can be used together</td></tr><tr class="even"><td><a href="#bind.address">bind.address</a></td><td>Y</td><td>Y</td><td></td><td>Example: &lt;ip_address&gt;:&lt;port&gt;</td></tr><tr class="odd"><td><a href="#external.address">external.address</a></td><td></td><td></td><td></td><td>Example: &lt;ip_address/hostname&gt;</td></tr><tr class="even"><td><a href="#admin.port">admin.port</a></td><td>Y</td><td>Y</td><td>7809</td><td>Modify if the default port is already in use</td></tr><tr class="odd"><td><a href="#is.witness">is.witness</a></td><td>Y</td><td>Y</td><td></td><td>See description</td></tr><tr class="even"><td><a href="#local.period">local.period</a></td><td>Y</td><td></td><td>10</td><td></td></tr><tr class="odd"><td><a href="#local.timeout">local.timeout</a></td><td>Y</td><td></td><td>60</td><td></td></tr><tr class="even"><td><a href="#local.timeout.final">local.timeout.final</a></td><td>Y</td><td></td><td>10</td><td></td></tr><tr class="odd"><td><a href="#remote.timeout">remote.timeout</a></td><td>Y</td><td>Y</td><td>10</td><td></td></tr><tr class="even"><td><a href="#node.timeout">node.timeout</a></td><td>Y</td><td>Y</td><td>50</td><td>This value must be same for all the agents</td></tr><tr class="odd"><td><a href="#encrypt.agent.messages">encrypt.agent.messages</a></td><td>Y</td><td>Y</td><td>false</td><td>This value must be same for all the agents</td></tr><tr class="even"><td><a href="#stop.isolated.primary">stop.isolated.primary</a></td><td>Y</td><td></td><td>true</td><td></td></tr><tr class="odd"><td><a href="#stop.failed.primary">stop.failed.primary</a></td><td>Y</td><td></td><td>true</td><td></td></tr><tr class="even"><td><a href="#primary.shutdown.as.failure">primary.shutdown.as.failure</a></td><td>Y</td><td>Y</td><td>false</td><td></td></tr><tr class="odd"><td><a href="#update.physical.slots.period">update.physical.slots.period</a></td><td>Y</td><td></td><td>0</td><td></td></tr><tr class="even"><td><a href="#ping.server.ip">ping.server.ip</a></td><td>Y</td><td>Y</td><td>8.8.8.8</td><td></td></tr><tr class="odd"><td><a href="#ping.server.command">ping.server.command</a></td><td>Y</td><td>Y</td><td>/bin/ping -q -c3 -w5</td><td></td></tr><tr class="even"><td><a href="#auto.allow.hosts">auto.allow.hosts</a></td><td>Y</td><td>Y</td><td>false</td><td></td></tr><tr class="odd"><td><a href="#stable.nodes.file">stable.nodes.file</a></td><td>Y</td><td>Y</td><td>false</td><td></td></tr><tr class="even"><td><a href="#db.reuse.connection.count">db.reuse.connection.count</a></td><td>Y</td><td></td><td>0</td><td></td></tr><tr class="odd"><td><a href="#auto.failover">auto.failover</a></td><td>Y</td><td>Y</td><td>true</td><td></td></tr><tr class="even"><td><a href="#auto.reconfigure">auto.reconfigure</a></td><td>Y</td><td></td><td>true</td><td>This value must be same for all the agents</td></tr><tr class="odd"><td><a href="#promotable">promotable</a></td><td>Y</td><td></td><td>true</td><td></td></tr><tr class="even"><td><a href="#use.replay.tiebreaker">use.replay.tiebreaker</a></td><td>Y</td><td>Y</td><td>true</td><td>This value must be same for all the agents</td></tr><tr class="odd"><td><a href="#standby.restart.delay">standby.restart.delay</a></td><td></td><td></td><td>0</td><td></td></tr><tr class="even"><td><a href="#application.name">application.name</a></td><td></td><td></td><td></td><td>Set to replace the application_name portion of the primary_conninfo entry with this property value before starting the original primary database as a standby.</td></tr><tr class="odd"><td><a href="#restore.command">restore.command</a></td><td></td><td></td><td></td><td><p>Example: restore.command=scp<br />
&lt;db_service_owner&gt;@%h:<br />
&lt;archive_path&gt;/%f %p</p></td></tr><tr class="even"><td><a href="#reconfigure.num.sync">reconfigure.num.sync</a></td><td>Y</td><td></td><td>false</td><td></td></tr><tr class="odd"><td><a href="#reconfigure.sync.primary">reconfigure.sync.primary</a></td><td>Y</td><td></td><td>false</td><td></td></tr><tr class="even"><td><a href="#minimum.standbys">minimum.standbys</a></td><td>Y</td><td>Y</td><td>0</td><td>This value must be same for all the nodes</td></tr><tr class="odd"><td><a href="#recovery.check.period">recovery.check.period</a></td><td>Y</td><td></td><td>2</td><td></td></tr><tr class="even"><td><a href="#restart.connection.timeout">restart.connection.timeout</a></td><td></td><td></td><td>60</td><td></td></tr><tr class="odd"><td><a href="#auto.resume.period">auto.resume.period</a></td><td>Y</td><td></td><td>0</td><td></td></tr><tr class="even"><td><a href="#virtual.ip">virtual.ip</a></td><td></td><td></td><td>(see virtual.ip.single)</td><td>Leave blank if you do not specify a VIP</td></tr><tr class="odd"><td><a href="#virtual.ip">virtual.ip.interface</a></td><td></td><td></td><td></td><td>Required if you specify a VIP</td></tr><tr class="even"><td><a href="#virtual.ip">virtual.ip.prefix</a></td><td></td><td></td><td></td><td>Required if you specify a VIP</td></tr><tr class="odd"><td><a href="#virtual.ip">virtual.ip.single</a></td><td>Y</td><td>Y</td><td>Yes</td><td>This value must be same for all the nodes</td></tr><tr class="even"><td><a href="#check.vip.before.promotion">check.vip.before.promotion</a></td><td>Y</td><td>Y</td><td>Yes</td><td></td></tr><tr class="odd"><td><a href="#script.load.balancer">script.load.balancer.attach</a></td><td></td><td></td><td></td><td><p>Example: script.load.balancer.attach=<br />
/&lt;path&gt;/&lt;attach_script&gt; %h %t</p></td></tr><tr class="even"><td><a href="#script.load.balancer">script.load.balancer.detach</a></td><td></td><td></td><td></td><td><p>Example: script.load.balancer.detach=<br />
/&lt;path&gt;/&lt;detach_script&gt; %h %t</p></td></tr><tr class="odd"><td><a href="#script.fence">script.fence</a></td><td></td><td></td><td></td><td><p>Example: script.fence=<br />
/&lt;path&gt;/&lt;script_name&gt; %p %f</p></td></tr><tr class="even"><td><a href="#script.post.promotion">script.post.promotion</a></td><td></td><td></td><td></td><td><p>Example: script.post.promotion=<br />
/&lt;path&gt;/&lt;script_name&gt; %f %p</p></td></tr><tr class="odd"><td><a href="#script.resumed">script.resumed</a></td><td></td><td></td><td></td><td><p>Example: script.resumed=<br />
/&lt;path&gt;/&lt;script_name&gt;</p></td></tr><tr class="even"><td><a href="#script.db.failure">script.db.failure</a></td><td></td><td></td><td></td><td><p>Example: script.db.failure=<br />
/&lt;path&gt;/&lt;script_name&gt;</p></td></tr><tr class="odd"><td><a href="#script.primary.isolated">script.primary.isolated</a></td><td></td><td></td><td></td><td><p>Example: script.primary.isolated=<br />
/&lt;path&gt;/&lt;script_name&gt;</p></td></tr><tr class="even"><td><a href="#script.remote.pre.promotion">script.remote.pre.promotion</a></td><td></td><td></td><td></td><td><p>Example: script.remote.pre.promotion=<br />
/&lt;path&gt;/&lt;script_name&gt; %p</p></td></tr><tr class="odd"><td><a href="#script.remote.post.promotion">script.remote.post.promotion</a></td><td></td><td></td><td></td><td><p>Example: script.remote.post.promotion=<br />
/&lt;path&gt;/&lt;script_name&gt; %p</p></td></tr><tr class="even"><td><a href="#script.custom.monitor">script.custom.monitor</a></td><td></td><td></td><td></td><td><p>Example: script.custom.monitor=<br />
/&lt;path&gt;/&lt;script_name&gt;</p></td></tr><tr class="odd"><td><a href="#script.custom.monitor">custom.monitor.interval</a></td><td></td><td></td><td></td><td>Required if a custom monitoring script is specified</td></tr><tr class="even"><td><a href="#script.custom.monitor">custom.monitor.timeout</a></td><td></td><td></td><td></td><td>Required if a custom monitoring script is specified</td></tr><tr class="odd"><td><a href="#script.custom.monitor">custom.monitor.safe.mode</a></td><td></td><td></td><td></td><td>Required if a custom monitoring script is specified</td></tr><tr class="even"><td><a href="#sudo.command">sudo.command</a></td><td>Y</td><td>Y</td><td>sudo</td><td></td></tr><tr class="odd"><td><a href="#sudo.command">sudo.user.command</a></td><td>Y</td><td>Y</td><td>sudo -u %u</td><td></td></tr><tr class="even"><td><a href="#lock.dir">lock.dir</a></td><td></td><td></td><td></td><td>If not specified, defaults to '/var/lock/efm-&lt;version&gt;'</td></tr><tr class="odd"><td><a href="#log.dir">log.dir</a></td><td></td><td></td><td></td><td>If not specified, defaults to '/var/log/efm-&lt;version&gt;'</td></tr><tr class="even"><td><a href="#syslog.logging">syslog.host</a></td><td></td><td></td><td>localhost</td><td></td></tr><tr class="odd"><td><a href="#syslog.logging">syslog.port</a></td><td></td><td></td><td>514</td><td></td></tr><tr class="even"><td><a href="#syslog.logging">syslog.protocol</a></td><td></td><td></td><td></td><td></td></tr><tr class="odd"><td><a href="#syslog.logging">syslog.facility</a></td><td></td><td></td><td>UDP</td><td></td></tr><tr class="even"><td><a href="#logtype.enabled">file.log.enabled</a></td><td>Y</td><td>Y</td><td>true</td><td></td></tr><tr class="odd"><td><a href="#logtype.enabled">syslog.enabled</a></td><td>Y</td><td>Y</td><td>false</td><td></td></tr><tr class="even"><td><a href="#loglevel">jgroups.loglevel</a></td><td></td><td></td><td>info</td><td></td></tr><tr class="odd"><td><a href="#loglevel">efm.loglevel</a></td><td></td><td></td><td>info</td><td></td></tr><tr class="even"><td><a href="#jvm.options">jvm.options</a></td><td></td><td></td><td>-Xmx128m</td><td></td></tr></tbody></table>

Cluster Properties



<div id="db_user" class="registered_link"></div>

<div id="db_password_encrypted" class="registered_link"></div>

<div id="db_port" class="registered_link"></div>

<div id="db_database" class="registered_link"></div>

Use the following properties to specify connection details for the cluster:

    # The value for the password property should be the output from
    # 'efm encrypt' -- do not include a cleartext password here. To
    # prevent accidental sharing of passwords among clusters, the
    # cluster name is incorporated into the encrypted password. If
    # you change the cluster name (the name of this file), you must
    # encrypt the password again with the new name.
    # The db.port property must be the same for all nodes.
    db.user=
    db.password.encrypted=
    db.port=
    db.database=

The `db.user` specified must have sufficient privileges to invoke selected PostgreSQL commands on behalf of . For more information, please see `Prerequisites <prerequisites>`.

For information about encrypting the password for the database user, see `Encrypting Your Database Password <encrypting_database_password>`.



<div id="db_service_owner" class="registered_link"></div>

Use the `db.service.owner` property to specify the name of the operating system user that owns the cluster that is being managed by Failover Manager. This property is not required on a dedicated witness node.

    # This property tells EFM which OS user owns the $PGDATA dir for
    # the 'db.database'. By default, the owner is either 'postgres'
    # for PostgreSQL or 'enterprisedb' for EDB Postgres Advanced
    # Server. However, if you have configured your db to run as a
    # different user, you will need to copy the /etc/sudoers.d/efm-XX
    # conf file to grant the necessary permissions to your db owner.
    #
    # This username must have write permission to the
    # 'db.data.dir' specified below.
    db.service.owner=



<div id="db_service_name" class="registered_link"></div>

Specify the name of the database service in the `db.service.name` property if you use the service or systemctl command when starting or stopping the service.

    # Specify the proper service name in order to use service commands
    # rather than pg_ctl to start/stop/restart a database. For example, if
    # this property is set, then 'service <name> restart' or 'systemctl
    # restart <name>'
    # (depending on OS version) will be used to restart the database rather
    # than pg_ctl.
    # This property is required if running the database as a service.
    db.service.name=



<div id="db_bin" class="registered_link"></div>

You should use the same service control mechanism (pg\_ctl, service, or systemctl) each time you start or stop the database service. If you use the `pg_ctl` program to control the service, specify the location of the `pg_ctl` program in the `db.bin` property.

    # Specify the directory containing the pg_controldata/pg_ctl commands,
    # for example:
    # /usr/edb/as11/bin. Unless the db.service.name property is used, the
    # pg_ctl command is used to start/stop/restart databases as needed
    # after a failover or switchover. This property is required.
    db.bin=



<div id="db_data_dir" class="registered_link"></div>

Use the `db.data.dir` property to specify the location to which a recovery file will be written on the Primary node of the cluster during promotion. This property is required on primary and standby nodes; it is not required on a dedicated witness node.

    # For database version 12 and up, this is the directory where a
    # standby.signal file will exist for a standby node. For previous
    # versions, this is the location of the db recovery.conf file on
    # the node.
    # After a failover, the recovery.conf files on remaining standbys are
    # changed to point to the new primary db (a copy of the original is made
    # first). On a primary node, a recovery.conf file will be written during
    # failover and promotion to ensure that the primary node can not be
    # restarted as the primary database.
    # This corresponds to database environment variable PGDATA and should
    # be same as the output of query 'show data_directory;' on respective
    # database.
    db.data.dir=



<div id="db_config_dir" class="registered_link"></div>

Use the `db.config.dir` property to specify the location of database configuration files if they are not stored in the same directory as the `recovery.conf` or `standby.signal` file. This should be the value specified by the `config_file` parameter directory of your Advanced Server or PostgreSQL installation. This value will be used as the location of the Postgres `data` directory when stopping, starting, or restarting the database.

    # Specify the location of database configuration files if they are
    # not contained in the same location as the recovery.conf or
    # standby.signal file. This is most likely the case for Debian
    # installations. The location specified will be used as the -D value
    # (the location of the data directory for the cluster) when calling
    # pg_ctl to start or stop the database. If this property is blank,
    # the db.data.dir location specified by the db.data.dir property will
    # be used. This corresponds to the output of query 'show config_file;'
    # on respective database.
    db.config.dir=

For more information about database configuration files, visit the [PostgreSQL website](https://www.postgresql.org/docs/current/runtime-config-file-locations.html).



<div id="jdbc_sslmode" class="registered_link"></div>

Use the `jdbc.sslmode` property to instruct to use SSL connections; by default, SSL is disabled.

    # Use the jdbc.sslmode property to enable ssl for EFM
    # connections. Setting this property to anything but 'disable'
    # will force the agents to use 'ssl=true' for all JDBC database
    # connections (to both local and remote databases).
    # Valid values are:
    #
    # disable - Do not use ssl for connections.
    # verify-ca - EFM will perform CA verification before allowing
    # the certificate.
    # require - Verification will not be performed on the server
    # certificate.
    jdbc.sslmode=disable

<div id="jdbc_note" class="registered_link"></div>

<div class="note">

<div class="title">

Note

</div>

If you set the value of `jdbc.sslmode` to `verify-ca` and you want to use Java trust store for certificate validation, you need to set the following value:

`jdbc.properties=sslfactory=org.postgresql.ssl.DefaultJavaSSLFactory`

</div>

For information about configuring and using SSL, please see:

> <https://www.postgresql.org/docs/current/static/ssl-tcp.html>

and

> <https://jdbc.postgresql.org/documentation/head/ssl.html>



<div id="user_email" class="registered_link"></div>

Use the `user.email` property to specify an email address (or multiple email addresses) that will receive any notifications sent by Failover Manager.

    # Email address(es) for notifications. The value of this
    # property must be the same across all agents. Multiple email
    # addresses must be separated by space. If using a notification
    # script instead, this property can be left blank.
    user.email=



<div id="from_email" class="registered_link"></div>

The `from.email` property specifies the value that will be used as the sender's address on any email notifications from . You can:

-   leave `from.email` blank to use the default value (`efm@localhost`).
-   specify a custom value for the email address.
-   specify a custom email address, using the `%h` placeholder to represent the name of the node host (e.g., [example@%h](mailto:example@%h)). The placeholder will be replaced with the name of the host as returned by the Linux hostname utility.

For more information about notifications, see `Notifications <notifications>`.

    # Use the from.email property to specify the from email address that
    # will be used for email notifications. Use the %h placeholder to
    # represent the name of the node host (e.g. example@%h). The
    # placeholder will be replaced with the name of the host as returned
    # by the hostname command.
    # Leave blank to use the default, efm@localhost.
    from.email=



<div id="notification_level" class="registered_link"></div>

Use the `notification.level` property to specify the minimum severity level at which will send user notifications or when a notification script is called. For a complete list of notifications, please see `Notifications <notifications>`.

    # Minimum severity level of notifications that will be sent by
    # the agent. The minimum level also applies to the notification
    # script (below). Valid values are INFO, WARNING, and SEVERE.
    # A list of notifications is grouped by severity in the user's
    # guide.
    notification.level=INFO



<div id="notification_text_prefix" class="registered_link"></div>

Use the `notification.text.prefix` property to specify the text to be added to the beginning of every notification.

    # Text to add to the beginning of every notification. This could
    # be used to help identify what the cluster is used for, the role
    # of this node, etc. To use multiple lines, add a backslash \ to
    # the end of a line of text. To include a newline use \n.
    # Example:
    # notification.text.prefix=Development cluster for Example dept.\n\
    # Used by Dev and QA \
    # See Example group for questions.
    notification.text.prefix=



<div id="script_notification" class="registered_link"></div>

Use the `script.notification` property to specify the path to a user-supplied script that acts as a notification service; the script will be passed a message subject and a message body. The script will be invoked each time generates a user notification.

    # Absolute path to script run for user notifications.
    #
    # This is an optional user-supplied script that can be used for
    # notifications instead of email. This is required if not using
    # email notifications. Either/both can be used. The script will
    # be passed two parameters: the message subject and the message
    # body.
    script.notification=



<div id="bind_address" class="registered_link"></div>

The `bind.address` property specifies the IP address and port number of the agent on the current node of the cluster.

    # This property specifies the ip address and port that jgroups
    # will bind to on this node. The value is of the form
    # <ip>:<port>.
    # Note that the port specified here is used for communicating
    # with other nodes, and is not the same as the admin.port below,
    # used only to communicate with the local agent to send control
    # signals.
    # For example, <provide_your_ip_address_here>:7800
    bind.address=



<div id="external_address" class="registered_link"></div>

Use the `external.address` property to specify the IP address or hostname that should be used for communication with all other Failover Manager agents in a NAT environment.

    # This is the ip address/hostname to be used for communication with all
    # other Failover Manager agents. All traffic towards this address
    # should be routed by the network to the bind.address of the node.
    # The value is in the ip/hostname format only. This address will be
    # used in scenarios where nodes are on different networks and broadcast
    # an IP address other than the bind.address to the external world.
    external.address=



<div id="admin_port" class="registered_link"></div>

Use the `admin.port` property to specify a port on which listens for administrative commands.

    # This property controls the port binding of the administration
    # server which is used for some commands (ie cluster-status). The
    # default is 7809; you can modify this value if the port is
    # already in use.
    admin.port=7809



<div id="is_witness" class="registered_link"></div>

Set the `is.witness` property to true to indicate that the current node is a witness node. If is.witness is true, the local agent will not check to see if a local database is running.

    # Specifies whether or not this is a witness node. Witness nodes
    # do not have local databases running.
    is.witness=

The Postgres `pg_is_in_recovery()` function is a boolean function that reports the recovery state of a database. The function returns `true` if the database is in recovery, or false if the database is not in recovery. When an agent starts, it connects to the local database and invokes the `pg_is_in_recovery()` function. If the server responds true, the agent assumes the role of standby; if the server responds false, the agent assumes the role of primary. If there is no local database, the agent will assume an idle state.

<div class="note">

<div class="title">

Note

</div>

If `is.witness` is `true`, will not check the recovery state.

</div>



<div id="local_period" class="registered_link"></div>

<div id="local_timeout" class="registered_link"></div>

<div id="local_timeout_final" class="registered_link"></div>

The following properties specify properties that apply to the local server:

-   The `local.period` property specifies how many seconds between attempts to contact the database server.
-   The `local.timeout` property specifies how long an agent will wait for a positive response from the local database server.
-   The `local.timeout.final` property specifies how long an agent will wait after the final attempt to contact the database server on the current node. If a response is not received from the database within the number of seconds specified by the local.timeout.final property, the database is assumed to have failed.

For example, given the default values of these properties, a check of the local database happens once every 10 seconds. If an attempt to contact the local database does not come back positive within 60 seconds, makes a final attempt to contact the database. If a response is not received within 10 seconds, declares database failure and notifies the administrator listed in the user.email property. These properties are not required on a dedicated witness node.

    # These properties apply to the connection(s) EFM uses to monitor
    # the local database. Every 'local.period' seconds, a database
    # check is made in a background thread. If the main monitoring
    # thread does not see that any checks were successful in
    # 'local.timeout' seconds, then the main thread makes a final
    # check with a timeout value specified by the
    # 'local.timeout.final' value. All values are in seconds.
    # Whether EFM uses single or multiple connections for database
    # checks is controlled by the 'db.reuse.connection.count'
    # property.
    local.period=10
    local.timeout=60
    local.timeout.final=10

If necessary, you should modify these values to suit your business model.



<div id="remote_timeout" class="registered_link"></div>

Use the `remote.timeout` property to specify how many seconds an agent waits for a response from a remote database server (i.e., how long a standby agent waits to verify that the primary database is actually down before performing failover).

    # Timeout for a call to check if a remote database is responsive.
    # For example, this is how long a standby would wait for a
    # DB ping request from itself and the witness to the primary DB
    # before performing failover.
    remote.timeout=10



<div id="node_timeout" class="registered_link"></div>

Use the `node.timeout` property to specify the number of seconds that an agent will wait for a response from a node when determining if a node has failed. The node.timeout property value specifies a timeout value for agent-to-agent communication; other timeout properties in the cluster properties file specify values for agent-to-database communication.

    # The total amount of time in seconds to wait before determining
    # that a node has failed or been disconnected from this node.
    #
    # The value of this property must be the same across all agents.
    node.timeout=50



<div id="encrypt_agent_messages" class="registered_link"></div>

Use the `encrypt.agent.messages` property to specify if the messages sent between agents should be encrypted.

    # Set to true to encrypt messages that are sent between agents.
    # This property must be the same on all agents or else the agents
    # will not be able to connect.
    encrypt.agent.messages=false



<div id="stop_isolated_primary" class="registered_link"></div>

Use the `stop.isolated.primary` property to instruct to shut down the database if a primary agent detects that it is isolated. When true (the default), will stop the database before invoking the script specified in the `script.primary.isolated` property.

    # Shut down the database after a primary agent detects that it has
    # been isolated from the majority of the efm cluster. If set to
    # true, efm will stop the database before running the
    # 'script.primary.isolated' script, if a script is specified.
    stop.isolated.primary=true



<div id="stop_failed_primary" class="registered_link"></div>

Use the `stop.failed.primary` property to instruct to attempt to shut down a primary database if it can not reach the database. If `true`, will run the script specified in the `script.db.failure` property after attempting to shut down the database.

    # Attempt to shut down a failed primary database after EFM can no
    # longer connect to it. This can be used for added safety in the
    # case a failover is caused by a failure of the network on the
    # primary node.
    # If specified, a 'script.db.failure' script is run after this attempt.
    stop.failed.primary=true



<div id="primary_shutdown_as_failure" class="registered_link"></div>

Use the `primary.shutdown.as.failure` parameter to indicate that any shutdown of the agent on the primary node should be treated as a failure. If this parameter is set to `true` and the primary agent stops (for any reason), the cluster will attempt to confirm if the database on the primary node is running:

-   If the database is reached, a notification will be sent informing you of the agent status.
-   If the database is not reached, a failover will occur.

<!-- -->

    # Treat a primary agent shutdown as a failure. This can be set to
    # true to treat a primary agent shutdown as a failure situation,
    # e.g. during the shutdown of a node, accidental or otherwise.
    # Caution should be used when using this feature, as it could
    # cause an unwanted promotion in the case of performing primary
    # database maintenance.
    # Please see the user's guide for more information.
    primary.shutdown.as.failure=false

The `primary.shutdown.as.failure` property is meant to catch user error, rather than failures, such as the accidental shutdown of a primary node. The proper shutdown of a node can appear to the rest of the cluster like a user has stopped the primary agent (for example to perform maintenance on the primary database). If you set the `primary.shutdown.as.failure` property to `true`, care must be taken when performing maintenance.

To perform maintenance on the primary database when `primary.shutdown.as.failure` is `true`, you should stop the primary agent and wait to receive a notification that the primary agent has failed but the database is still running. Then it is safe to stop the primary database. Alternatively, you can use the `efm stop-cluster` command to stop all of the agents without failure checks being performed.



<div id="update_physical_slots_period" class="registered_link"></div>

Use the `update.physical.slots.period` property to define the slot advance frequency for database version 12 and above. When `update.physical.slots.period` is set to a non-zero value, the primary agent will read the current `restart_lsn` of the physical replication slots after every `update.physical.slots.period` seconds, and send this information with its `pg_current_wal_lsn` and `primary_slot_name` (If it is set in the postgresql.conf file) to the standbys. If physical slots do not already exist, setting this parameter to a non-zero value will create the slots and then update the `restart_lsn parameter` for these slots. A non-promotable standby will not create new slots but will update them if they exist.

    # Period in seconds between having the primary agent update promotable
    # standbys with physical replication slot information so that
    # the cluster will continue to use replication slots after a failover.
    # Set to zero to turn off.
    update.physical.slots.period=0



<div id="ping_server_ip" class="registered_link"></div>

Use the `ping.server.ip` property to specify the IP address of a server that can use to confirm that network connectivity is not a problem.

    # This is the address of a well-known server that EFM can ping
    # in an effort to determine network reachability issues. It
    # might be the IP address of a nameserver within your corporate
    # firewall or another server that *should* always be reachable
    # via a 'ping' command from each of the EFM nodes.
    #
    # There are many reasons why this node might not be considered
    # reachable: firewalls might be blocking the request, ICMP might
    # be filtered out, etc.
    #
    # Do not use the IP address of any node in the EFM cluster
    # (primary, standby, or witness) because this ping server is meant
    # to provide an additional layer of information should the EFM
    # nodes lose sight of each other.
    #
    # The installation default is Google's DNS server.
    ping.server.ip=8.8.8.8



<div id="ping_server_command" class="registered_link"></div>

Use the `ping.server.command` property to specify the command used to test network connectivity.

    # This command will be used to test the reachability of certain
    # nodes.
    #
    # Do not include an IP address or hostname on the end of
    # this command - it will be added dynamically at runtime with the
    # values contained in 'virtual.ip' and 'ping.server.ip'.
    #
    # Make sure this command returns reasonably quickly - test it
    # from a shell command line first to make sure it works properly.
    ping.server.command=/bin/ping -q -c3 -w5



<div id="auto_allow_hosts" class="registered_link"></div>

Use the `auto.allow.hosts` property to instruct the server to use the addresses specified in the .nodes file of the first node started to update the allowed host list. Enabling this property (setting auto.allow.hosts to true) can simplify cluster start-up.

    # Have the first node started automatically add the addresses
    # from its .nodes file to the allowed host list. This will make
    # it faster to start the cluster when the initial set of hosts
    # is already known.
    auto.allow.hosts=false



<div id="stable_nodes_file" class="registered_link"></div>

Use the `stable.nodes.file` property to instruct the server to not rewrite the nodes file when a node joins or leaves the cluster. This property is most useful in clusters with unchanging IP addresses.

    # When set to true, EFM will not rewrite the .nodes file whenever
    # new nodes join or leave the cluster. This can help starting a
    # cluster in the cases where it is expected for member addresses
    # to be mostly static, and combined with 'auto.allow.hosts' makes
    # startup easier when learning failover manager.
    stable.nodes.file=false



<div id="db_reuse_connection_count" class="registered_link"></div>

The `db.reuse.connection.count` property allows the administrator to specify the number of times reuses the same database connection to check the database health. The default value is 0, indicating that will create a fresh connection each time. This property is not required on a dedicated witness node.

    # This property controls how many times a database connection is
    # reused before creating a new one. If set to zero, a new
    # connection will be created every time an agent pings its local
    # database.
    db.reuse.connection.count=0



<div id="auto_failover" class="registered_link"></div>

The `auto.failover` property enables automatic failover. By default, auto.failover is set to true.

    # Whether or not failover will happen automatically when the primary
    # fails. Set to false if you want to receive the failover notifications
    # but not have EFM actually perform the failover steps.
    # The value of this property must be the same across all agents.
    auto.failover=true



<div id="auto_reconfigure" class="registered_link"></div>

Use the `auto.reconfigure` property to instruct to enable or disable automatic reconfiguration of remaining Standby servers after the primary standby is promoted to Primary. Set the property to `true` to enable automatic reconfiguration (the default) or `false` to disable automatic reconfiguration. This property is not required on a dedicated witness node. If you are using Advanced Server or PostgreSQL version 11 or earlier, the `recovery.conf` file will be backed up during the reconfiguration process.

    # After a standby is promoted, Failover Manager will attempt to
    # update the remaining standbys to use the new primary. For database
    # versions before 12, Failover Manager will back up recovery.conf.
    # Then it will change the host parameter of the primary_conninfo entry
    # in recovery.conf or postgresql.auto.conf, and restart the database.
    # The restart command is contained in either the efm_db_functions or
    # efm_root_functions file; default when not running db as an os
    # service is: "pg_ctl restart -m fast -w -t <timeout> -D <directory>"
    # where the timeout is the local.timeout property value and the
    # directory is specified by db.data.dir. To turn off
    # automatic reconfiguration, set this property to false.
    auto.reconfigure=true

**Please note:** : `primary_conninfo` is a space-delimited list of keyword=value pairs.



<div id="promotable" class="registered_link"></div>

Use the `promotable` property to indicate that a node should not be promoted. The `promotable` property is ignored when a primary agent is started. This simplifies switching back to the original primary after a switchover or failover. To override the setting, use the efm set-priority command at runtime; for more information about the efm set-priority command, see `Using the efm Utility <using_efm_utility>`.

    # A standby with this set to false will not be added to the
    # failover priority list, and so will not be available for
    # promotion. The property will be used whenever an agent starts
    # as a standby or resumes as a standby after being idle. After
    # startup/resume, the node can still be added or removed from the
    # priority list with the 'efm set-priority' command. This
    # property is required for all non-witness nodes.
    promotable=true



<div id="use_replay_tiebreaker" class="registered_link"></div>

If the same amount of data has been written to more than one standby node, and a failover occurs, the `use.replay.tiebreaker` value will determine how selects a replacement primary. Set the `use.replay.tiebreaker` property to `true` to instruct to failover to the node that will come out of recovery faster, as determined by the log sequence number. To ignore the log sequence number and promote a node based on user preference, set `use.replay.tiebreaker` to `false`.

    # Use replay LSN value for tiebreaker when choosing a standby to
    # promote before using failover priority. Set this property to true to
    # consider replay location as more important than failover priority
    # (as seen in cluster-status command) when choosing the "most ahead"
    # standby to promote.
    use.replay.tiebreaker=true



<div id="standby_restart_delay" class="registered_link"></div>

Use the `standby.restart.delay` property to specify the time in seconds that the standby should wait before it gets reconfigured (stopped/started) to follow the new primary after a promotion.

    # Time in seconds for this standby to delay restarting to follow the
    # primary after a promotion. This can be used to have standbys restart
    # at different times to increase availability. Caution should be used
    # when using this feature, as a delayed standby will not be following
    # the new primary and care must be taken that the new primary retains
    # enough WAL for the standby to follow it.
    # Please see the user's guide for more information.
    standby.restart.delay=0



<div id="application_name" class="registered_link"></div>

You can use the `application.name` property to provide the name of an application that will be copied to the `primary_conninfo` parameter before restarting an old primary node as a standby.

    # During a switchover, recovery settings are copied from a standby
    # to the original primary. If the application.name property is set,
    # Failover Manager will replace the application_name portion of the
    # primary_conninfo entry with this property value before starting
    # the original primary database as a standby. If this property is
    # not set, Failover Manager will remove the parameter value
    # from primary_conninfo.
    application.name=

**Please note:** You should set the `application.name` property on the primary and any promotable standby; in the event of a failover/switchover, the primary node could potentially become a standby node again.



<div id="restore_command" class="registered_link"></div>

Use the `restore.command` property to instruct to update the `restore_command` when a new primary is promoted. `%h` represents the address of the new primary; will replace `%h` with the address of the new primary. `%f` and `%p` are placeholders used by the server. If the property is left blank, will not update the `restore_command` values on the standbys after a promotion.

See the PostgreSQL documentation for more information about using a [restore\_command](https://www.postgresql.org/docs/current/runtime-config-wal.html#RUNTIME-CONFIG-WAL-ARCHIVE-RECOVERY).

    # If the restore_command on a standby restores directly from the
    # primary node, use this property to have Failover Manager change
    # the command when a new primary is promoted.
    #
    # Use the %h placeholder to represent the address of the new primary.
    # During promotion it will be replaced with the address of the new
    # primary.
    #
    # If not specified, failover manager will not change the
    # restore_command value, if any, on standby nodes.
    #
    # Example:
    # restore.command=scp <db service owner>@%h:/var/lib/edb/as12/data/archive/%f %p
    restore.command=



<div id="reconfigure_num_sync" class="registered_link"></div>

The database parameter `synchronous_standby_names` on the primary node specifies the names and count of the synchronous standby servers that will confirm receipt of data, to ensure that the primary nodes can accept write transactions. When `reconfigure.num.sync` property is set to true, will reduce the number of synchronous standby servers and reload the configuration of the primary node to reflect the current value.

    # Reduce num_sync when the number of synchronous standbys drops
    # below the value required by the primary database. If set to true,
    # Failover Manager will reduce the number of standbys needed
    # in the primary's synchronous_standby_names property and reload
    # the primary configuration.
    # Failover Manager will not reduce the number below 1, taking
    # the primary out of synchronous replication, unless the
    # reconfigure.sync.primary property is also set to true.
    reconfigure.num.sync=false



<div id="reconfigure_sync_primary" class="registered_link"></div>

Set the `reconfigure.sync.primary` property to `true` to take the primary database out of synchronous replication mode if the number of standby nodes drops below the level required. Set `reconfigure.sync.primary` to `false` to send a notification if the standby count drops, but not interrupt synchronous replication.

    # Take the primary database out of synchronous replication mode when
    # needed. If set to true, Failover Manager will clear the
    # synchronous_standby_names configuration parameter on the primary
    # if the number of synchronous standbys drops below the required
    # level for the primary to accept writes.
    # If set to false, Failover Manager will detect the situation but
    # will only send a notification if the standby count drops below the
    # required level.
    #
    # CAUTION: TAKING THE PRIMARY DATABASE OUT OF SYNCHRONOUS MODE MEANS
    # THERE MAY ONLY BE ONE COPY OF DATA. DO NOT MAKE THIS CHANGE UNLESS
    # YOU ARE SURE THIS IS OK.
    reconfigure.sync.primary=false



<div id="minimum_standbys" class="registered_link"></div>

Use the `minimum.standbys` property to specify the minimum number of standby nodes that will be retained on a cluster; if the standby count drops to the specified minimum, a replica node will not be promoted in the event of a failure of the primary node.

    # Instead of setting specific standbys as being unavailable for
    # promotion, this property can be used to set a minimum number
    # of standbys that will not be promoted. Set to one, for
    # example, promotion will not happen if it will drop the number
    # of standbys below this value. This property must be the same on
    # each node.
    minimum.standbys=0



<div id="recovery_check_period" class="registered_link"></div>

Use the `recovery.check.period` property to specify the number of seconds that will wait before checks to see if a database is out of recovery.

    # Time in seconds between checks to see if a promoting database
    # is out of recovery.
    recovery.check.period=2



<div id="restart_connection_timeout" class="registered_link"></div>

Use the `restart.connection.timeout` property to specify the number of seconds that will attempt to connect to a newly reconfigured primary or standby node while the database on that node prepares to accept connections.

    # Time in seconds to keep trying to connect to a database after a
    # start or restart command returns successfully but the database
    # is not ready to accept connections yet (a rare occurance). This
    # applies to standby databases that are restarted when being
    # reconfigured for a new primary, and to primary databases that
    # are stopped and started as standbys during a switchover.
    # This retry mechanism is unrelated to the auto.resume.period
    # parameter.
    restart.connection.timeout=60



<div id="auto_resume_period" class="registered_link"></div>

Use the `auto.resume.period` property to specify the number of seconds (after a monitored database fails, and an agent has assumed an idle state, or when starting in IDLE mode) during which an agent will attempt to resume monitoring that database.

    # Period in seconds for IDLE agents to try to resume monitoring
    # after a database failure or when starting in IDLE mode. Set to
    # 0 for agents to not try to resume (in which case the
    # 'efm resume <cluster>' command is used after bringing a
    # database back up).
    auto.resume.period=0



<div id="virtual_ip" class="registered_link"></div>

provides support for clusters that use a virtual IP. If your cluster uses a virtual IP, provide the host name or IP address in the `virtual.ip` property; specify the corresponding prefix in the `virtual.ip.prefix` property. If `virtual.ip` is left blank, virtual IP support is disabled.

Use the `virtual.ip.interface` property to provide the network interface used by the VIP.

The specified virtual IP address is assigned only to the primary node of the cluster. If you specify `virtual.ip.single=true`, the same VIP address will be used on the new primary in the event of a failover. Specify a value of false to provide a unique IP address for each node of the cluster.

For information about using a virtual IP address, see `Using Failover Manager with Virtual IP Addresses <using_vip_addresses>`.

    # These properties specify the IP and prefix length that will be
    # remapped during failover. If you do not use a VIP as part of
    # your failover solution, leave the virtual.ip property blank to
    # disable Failover Manager support for VIP processing (assigning,
    # releasing, testing reachability, etc).
    #
    # If you specify a VIP, the interface and prefix are required.
    #
    # If you specify a host name, it will be resolved to an IP address
    # when acquiring or releasing the VIP. If the host name resolves
    # to more than one IP address, there is no way to predict which
    # address Failover Manager will use.
    #
    # By default, the virtual.ip and virtual.ip.prefix values must be
    # the same across all agents. If you set virtual.ip.single to
    # false, you can specify unique values for virtual.ip and
    # virtual.ip.prefix on each node.
    #
    # If you are using an IPv4 address, the virtual.ip.interface value
    # should not contain a secondary virtual ip id (do not include
    # ":1", etc).
    virtual.ip=
    virtual.ip.interface=
    virtual.ip.prefix=
    virtual.ip.single=true

**Please note:** : If a primary agent is started and the node does not currently have the VIP, the EFM agent will acquire it. Stopping a primary agent does not drop the VIP from the node.



<div id="check_vip_before_promotion" class="registered_link"></div>

Set the `check.vip.before.promotion` property to false to indicate that will not check to see if a VIP is in use before assigning it to a a new primary in the event of a failure. Please note that this could result in multiple nodes broadcasting on the same VIP address; unless the primary node is isolated or can be shut down via another process, you should set this property to true.

    # Whether to check if the VIP (when used) is still in use before
    # promoting after a primary failure. Turning this off may allow
    # the new primary to have the VIP even though another node is also
    # broadcasting it. This should only be used in environments where
    # it is known that the failed primary node will be isolated or
    # shut down through other means.
    check.vip.before.promotion=true



<div id="script_load_balancer" class="registered_link"></div>

Use the following properties to provide paths to scripts that reconfigure your load balancer in the event of a switchover or primary failure scenario. The scripts will also be invoked in the event of a standby failure. If you are using these properties, they should be provided on every node of the cluster (primary, standby, and witness) to ensure that if a database node fails, another node will call the detach script with the failed node's address.

Provide a script name after the `script.load.balancer.attach` property to identify a script that will be invoked when a node should be attached to the load balancer. Use the `script.load.balancer.detach` property to specify the name of a script that will be invoked when a node should be detached from the load balancer. Include the `%h` placeholder to represent the IP address of the node that is being attached or removed from the cluster. Include the `%t` placeholder to instruct to include an p (for a primary node) or an s (for a standby node) in the string.

    # Absolute path to load balancer scripts
    # The attach script is called when a node should be attached to
    # the load balancer, for example after a promotion. The detach
    # script is called when a node should be removed, for example
    # when a database has failed or is about to be stopped. Use %h to
    # represent the IP/hostname of the node that is being
    # attached/detached. Use %t to represent the type of node being
    # attached or detached: the letter m will be passed in for primary nodes
    #and the letter s for standby nodes.
    #
    # Example:
    # script.load.balancer.attach=/somepath/attachscript %h %t
    script.load.balancer.attach=
    script.load.balancer.detach=



<div id="script_fence" class="registered_link"></div>

`script.fence` specifies the path to an optional user-supplied script that will be invoked during the promotion of a standby node to primary node.

    # absolute path to fencing script run during promotion
    #
    # This is an optional user-supplied script that will be run
    # during failover on the standby database node. If left blank,
    # no action will be taken. If specified, EFM will execute this
    # script before promoting the standby.
    #
    # Parameters can be passed into this script for the failed primary
    # and new primary node addresses. Use %p for new primary and %f
    # for failed primary. On a node that has just been promoted, %p
    # should be the same as the node's efm binding address.
    #
    # Example:
    # script.fence=/somepath/myscript %p %f
    #
    # NOTE: FAILOVER WILL NOT OCCUR IF THIS SCRIPT RETURNS A NON-ZERO EXIT
    # CODE.
    script.fence=



<div id="script_post_promotion" class="registered_link"></div>

Use the `script.post.promotion` property to specify the path to an optional user-supplied script that will be invoked after a standby node has been promoted to primary.

    # Absolute path to fencing script run after promotion
    #
    # This is an optional user-supplied script that will be run after
    # failover on the standby node after it has been promoted and
    # is no longer in recovery. The exit code from this script has
    # no effect on failover manager, but will be included in a
    # notification sent after the script executes.
    #
    # Parameters can be passed into this script for the failed primary
    # and new primary node addresses. Use %p for new primary and %f
    # for failed primary. On a node that has just been promoted, %p
    # should be the same as the node's efm binding address.
    #
    # Example:
    # script.post.promotion=/somepath/myscript %f %p
    script.post.promotion=



<div id="script_resumed" class="registered_link"></div>

Use the `script.resumed property` to specify an optional path to a user-supplied script that will be invoked when an agent resumes monitoring of a database.

    # Absolute path to resume script
    #
    # This script is run before an IDLE agent resumes
    # monitoring its local database.
    script.resumed=



<div id="script_db_failure" class="registered_link"></div>

Use the `script.db.failure` property to specify the complete path to an optional user-supplied script that will invoke if an agent detects that the database that it monitors has failed.

    # Absolute path to script run after database failure
    # This is an optional user-supplied script that will be run after
    # an agent detects that its local database has failed.
    script.db.failure=



<div id="script_primary_isolated" class="registered_link"></div>

Use the `script.primary.isolated` property to specify the complete path to an optional user-supplied script that will invoke if the agent monitoring the primary database detects that the primary is isolated from the majority of the cluster. This script is called immediately after the VIP is released (if a VIP is in use).

    # Absolute path to script run on isolated primary
    # This is an optional user-supplied script that will be run after
    # a primary agent detects that it has been isolated from the
    # majority of the efm cluster.
    script.primary.isolated=



<div id="script_remote_pre_promotion" class="registered_link"></div>

Use the `script.remote.pre.promotion` property to specify the path and name of a script that will be invoked on any agent nodes not involved in the promotion when a node is about to promote its database to primary.

Include the %p placeholder to identify the address of the new primary node.

    # Absolute path to script invoked on non-promoting agent nodes
    # before a promotion.
    #
    # This optional user-supplied script will be invoked on other
    # agents when a node is about to promote its database. The exit
    # code from this script has no effect on Failover Manager, but
    # will be included in a notification sent after the script
    # executes.
    #
    # Pass a parameter (%p) with the script to identify the new
    # primary node address.
    #
    # Example:
    # script.remote.pre.promotion=/path_name/script_name %p
    script.remote.pre.promotion=



<div id="script_remote_post_promotion" class="registered_link"></div>

Use the `script.remote.post.promotion` property to specify the path and name of a script that will be invoked on any non-primary nodes after a promotion occurs.

Include the %p placeholder to identify the address of the new primary node.

    # Absolute path to script invoked on non-primary agent nodes
    # after a promotion.
    #
    # This optional user-supplied script will be invoked on nodes
    # (except the new primary) after a promotion occurs. The exit code
    # from this script has no effect on Failover Manager, but will be
    # included in a notification sent after the script executes.
    #
    # Pass a parameter (%p) with the script to identify the new
    # primary node address.
    #
    # Example:
    # script.remote.post.promotion=/path_name/script_name %p
    script.remote.post.promotion=



<div id="script_custom_monitor" class="registered_link"></div>

Use the `script.custom.monitor` property to provide the name and location of an optional script that will be invoked on regular intervals (specified in seconds by the `custom.monitor.interval` property).

Use `custom.monitor.timeout` to specify the maximum time that the script will be allowed to run; if script execution does not complete within the time specified, will send a notification.

Set `custom.monitor.safe.mode` to `true` to instruct to report non-zero exit codes from the script, but not promote a standby as a result of an exit code.

    # Absolute path to a custom monitoring script.
    #
    # Use script.custom.monitor to specify the location and name of
    # an optional user-supplied script that will be invoked
    # periodically to perform custom monitoring tasks. A non-zero
    # exit value means that a check has failed; this will be treated
    # as a database failure. On a primary node, script failure will
    # cause a promotion. On a standby node script failure will
    # generate a notification and the agent will become IDLE.
    #
    # The custom.monitor.\* properties are required if a custom
    # monitoring script is specified:
    #
    # custom.monitor.interval is the time in seconds between executions
    # of the script.
    #
    # custom.monitor.timeout is a timeout value in seconds for how
    # long the script will be allowed to run. If script execution
    # exceeds the specified time, the task will be stopped and a
    # notification sent. Subsequent runs will continue.
    #
    # If custom.monitor.safe.mode is set to true, non-zero exit codes
    # from the script will be reported but will not cause a promotion
    # or be treated as a database failure. This allows testing of the
    # script without affecting EFM.
    #
    script.custom.monitor=
    custom.monitor.interval=
    custom.monitor.timeout=
    custom.monitor.safe.mode=



<div id="sudo_command" class="registered_link"></div>

Use the `sudo.command` property to specify a command that will be invoked by when performing tasks that require extended permissions. Use this option to include command options that might be specific to your system authentication.

Use the `sudo.user.command` property to specify a command that will be invoked by when executing commands that will be performed by the database owner.

    # Command to use in place of 'sudo' if desired when efm runs
    # the efm_db_functions or efm_root_functions, or efm_address
    # scripts.
    # Sudo is used in the following ways by efm:
    #
    # sudo /usr/edb/efm-<version>/bin/efm_address <arguments>
    # sudo /usr/edb/efm-<version>/bin/efm_root_functions <arguments>
    # sudo -u <db service owner> /usr/edb/efm-<version>/bin/efm_db_functions <arguments>
    #
    # 'sudo' in the first two examples will be replaced by the value
    # of the sudo.command property. 'sudo -u <db service owner>' will
    # be replaced by the value of the sudo.user.command property.
    # The '%u' field will be replaced with the db owner.
    sudo.command=sudo
    sudo.user.command=sudo -u %u



<div id="lock_dir" class="registered_link"></div>

Use the `lock.dir` property to specify an alternate location for the lock file; the file prevents from starting multiple (potentially orphaned) agents for a single cluster on the node.

    # Specify the directory of lock file on the node. Failover
    # Manager creates a file named <cluster>.lock at this location to
    # avoid starting multiple agents for same cluster. If the path
    # does not exist, Failover Manager will attempt to create it. If
    # not specified defaults to '/var/lock/efm-<version>'
    lock.dir=



<div id="log_dir" class="registered_link"></div>

Use the `log.dir` property to specify the location to which agent log files will be written; will attempt to create the directory if the directory does not exist.

    # Specify the directory of agent logs on the node. If the path
    # does not exist, Failover Manager will attempt to create it. If
    # not specified defaults to '/var/log/efm-<version>'. (To store
    # Failover Manager startup logs in a custom location, modify the
    # path in the service script to point to an existing, writable
    # directory.)
    # If using a custom log directory, you must configure
    # logrotate separately. Use 'man logrotate' for more information.
    log.dir=



<div id="syslog_logging" class="registered_link"></div>

After enabling the UDP or TCP protocol on a host, you can enable logging to syslog. Use the `syslog.protocol` parameter to specify the protocol type (UDP or TCP) and the `syslog.port` parameter to specify the listener port of the syslog host. The `syslog.facility` value may be used as an identifier for the process that created the entry; the value must be between LOCAL0 and LOCAL7.

    # Syslog information. The syslog service must be listening on
    # the port for the given protocol, which can be UDP or TCP.
    # The facilities supported are LOCAL0 through LOCAL7.
    syslog.host=localhost
    syslog.port=514
    syslog.protocol=UDP
    syslog.facility=LOCAL1



<div id="logtype_enabled" class="registered_link"></div>

Use the `file.log.enabled` and `syslog.enabled` properties to specify the type of logging that you wish to implement. Set `file.log.enabled` to `true` to enable logging to a file; enable the UDP protocol or TCP protocol and set `syslog.enabled` to `true` to enable logging to syslog. You can enable logging to both a file and syslog.

    # Which logging is enabled.
    file.log.enabled=true
    syslog.enabled=false

For more information about configuring syslog logging, see [Enabling syslog Log File Entries](../#enabling_syslog).



<div id="loglevel" class="registered_link"></div>

Use the `jgroups.loglevel` and `efm.loglevel` parameters to specify the level of detail logged by . The default value is INFO. For more information about logging, see `Controlling Logging <controlling_logging>`.

    # Logging levels for JGroups and EFM.
    # Valid values are: TRACE, DEBUG, INFO, WARN, ERROR
    # Default value: INFO
    # It is not necessary to increase these values unless debugging a
    # specific issue. If nodes are not discovering each other at
    # startup, increasing the jgroups level to DEBUG will show
    # information about the TCP connection attempts that may help
    # diagnose the connection failures.
    jgroups.loglevel=INFO
    efm.loglevel=INFO



<div id="jvm_options" class="registered_link"></div>

Use the `jvm.options` property to pass JVM-related configuration information. The default setting specifies the amount of memory that the agent will be allowed to use.

    # Extra information that will be passed to the JVM when starting
    # the agent.
    jvm.options=-Xmx128m

<div class="toctree" maxdepth="3">

encrypting\_database\_password

</div>
