---
title: Terminology
description: Learn some basic concepts associated with EDB Data Migration Service.
redirects: 
- /edb-postgres-ai/migration-etl/data-migration-service/terminology
---

This terminology is important to understand EDB Data Migration Service (DMS) functionality.

## Change Data Capture (CDC)

CDC is a set of software design patterns used to determine and track changes in data sets by calculating *deltas*. EDB Data Migration Service uses CDC to stream changes from a database cluster to another. 

## EDB DMS Reader

The [EDB Data Migration Service Reader](installing), packaged as `cdcreader`, uses Debezium to perform CDC operations on the source database and Kafka to produce messages containing the change events.

Install and configure the DMS Reader when performing any type of migrations, as it allows you to connect to and read the source. If the destination for your migration is an Hybrid Manager-managed (HM-managed) database, you don't need to install the [DMS Writer](terminology.mdx#edb-dms-writer). If the destination is another self-managed database, install the [DMS Writer](terminology.mdx#edb-dms-writer).

## EDB DMS Writer

The [EDB Data Migration Service Writer](installing2), packaged as `cdcwriter`, uses CDC records to replicate and apply changes on the destination database.

Install and configure the DMS Writer on your destination machine when performing migrations to self-managed destination databases, as it allows you to connect to self-managed destinations. Additionally install the [DMS Reader](terminology.mdx#edb-dms-reader) for any type of migrations.

## Auxiliary machine

An auxiliary machine is a Linux-based server (bare metal, VM, or local) dedicated to running the EDB DMS Reader and Writer for database migrations. This machine acts as the migration engine, capable of connecting to various source and destination databases, whether local or remote. 

While it can be the same host as where you have a source or destination database, as well as the same host where you have the HM running, its only requirement is a Linux operating system, since it is the only platform currently supporting the EDB DMS Reader and Writer.

## Migration types

When [creating migrations](migration_guides/self_managed_pg_to_hm_managed/creating_migration/), you can choose whether to perform a **Snapshot** or **Snapshot + Streaming** migration.

### Snapshot migration

When you select the **Snapshot** option, DMS captures an image of your database at a specific moment. This point-in-time copy is then used for the migration. Any new inserts and updates performed on the source database after the snapshot is taken won't be replicated to the destination database.

### Snapshot + Streaming migration

When you select the **Snapshot + Streaming** option, DMS begins with a snapshot to establish a baseline copy, and then constantly employs CDC to apply subsequent changes, ensuring data consistency during migration. DMS continues to stream any data updates performed on the source database to the destination database until you [mark the migration as completed](migration_guides/self_managed_pg_to_hm_managed/finalizing_migration/).

## Migration destination types

When [creating migrations](migration_guides/self_managed_pg_to_hm_managed/creating_migration/), you can choose whether to perform a migration to **Managed Postgres** or to **External Postgres**.

### Managed Postgres

Managed Postgres destinations are databases created and managed through the HM. All database clusters created within the project where you are performing the migration can be selected as possible migration destinations. 

### External Postgres

External Postgres destinations are databases created outside of the HM and fully managed by you. To choose an external postgres database as a migration destination, you must first install and configure the [DMS Writer](terminology.mdx#edb-dms-writer) to allow the DMS to connect to the self-managed database and perform write operations on it.

## Apache Kafka

[Apache Kafka](https://kafka.apache.org/) is an open-source, distributed-event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications. EDB Data Migration Service uses Kafka to manage data streaming from the source to the destination database.

## Debezium

[Debezium](https://debezium.io/) is a Java-based, open-source platform for CDC that is supported by the Red Hat community. The EDB DMS Reader uses Debezium to perform reading operations and capture data changes on the source database.
