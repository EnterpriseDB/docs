---
title: trafilatura
navTitle: TrafilaturaWebScraperDriver

---

-   `__all__ = ['TrafilaturaWebScraperDriver']` <small>module-attribute</small>  <span id="griptape.drivers.web_scraper.trafilatura.__all__"></span> 

<span id="griptape.drivers.web_scraper.trafilatura.TrafilaturaWebScraperDriver"></span>

Bases:
 [`BaseWebScraperDriver`](./#griptape.drivers.web_scraper.BaseWebScraperDriver "BaseWebScraperDriver (griptape.drivers.web_scraper.BaseWebScraperDriver)")

<details><summary>Source Code in <code>griptape&#47;drivers&#47;web_scraper&#47;trafilatura_web_scraper_driver.py</code></summary>

```python
@define
class TrafilaturaWebScraperDriver(BaseWebScraperDriver):
    include_links: bool = field(default=True, kw_only=True)
    no_ssl: bool = field(default=False, kw_only=True)

    def fetch_url(self, url: str) -> str:
        trafilatura = import_optional_dependency("trafilatura")
        use_config = trafilatura.settings.use_config

        config = use_config()
        page = trafilatura.fetch_url(url, no_ssl=self.no_ssl)

        # This disables signal, so that trafilatura can work on any thread:
        # More info: https://trafilatura.readthedocs.io/usage-python.html#disabling-signal
        config.set("DEFAULT", "EXTRACTION_TIMEOUT", "0")

        # Disable error logging in trafilatura as it sometimes logs errors from lxml, even though
        # the end result of page parsing is successful.
        logging.getLogger("trafilatura").setLevel(logging.FATAL)

        if page is None:
            raise Exception("can't access URL")

        return page

    def extract_page(self, page: str) -> TextArtifact:
        trafilatura = import_optional_dependency("trafilatura")
        use_config = trafilatura.settings.use_config

        config = use_config()

        extracted_page = trafilatura.extract(
            page,
            include_links=self.include_links,
            output_format="json",
            config=config,
        )

        if not extracted_page:
            raise Exception("can't extract page")

        text = json.loads(extracted_page).get("text")

        return TextArtifact(text)
```

</details>

-   `include_links = field(default=True, kw_only=True)` <small>class-attribute</small> <small>instance-attribute</small>  <span id="griptape.drivers.web_scraper.trafilatura.TrafilaturaWebScraperDriver.include_links"></span> 

-   `no_ssl = field(default=False, kw_only=True)` <small>class-attribute</small> <small>instance-attribute</small>  <span id="griptape.drivers.web_scraper.trafilatura.TrafilaturaWebScraperDriver.no_ssl"></span> 

<span id="griptape.drivers.web_scraper.trafilatura.TrafilaturaWebScraperDriver.extract_page"></span>

### extract_page(page)

<details><summary>Source Code in <code>griptape&#47;drivers&#47;web_scraper&#47;trafilatura_web_scraper_driver.py</code></summary>

```python
def extract_page(self, page: str) -> TextArtifact:
    trafilatura = import_optional_dependency("trafilatura")
    use_config = trafilatura.settings.use_config

    config = use_config()

    extracted_page = trafilatura.extract(
        page,
        include_links=self.include_links,
        output_format="json",
        config=config,
    )

    if not extracted_page:
        raise Exception("can't extract page")

    text = json.loads(extracted_page).get("text")

    return TextArtifact(text)
```

</details>

<span id="griptape.drivers.web_scraper.trafilatura.TrafilaturaWebScraperDriver.fetch_url"></span>

### fetch_url(url)

<details><summary>Source Code in <code>griptape&#47;drivers&#47;web_scraper&#47;trafilatura_web_scraper_driver.py</code></summary>

```python
def fetch_url(self, url: str) -> str:
    trafilatura = import_optional_dependency("trafilatura")
    use_config = trafilatura.settings.use_config

    config = use_config()
    page = trafilatura.fetch_url(url, no_ssl=self.no_ssl)

    # This disables signal, so that trafilatura can work on any thread:
    # More info: https://trafilatura.readthedocs.io/usage-python.html#disabling-signal
    config.set("DEFAULT", "EXTRACTION_TIMEOUT", "0")

    # Disable error logging in trafilatura as it sometimes logs errors from lxml, even though
    # the end result of page parsing is successful.
    logging.getLogger("trafilatura").setLevel(logging.FATAL)

    if page is None:
        raise Exception("can't access URL")

    return page
```

</details>
