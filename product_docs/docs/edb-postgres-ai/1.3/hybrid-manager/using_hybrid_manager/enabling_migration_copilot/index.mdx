---
title: Enabling the Migration Portal AI Copilot
navTitle: Enabling Migration Portal AI Copilot
description: Learn how to enable and configure the Migration Portal AI Copilot for Hybrid Manager.
navigation: 
  - third_party_model
  - self-hosted_model
---

After deploying the Hybrid Manager (HM), [Migration Portal](https://www.enterprisedb.com/docs/migration_portal/latest/), a Launchpad tool to help you migrate external database schemas, works out of the box. 

However, the [AI Copilot](https://www.enterprisedb.com/docs/migration_portal/latest/03_mp_using_portal/mp_ai_copilot/), a chat-bot tool that helps you resolve schema migration compatibility issues within the Migration Portal, is not enabled by default, so you need additional configuration to enable it.

You can configure the AI Copilot using OpenAI, Azure OpenAI, or an alternative AI vendor. Alternatively, you can configure the AI Copilot to work with a self-hosted model you previously created within the HM with EDB AI Factory capabilities. This gives you the flexibility of using ready-to-use models from a third-party vendor or of having complete control over your data and environment. 

<br/>

<center>

![Model options for the Migration Portal AI Copilot](/edb-postgres-ai/latest/hybrid-manager/images/mp_ai_copilot_models.svg)
 
</center>

## Third-party model (cloud)

**Workflow:** While using the Migration Portal, you can submit a prompt to the Migration Portal AI Copilot to obtain information and help on schema conversion.The AI Copilot then communicates with an external, third-party cloud vendor of your choice (for example, OpenAI) over the Internet. The third-party vendor uses its own model to process the prompt and generate an answer.

**Models:** Third-party vendors provide the core AI capabilities, including a chat completion model and an embeddings model. (For Azure OpenAI you'll still have to generate an embedding model.)

**Benefits:** This approach offers access to highly powerful and continuously updated models without the need for you to manage any AI infrastructure.

**Considerations:** This option requires uninterrupted Internet connectivity, and depeding on the license, data may be stored with the vendor. Additionally, consider costs that may be caused by periodic health check requests that the chat completion and embeddings models need, as well as per-query charges.

## Self-hosted model (on-premises)

**Workflow:** While using the Migration Portal, you can submit a prompt to the Migration Portal AI Copilot to obtain information and help on schema conversion. The AI Copilot then communicates with models that are hosted locally within the Hybrid Manager environment itself. These models are previously created by your organization with EDB AI Factory capabilities. The self-hosted models process the prompt and generate an answer.

**Models:** You create and manage these models using the EDB AI Factory. They can be models like Llama 3, which is served using an NVIDIA NIM microservice.

**Benefits:** This approach is better suited for organizations that require a highly secure, air-gapped environment. It ensures that all data processing remains within your infrastructure, meeting strict compliance and privacy requirements. 

**Considerations:** The AI infrastructure is managed by you, which means you'll need AI expertise in your organization. Additionally, self-hosted models lack the built-in content filtering and safeguards provided by third-party vendors. The responsibility and potential liability for any unsafe or harmful content generated by the model will fall on the user or organization. You also must consider resource consumption of costly GPU nodes required to run AI workloads.

## Model performance and quality

The following tables show evaluation results of the Migration Copilot backed by the recommended OpenAI models followed by the recommended AI Factory models.
The evaluation scores range from 0 to 1 and criteria can be briefly summarized as:

- alignment: Verify responses are aligned with the desired character by providing relevant and helpful database information, avoiding aggressive or inappropriate prompts, and refraining from offering unnecessary menus or referencing its own internal tools.
- answer_correctness: Assess whether responses meet specific quality criteria.
- answer_input_coherence: Determine if the response is coherent with the input query.
- answer_retrieval_context_coherence: Determine if the response is coherent with the input query and retrieval context.

### gpt-4o and text-embedding-3-small

|       |   alignment_score |   answer_correctness_score |   answer_input_coherence_score |   answer_retrieval_context_coherence_score |
|:------|------------------:|---------------------------:|-------------------------------:|-------------------------------------------:|
| count |        24         |                  24        |                      22        |                                 20         |
| mean  |         0.947577  |                   0.825242 |                       0.929941 |                                  0.935199  |
| std   |         0.0829911 |                   0.180767 |                       0.14578  |                                  0.0844927 |
| min   |         0.713618  |                   0.353643 |                       0.472948 |                                  0.670565  |
| 25%   |         0.914415  |                   0.700465 |                       0.928083 |                                  0.899846  |
| 50%   |         1         |                   0.87383  |                       1        |                                  0.974838  |
| 75%   |         1         |                   1        |                       1        |                                  1         |
| max   |         1         |                   1        |                       1        |                                  1         |

### nvidia/llama-3.3-nemotron-super-49b-v1 and nvidia/llama-3.2-nv-embedqa-1b-v2

|       |   alignment_score |   answer_correctness_score |   answer_input_coherence_score |   answer_retrieval_context_coherence_score |
|:------|------------------:|---------------------------:|-------------------------------:|-------------------------------------------:|
| count |         24        |                 24         |                      22        |                                  20        |
| mean  |          0.806169 |                  0.678732  |                       0.893696 |                                   0.915421 |
| std   |          0.239017 |                  0.297342  |                       0.210395 |                                   0.177903 |
| min   |          0        |                  0.0629086 |                       0.233905 |                                   0.194792 |
| 25%   |          0.77138  |                  0.522347  |                       0.913309 |                                   0.928837 |
| 50%   |          0.857742 |                  0.758671  |                       0.989979 |                                   0.946891 |
| 75%   |          0.941703 |                  0.901787  |                       1        |                                   1        |
| max   |          1        |                  1         |                       1        |                                   1        |

