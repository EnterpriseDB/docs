---
title: Enabling the Migration Portal AI Copilot
navTitle: Enabling Migration Portal AI Copilot
description: Learn how to enable and configure the Migration Portal AI Copilot for Hybrid Manager.
navigation: 
  - third_party_model
  - self-hosted_model
---

After deploying the Hybrid Manager (HM), [Migration Portal](https://www.enterprisedb.com/docs/migration_portal/latest/), a Launchpad tool to help you migrate external database schemas, works out of the box. 

However, the [AI Copilot](https://www.enterprisedb.com/docs/migration_portal/latest/03_mp_using_portal/mp_ai_copilot/), a chat-bot tool that helps you resolve schema migration compatibility issues within the Migration Portal, is not enabled by default, so you need additional configuration to enable it.

You can configure the AI Copilot using OpenAI, Azure OpenAI, or an alternative AI vendor. Alternatively, you can configure the AI Copilot to work with a self-hosted model you previously created within the HM with EDB AI Factory capabilities. This gives you the flexibility of using ready-to-use models from a third-party vendor or of having complete control over your data and environment. 

<br/>

<center>

![Model options for the Migration Portal AI Copilot](/edb-postgres-ai/latest/hybrid-manager/images/mp_ai_copilot_models.svg)
 
</center>

## Third-party model (cloud)

**Workflow:** While using the Migration Portal, you can submit a prompt to the Migration Portal AI Copilot to obtain information and help on schema conversion.The AI Copilot then communicates with an external, third-party cloud vendor of your choice (for example, OpenAI) over the Internet. The third-party vendor uses its own model to process the prompt and generate an answer.

**Models:** Third-party vendors provide the core AI capabilities, including a chat completion model and an embeddings model. (For Azure OpenAI you'll still have to generate an embedding model.)

**Benefits:** This approach offers access to highly powerful and continuously updated models without the need for you to manage any AI infrastructure. However, they require uninterrupted Internet connectivity, and depeding on the license, data may be stored with the vendor.

**Considerations:** This option can incur costs caused by periodic health checks requests that the chat completion and embeddings models need to ensure continued operations. Additionally, further charged may be done per user query.

## Self-hosted model (on-premises)

**Workflow:** While using the Migration Portal, you can submit a prompt to the Migration Portal AI Copilot to obtain information and help on schema conversion. The AI Copilot then communicates with models that are hosted locally within the Hybrid Manager environment itself. These models are previously created by your organization with EDB AI Factory capabilities. The self-hosted models process the prompt and generate an answer.

**Models:** You create and manage these models using the EDB AI Factory. They can be models like Llama 3, which is served using an NVIDIA NIM microservice.

**Benefits:** This approach is better suited for organizations that require a highly secure, air-gapped environment. It ensures that all data processing remains within your infrastructure, meeting strict compliance and privacy requirements. However, the AI infrastructure is managed by you, which means you'll need AI expertise in your organization. Additionally, the quality of answers may not be as good as with third-party vendors. You also must consider resource consumption of costly GPU nodes required to run AI workloads. 

**Considerations:**

## Model performance and quality

