---
title: AI Factory Quickstart
navTitle: Quickstart
description: Build a simple Gen AI assistant backed by a Knowledge Base and deploy a model endpoint using AI Factory.
---

Hub quick links: [Gen AI](/edb-postgres-ai/1.3/ai-factory/gen-ai/) — [Pipelines](/edb-postgres-ai/1.3/ai-factory/pipeline/) — [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/)

## What you’ll build

This quickstart gets you from zero to a working Gen AI assistant that answers questions from a Knowledge Base, plus a deployed model endpoint you can call from applications.

## Prerequisites

- Prepare your deployment's GPU: [Setup GPU](/edb-postgres-ai/1.3/ai-factory/model/setup-gpu)
- Familiarity with the Gen AI concepts and Pipelines: [Gen AI](/edb-postgres-ai/1.3/ai-factory/gen-ai/), [Pipelines](/edb-postgres-ai/1.3/ai-factory/pipeline/)

## Step 1 — Create a Knowledge Base

Create a Knowledge Base and ingest your content so the assistant can retrieve context:

- [Create a Knowledge Base](/edb-postgres-ai/1.3/ai-factory/gen-ai/create-knowledge-base)
- (Optional) Review Knowledge Base concepts: [Knowledge Bases (explained)](/edb-postgres-ai/1.3/ai-factory/gen-ai/knowledge-bases/)

## Step 2 — Create an Assistant

Build a conversational assistant and attach your Knowledge Base:

- [Create an Assistant](/edb-postgres-ai/1.3/ai-factory/gen-ai/create-assistant)
- (Optional) Review assistants: [Assistants explained](/edb-postgres-ai/1.3/ai-factory/gen-ai/assistants/assistants-explained/)

## Step 3 — Deploy a model endpoint

Deploy a model using KServe so your applications can call it directly:

- [Deploy NIM containers](/edb-postgres-ai/1.3/ai-factory/model/deploy-nim-container)
- [Create an InferenceService](/edb-postgres-ai/1.3/ai-factory/model/create-inferenceservice/)
- (Optional) Customize runtime: [Configure ServingRuntime](/edb-postgres-ai/1.3/ai-factory/model/configure-servingruntime/)

## Step 4 — Call the endpoint from an app

Test your deployed model with a simple client and learn how to reach endpoints:

- [Quickstart (Python)](/edb-postgres-ai/1.3/ai-factory/model/quickstart-python-using-inference-endpoint)
- [Access KServe endpoints](/edb-postgres-ai/1.3/ai-factory/model/access-kserve-endpoints)

## Step 5 — Monitor and iterate

Keep an eye on model health and performance:

- [Monitor InferenceService](/edb-postgres-ai/1.3/ai-factory/model/monitor-inferenceservice)
- (Optional) Tune Knowledge Base performance: [Knowledge Base performance](/edb-postgres-ai/1.3/ai-factory/pipeline/knowledge_base/performance_tuning)

## Next steps

- Learn progressively: [Learning paths](/edb-postgres-ai/1.3/ai-factory/learn/learning-paths)
- Explore patterns: [Use cases](/edb-postgres-ai/1.3/ai-factory/learn/use-cases) and [Solutions](/edb-postgres-ai/1.3/ai-factory/learn/solutions)
- Deep dive into the APIs and reference material via the Gen AI and Model Serving hubs
