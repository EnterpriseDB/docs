---
title: AI Factory terminology
navTitle: Terminology
description: Definitions of key concepts, technologies, and architecture patterns used in AI Factory and Hybrid Manager AI Factory.
---

AI Factory terminology defines key concepts and technologies used across **EDB Postgres® AI** (EDB PG AI), **Hybrid Manager AI Factory**, and related components.

This page complements these conceptual explanations:

-   [AI Factory concepts](/edb-postgres-ai/1.3/ai-factory/ai-factory-concepts)
-   [Generic concepts](/edb-postgres-ai/1.3/ai-factory/generic-concepts)

Understanding these terms helps you build trusted, governed, and scalable AI solutions with EDB PG AI.

* * *

## Core AI concepts

### Machine learning (ML)

Machine learning uses algorithms that improve through data exposure to perform tasks without explicit programming. It powers predictive analytics, automation, and decision making in AI Factory through [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/), Pipelines, and Assistants.

[Learn more](https://en.wikipedia.org/wiki/Machine_learning)

### Deep learning (DL)

Deep learning leverages multi-layer neural networks to model complex data patterns. It supports advanced applications such as language understanding and image recognition within AI Factory, enabled through [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/) with GPU acceleration.

[Learn more](https://en.wikipedia.org/wiki/Deep_learning)

### Natural language processing (NLP)

Natural language processing (NLP) enables computers to understand and generate human language. It underpins semantic search and conversational AI in AI Factory via [Knowledge Bases](/edb-postgres-ai/1.3/ai-factory/gen-ai/libraries/knowledge-bases-explained/), [Retrievers](/edb-postgres-ai/1.3/ai-factory/gen-ai/structures/retrievers-explained/), and [Assistants](/edb-postgres-ai/1.3/ai-factory/gen-ai/assistants/assistants-explained/).

[Learn more](https://en.wikipedia.org/wiki/Natural_language_processing)

### Large language models (LLMs)

LLMs are large deep learning models trained on massive text corpora. In AI Factory, they drive [Assistants](/edb-postgres-ai/1.3/ai-factory/gen-ai/assistants/assistants-explained/), Retrieval-Augmented Generation (RAG), and various model pipelines, deployed using [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/).

[Learn more](https://huggingface.co/blog/llm)

### Embeddings

Embeddings are vector representations of data that capture semantic meaning. AI Factory Pipelines create embeddings used in [Knowledge Bases](/edb-postgres-ai/1.3/ai-factory/gen-ai/libraries/knowledge-bases-explained/) and served through the [Vector Engine](/edb-postgres-ai/1.3/ai-factory/vector-engine/) to enable semantic search and RAG.

[Learn more](https://sebastianraschka.com/blog/2023/llm-embeddings.html)

### Vector databases

Vector databases store embeddings and enable fast similarity search. AI Factory provides this through the [Vector Engine](/edb-postgres-ai/1.3/ai-factory/vector-engine/), built on the open-source [pgvector](https://github.com/pgvector/pgvector) extension, integrated directly with Postgres.

### Retrieval-augmented generation (RAG)

RAG combines vector search with LLM generation to ground model responses in relevant documents. In AI Factory, it is implemented through [Knowledge Bases](/edb-postgres-ai/1.3/ai-factory/gen-ai/libraries/knowledge-bases-explained/), [Retrievers](/edb-postgres-ai/1.3/ai-factory/gen-ai/structures/retrievers-explained/), and [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/).

[Intro to RAG](https://huggingface.co/blog/rag)

* * *

## AI for databases

### Intelligent database management

Intelligent database management applies AI to optimize Postgres performance and operations. AI Factory extends this with intelligent retrieval and search using [Vector Engine](/edb-postgres-ai/1.3/ai-factory/vector-engine/) and Pipelines.

### In-database machine learning (In-DB ML)

In-DB ML enables running vector search and ML pipelines inside Postgres, reducing data movement and latency. AI Factory implements this through [Vector Engine](/edb-postgres-ai/1.3/ai-factory/vector-engine/) and [Pipelines](/edb-postgres-ai/1.3/ai-factory/pipeline/).

### Vector search in Postgres

Vector search allows you to query embeddings directly within Postgres. AI Factory uses [pgvector](https://github.com/pgvector/pgvector) to power this capability through the [Vector Engine](/edb-postgres-ai/1.3/ai-factory/vector-engine/), supporting Knowledge Bases and RAG.

### AIDB

AIDB (AI-in-Database) brings vector search, embedding pipelines, and future ML capabilities to HCP-managed Postgres clusters. It is the foundation for AI Factory [Pipelines](/edb-postgres-ai/1.3/ai-factory/pipeline/) and Knowledge Bases.
========
Intelligent database management applies AI to optimize Postgres performance and operations. AI Factory extends this with intelligent retrieval and search using [Vector Engine](/edb-postgres-ai/latest/ai-factory/vector-engine/) and Pipelines.

### In-database machine learning (In-DB ML)

In-DB ML enables running vector search and ML pipelines inside Postgres, reducing data movement and latency. AI Factory implements this through [Vector Engine](/edb-postgres-ai/latest/ai-factory/vector-engine/) and [Pipelines](/edb-postgres-ai/latest/ai-factory/pipeline/).

### Vector search in Postgres

Vector search allows you to query embeddings directly within Postgres. AI Factory uses [pgvector](https://github.com/pgvector/pgvector) to power this capability through the [Vector Engine](/edb-postgres-ai/latest/ai-factory/vector-engine/), supporting Knowledge Bases and RAG.

### AIDB

AIDB (AI-in-Database) brings vector search, embedding pipelines, and future ML capabilities to HCP-managed Postgres clusters. It is the foundation for AI Factory [Pipelines](/edb-postgres-ai/latest/ai-factory/pipeline/) and Knowledge Bases.

### Natural language interfaces to databases

Natural language interfaces enable users to query Postgres using natural language rather than SQL. AI Factory Assistants leverage this pattern through [Gen AI Builder](/edb-postgres-ai/latest/hybrid-manager/ai-factory/gen-ai/builder/), combining LLMs with structured and unstructured retrieval.

* * *

## AI infrastructure

### AI-accelerated hardware


AI Factory uses GPU-accelerated Kubernetes clusters to serve deep learning models and high-throughput inference. Model workloads in [Model Serving](/edb-postgres-ai/latest/ai-factory/model/serving/) run on GPU-enabled nodes.

[Learn more](https://developer.nvidia.com/cuda-gpus)

### KServe

KServe is the open-source Kubernetes-native framework AI Factory uses to deploy and manage ML models. It provides InferenceServices, autoscaling, and observability for AI Factory [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/).

[KServe documentation](https://kserve.github.io/website/)

### Model Serving

Model Serving deploys AI models as production-grade inference services, using KServe under the hood. It supports LLMs, embedding models, vision models, and custom AI workloads.

See: [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/), [Model Serving explained](/edb-postgres-ai/1.3/ai-factory/model/model-serving-explained/)

* * *

## Gen AI Builder

### Gen AI Builder

Gen AI Builder is the application layer of AI Factory for building AI-powered apps and agents. It integrates:

-   [Assistants](/edb-postgres-ai/1.3/ai-factory/gen-ai/assistants/assistants-explained) for conversational AI
-   [Knowledge Bases](/edb-postgres-ai/1.3/ai-factory/gen-ai/libraries/knowledge-bases-explained) for RAG and semantic search
-   [Retrievers](/edb-postgres-ai/1.3/ai-factory/gen-ai/structures/retrievers-explained) for advanced search patterns
-   [Tools](/edb-postgres-ai/1.3/ai-factory/gen-ai/tools/tools-explained) to perform external actions
-   [Rulesets](/edb-postgres-ai/1.3/ai-factory/gen-ai/rulesets/rulesets-explained) to control Assistant behavior
-   [Threads](/edb-postgres-ai/1.3/ai-factory/gen-ai/threads/threads-explained) to persist conversation history
-   [Structures](/edb-postgres-ai/1.3/ai-factory/gen-ai/structures/structures-explained) to define AI workflows and pipelines

It is deployed on [Hybrid Manager AI Factory](/edb-postgres-ai/1.3/hybrid-manager/ai-factory/), enabling full-stack Sovereign AI.

* * *

## Hybrid Manager AI Factory

### Hybrid Manager

Hybrid Manager provides the Kubernetes-based control plane for AI Factory workloads, managing GPU resources, Pipelines, Model Serving, and Knowledge Bases. It provides end-to-end governance, security, and observability.

See: [Hybrid Manager AI Factory](/edb-postgres-ai/1.3/hybrid-manager/ai-factory/)

### Pipelines

Pipelines automate the creation of embeddings and Knowledge Bases from data sources in your control, ensuring transparency and auditability.

See: [Pipelines overview](/edb-postgres-ai/1.3/ai-factory/pipeline/)

### Knowledge Bases

Knowledge Bases index content for semantic search and RAG. They support multi-source, multi-modal search and power AI Factory Assistants.

See: [Knowledge Bases explained](/edb-postgres-ai/1.3/ai-factory/gen-ai/libraries/knowledge-bases-explained/)

### Model Serving

Model Serving deploys models using Kubernetes-native KServe and integrates with the [Model Library](/edb-postgres-ai/1.3/ai-factory/model/library/). It powers Assistants, Knowledge Bases, and custom AI applications.

See: [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/serving/)

* * *

## Additional concepts

### Image and Model Library

The Image and Model Library in Hybrid Manager manages container images for both Postgres and AI model deployments. The [Model Library](/edb-postgres-ai/1.3/ai-factory/model/library/) provides an AI-focused view, supporting Model Serving and governed image workflows.

See: [Model Image Library explained](/edb-postgres-ai/1.3/hybrid-manager/ai-factory/learn/explained/model-image-library-explained/)

### NVIDIA NIM

NVIDIA NIM Microservices  are optimized AI model images from NVIDIA for high-performance inference. AI Factory uses NIM containers for LLMs, embeddings, and vision models, served through Model Serving.

See: [Deploy NIM containers](/edb-postgres-ai/1.3/ai-factory/model/deploy-nim-container/)

* * *

## Summary

Understanding these terms will help you build with:

-   [AI Factory concepts](/edb-postgres-ai/1.3/ai-factory/ai-factory-concepts)
-   [AI Factory explained pages](/edb-postgres-ai/1.3/ai-factory/learn/explained/)
-   [Hybrid Manager AI Factory](/edb-postgres-ai/1.3/hybrid-manager/ai-factory/)

Together, these capabilities enable you to deliver **trusted, governed, Sovereign AI** — with your data, in your databases, under your control.

* * *
