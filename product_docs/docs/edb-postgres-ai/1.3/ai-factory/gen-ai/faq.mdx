---
title: Gen AI Builder FAQ
navTitle: FAQ
description: Practical answers for building with Gen AI Builder in Hybrid Manager — models, knowledge bases, assistants, tools, security, performance, and operations.
prevNext: true
---

This FAQ focuses on Gen AI Builder  inside Hybrid Manager’s AI Factory. It covers common questions about models, knowledge bases, assistants, tools, SDK usage, security, performance, and operations.

Table of contents

- [Typical use cases and patterns](#typical-use-cases-and-patterns)
- [Which models/drivers are supported?](#which-modelsdrivers-are-supported)
- [When to use RAG vs. fine‑tuning?](#when-to-use-rag-vs-fine-tuning)
- [How do I create and update Knowledge Bases?](#how-do-i-create-and-update-knowledge-bases)
- [What are Retrievers and how do I tune them?](#what-are-retrievers-and-how-do-i-tune-them)
- [How do Assistants call Tools and Structures?](#how-do-assistants-call-tools-and-structures)
- [Where does data live and how is access governed?](#where-does-data-live-and-how-is-access-governed)
- [How do I improve latency and control cost?](#how-do-i-improve-latency-and-control-cost)
- [How do I test, observe, and troubleshoot?](#how-do-i-test-observe-and-troubleshoot)
- [Where to find SDK references and examples?](#where-to-find-sdk-references-and-examples)

### Which models/drivers are supported?

Gen AI Builder is driver‑based. You can use private/endpoints or hosted APIs via Prompt Drivers, Embedding Drivers, and Vector Store Drivers.

- Prompt Drivers: OpenAI, Anthropic, Google, and more (see reference: `reference/sdk/drivers/index.mdx` and per‑provider pages)
- Embedding Drivers: OpenAI, Google, NVIDIA NIM, Hugging Face, etc. (`reference/sdk/drivers/embedding-drivers.mdx`)
- Vector Store Drivers: pgvector (Postgres), local, Pinecone, Qdrant, Redis, and others (`reference/sdk/drivers/vector-store-drivers.mdx`)
- NVIDIA NIM: deploy as private endpoints via [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/)

See also: [AI Factory Models](/edb-postgres-ai/1.3/ai-factory/model/) and [deploy NIM containers](../model/deploy-nim-container).

### When to use RAG vs fine‑tuning?

Prefer RAG for living knowledge and governed answers; use fine‑tuning for tone/format/narrow tasks. Many production assistants combine both: retrieve context from [Knowledge Bases](knowledge-bases) and guide responses with [Rulesets](rulesets). For modular pipelines, explore [RAG Engines](reference/sdk/engines).

### How do I create and update Knowledge Bases?

- Create: [Create a Knowledge Base](create-knowledge-base) and configure [Data Sources](data-sources) (Confluence, Google Drive, S3, Web Page, Data Lake, Custom)
- Update: [Manage a Knowledge Base](manage-knowledge-base); re‑sync when source Libraries change
- Storage: embeddings live in Postgres (pgvector) or a configured vector store
- Tuning: choose chunking and metadata that match your retrieval; validate with golden questions

SDK references: [Data Loaders](reference/sdk/data/loaders.mdx), [Embedding Drivers](reference/sdk/drivers/embedding-drivers.mdx), [Vector Store Drivers](reference/sdk/drivers/vector-store-drivers.mdx).

### What are Retrievers and how do I tune them?

Retrievers control how assistants fetch context: target KBs, max tokens, filters, re‑ranking.

- Create: [Create a Retriever](create-retriever)
- Tune: similarity thresholds, top‑K, metadata filters, rerankers
- Advanced: modular [RAG Engines](reference/sdk/engines) with retrieval/rerank/response stages

SDK references: [RAG Engines](reference/sdk/engines), [Rerank Drivers](reference/sdk/drivers/rerank-drivers.mdx).

### How do Assistants call Tools and Structures?

Assistants orchestrate retrieval + generation + actions. Use Tools for external systems, or promote Structures (pipelines/workflows/agents) as callable Tools.

- Build assistants: [Create an Assistant](create-assistant) with [Rulesets](create-ruleset), [Retrievers](create-retriever), and [Tools](create-tool)
- Structures: package logic as a ZIP and deploy [Structures](create-structure); expose as Tool or run standalone
- Memory and threads: see [Threads](threads) and conversation memory drivers

SDK references: [Structures](reference/sdk/structures), [Tools](reference/sdk/tools), [Assistant Drivers](reference/sdk/drivers/assistant-drivers.mdx), [Conversation Memory Drivers](reference/sdk/drivers/conversation-memory-drivers.mdx).

### Where does data live and how is access governed?

- Documents: ingest via [Data Sources](data-sources); store in governed Data Lake or Postgres
- Embeddings/vectors: Postgres pgvector (recommended) or another configured vector store
- Governance: enforce permissions in source systems; restrict tool usage per project; audit retrieval and tool calls with threads/logs

See: [Configure Data Lake](configure-datalake), [Vector Engine](/edb-postgres-ai/1.3/ai-factory/vector-engine/).

### How do I improve latency and control cost?

- Retrieval: reduce top‑K, improve chunking/metadata, use re‑rank selectively
- Generation: choose right model per route; stream responses; batch where safe
- Caching: memoize embeddings, hot retrievals, and tool outputs when possible
- Infra: colocate models and KBs; scale with Model Serving autoscaling

See SDK: [Engines](reference/sdk/engines) and Drivers. See Models: [Model Serving](/edb-postgres-ai/1.3/ai-factory/model/).

### How do I test, observe, and troubleshoot?

- Testing: golden sets, conversation playbooks, SDK unit tests
- Observability: thread logs, assistant/structure run events; optionally export to your observability stack
- Debugging: verify retrieval set first; inspect ruleset changes; re‑run the same structure/assistant with stored inputs

Docs: [Threads](threads), SDK [Structures/observability](reference/sdk/structures/observability.mdx).

### Typical use cases and patterns

- Enterprise knowledge assistants: KB + Retriever + Assistant + Tooling (tickets/CRM)
- Customer support copilots: policy/FAQ KBs + routing + guardrails via Rulesets
- Workflow bots: Structures + Tools for approvals, data enrichment, and reporting
- RAG for analytics: pgvector + Pipelines + Assistant for guided exploration

Explore: [Hybrid KB best practices](hybrid-kb-best-practices), [Quickstart UI](quickstart-customer-service-agent-ui).

### Where to find SDK references and examples?

- SDK overview: [Gen AI Builder SDK](reference/sdk/)
- Data: [Artifacts](reference/sdk/data/artifacts.mdx), [Loaders](reference/sdk/data/loaders.mdx), [Chunkers](reference/sdk/data/chunkers.mdx)
- Drivers: [Prompt/Assistant](reference/sdk/drivers/index.mdx), [Embedding](reference/sdk/drivers/embedding-drivers.mdx), [Vector Stores](reference/sdk/drivers/vector-store-drivers.mdx)
- Structures: [Tasks](reference/sdk/structures/tasks.mdx), [Pipelines](reference/sdk/structures/pipelines.mdx), [Workflows](reference/sdk/structures/workflows.mdx)
- Tools: [Overview](reference/sdk/tools)

See also the product guides: [assistants](assistants), [knowledge bases](knowledge-bases), [retrievers](retrievers), [rulesets](rulesets), [structures](structures), [tools](tools), [threads](threads).
