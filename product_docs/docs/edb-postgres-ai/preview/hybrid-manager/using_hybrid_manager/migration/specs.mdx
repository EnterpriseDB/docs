---
title: Optimizing migration performance
navTitle: Performance considerations
description: Learn about recommended specifications to improve the performance and speed of database migrations using Hybrid Manager.
deepToC: true
redirects:
- /edb-postgres-ai/migration-etl/data-migration-service/specs
---

The EDB Data Migration Service (DMS) is included with Hybrid Manager (HM). You can leverage it to migrate your data from existing databases (Oracle, self-managed Postgres, and so on) to an HM-managed database cluster. EDB DMS supports two migration methods: snapshot and snapshot + streaming, allowing you to migrate your data with minimal-to-no downtime.

## Understanding migration workloads in HM

The EDB DMS runs within the same Kubernetes environment where your HM is deployed (on-premises, AWS, Red Hat OpenShift, and Google Cloud). This means that most of the workloads required for migration operations are managed and optimized by your Kubernetes cluster.

Generally, you don't need to extensively fine-tune resources, as your Kubernetes environment meeting the general requirements for running HM helps with a smooth migration. However, for large datasets, optimizing specific components can significantly accelerate the process.

The key components to consider for resource allocation are:

-   **EDB DMS Agent in reader mode:** This component can run on the same machine as the source database or on an auxiliary machine that can connect to the source database and to HM.

-   **Destination database cluster:** This can be the database managed by HM or a different external self-managed database. However, we'll focus on an HM-managed database. This is where your data will reside.

-   **EDB DMS Agent in writer mode:** This component is required only if your migration destination is an external (self-managed) database cluster and it runs on that database's host machine.

Whether you perform a snapshot or snapshot + streaming migration also affects performance differently:

-   **Snapshot migrations:** They primarily focus on efficiently transferring a large volume of existing data from a source database to the destination. Performance for these is heavily influenced by total data size and sustained disk I/O.

-   **Snapshot + streaming migrations:** They first transfer a snapshot of existing data and then continuously stream ongoing changes (transactions) from the source to the destination. Performance here is driven by the sustained transaction rate (TPS) and the ability to keep up with the source's write activity.

## Optimizing migration performance for large datasets

HM and DMS are designed to handle resource usage. For datasets smaller than 100 GB, they're configured to perform fast migrations without further tuning. However, for datasets larger than 100 GB, a few targeted alterations can lead to significantly better performance and quicker migrations.

### Tuning destination database performance

Optimizing the destination database cluster (whether an HM-managed database or a self-managed database) provides the most significant performance benefits from resource tuning.

!!!note

   These recommendations are based on current testing and are subject to change. We work continuously to improve migration performance and reduce migration times.

<br/>

#### Storage recommendations

During a migration, storage IOPS can peak at 2000, with an average throughput of roughly 300 MB/s and peaks up to 350 MB/s. To accommodate these demands:

-   Separate WAL and data volumes. Aim for storage volumes that can handle a minimum of 2500-3000 IOPS and at least 200-250 MB/s of throughput for both your data and write-ahead log (WAL) volumes. We highly recommend using separate volumes for WAL and data for optimal performance.

-   Unified storage and WAL volume. A unified storage and WAL volume can adversely affect performance. For example, using a single volume with 3000 IOPS and 125 MB/s throughput can increase migration time by over 40%. If you must use a unified storage and WAL volume, we recommend a throughput of 300-400 MB/s. Keep in mind that if the WAL becomes full, the migration will fail.

<details><summary>How to adjust this</summary>

For HM-managed database clusters:

-   Adjust WAL and data volume allocation by [editing](../../using_hybrid_manager/cluster_management/manage-clusters/edit-clusters/#editing-a-cluster) your cluster's storage.

-   By default, HM-managed clusters use separate volumes for data and WAL volumes, but if you clear the **Use a separate storage volume for Write-Ahead Logs** option while creating the cluster, you can't enable this setting later.

-   Volume speeds (IOPS or throughput) are determined by the cluster's underlying infrastructure. When migrating to an HM-managed database cluster, the specific storage classes available for your cluster, and their associated IOPS and throughput characteristics, are determined by your HM administrator (and the underlying cloud or on-premise environment). Therefore, review the storage options available for your clusters and work with your HM administrators to ensure the selected storage meets the recommended performance criteria. For more information on cloud provider infrastructure provisioning, see [Request Amazon EBS volume modifications](https://docs.aws.amazon.com/ebs/latest/userguide/requesting-ebs-volume-modifications.html) or [Google Cloud - About Persistent Disk performance](https://cloud.google.com/compute/docs/disks/performance).

</details>

<br/>

#### Memory recommendations

While 5 GB of memory is sufficient, a larger amount facilitates optimal performance during a migration. Use at least 10 GB of memory for the destination database.

<details><summary>How to adjust this</summary>

For HM-managed database clusters:

-   Adjust memory allocation by [editing](../../using_hybrid_manager/cluster_management/manage-clusters/edit-clusters/#editing-a-cluster) your cluster's instance size (under **Cluster Settings**).

-   You can also adjust the `shared_buffers`, `effective_cache_size`, and `wal_buffers` parameters in **DB Configuration**.

</details>

<br/>

#### CPU recommendations

The destination database cluster needs at least 4 CPU cores. A lower core count will negatively impact migration performance.

<details><summary>How to adjust this</summary>

For HM-managed database clusters, adjust CPU allocation by [editing](../../using_hybrid_manager/cluster_management/manage-clusters/edit-clusters/#editing-a-cluster) your cluster's instance size.

</details>

<br/>

!!!note

   Apply these optimizations during the migration process. After the migration is complete, you can readjust these values as needed based on your ongoing workload requirements.

Extensive testing has shown that the biggest factor affecting migration performance is volume speed (IOPS and throughput). While decreasing CPU below recommendations can reduce performance, it's not nearly to the degree that low IOPS and throughput for storage will. Halving the storage throughput can increase migration time by over 40%, whereas halving the CPU count to 2 cores might increase it by 10-15%. These recommendations are designed to yield the best migration performance. Using lower values may still result in successful migrations but at a slower speed.

#### WAL configuration

WAL checkpoints are one of the most resource-intensive tasks during a data migration. By default, `max_wal_size` is set to 1 GB, which means that a checkpoint is made for every GB written to the WAL file. During a migration, this can result in checkpoints occurring every 30-60 seconds, putting a substantial load on the destination database.

By increasing the `max_wal_size` during the migration, you can reduce the load on the destination database. Our tests found that a larger `max_wal_size` doesn't impact migration speed. For instance, a migration with a 20 GB `max_wal_size` takes the same amount of time as one with a 1 GB setting. However, the migration using the 20 GB setting consumes approximately 50% fewer resources.

Given that WAL logging ensures that all migrated data is properly saved via checkpoints, disabling `max_wal_size` isn't a viable option for most EDB databases, as several critical features depend on it.

<details><summary>How to adjust this</summary>

For HM-managed database clusters:

Adjust WAL configurations by [editing](../../using_hybrid_manager/cluster_management/manage-clusters/edit-clusters/#editing-a-cluster) your cluster's DB configuration. Search for the `max_wal_size` parameter, provide the new size in MB, and save to apply the configuration.

</details>

<br/>

### Tuning EBD DMS Agent performance

Optimal performance for the EDB DMS Agents is achieved when the host machines where these components are installed follow these specifications.

#### EDB DMS Agent in reader mode

**CPU:** 3 CPU cores

**Memory:** 4 GB

#### EDB DMS Agent in writer mode

**CPU:** 2 CPU cores

**Memory:** 2.5 GB

### Shared host considerations

For optimal migration performance, carefully consider resource allocation when EDB DMS components and source database run on the same machine/host.

-   **DMS agents share a host:** If both agents are on the same machine, one in reader mode and a second one in writer mode, provision combined resources (at least 5 CPU cores and 6.5 GB memory).

-   **DMS component and source database share a host:** If a DMS agent is on the same host as the source database, ensure the host's resources are significantly increased to accommodate both the database's operational workload and the migration's demands.


## Optimizing migration performance for bulk migrations

HM and DMS are designed to handle multiple concurrent migrations. However, when performing bulk migrations (that is, high volumes of concurrent or large migrations), increasing the number of Kafka brokers can significantly enhance data migration performance.

!!!Tip
If you observe high CPU and memory use on the Kafka brokers during a data migration, the default DMS configuration is insufficient for bulk migration. Use [Grafana](/edb-postgres-ai/current/hybrid-manager/using_hybrid_manager/monitoring/monitoring_grafana/) to check the resource usage for the Kafka pods in the `transporter-kafka-operator` namespace.
!!!

### Change Kafka broker count

1.  Connect to your HM Kubernetes cluster using your `kubeconfig` file. (The specific command varies by cloud environment.)

    ```shell
    # AWS example:
    aws eks update-kubeconfig --name eks-1234567890-main --region eu-west-2 --profile app-dev
    ```

1.  Before making any changes, check if a Kafka cluster was already provisioned. This is the case if you previously ran a data migration.

    ```shell
    kubectl get kafka -n transporter-kafka-operator
    ```

1.  Remove existing migrations and Kafka clusters. If the command output lists a Kafka resource, you must first delete all migrations to start with a clean state.

    !!!warning
    The Kafka cluster is generally deployed to support all data migration activities across the entire HM instance. Removing the Kafka resource will halt all active data migrations, regardless of the project. Coordinate this change with other users.
    !!!

    In the HM console, delete all active and completed migrations in your project under **Migrate > Migrations**.

    <details><summary>For testing environments</summary>

    For testing or development environments, you can also remove the Kafka cluster using `kubectl`. However, we recommend this method only in non-production environments, as it deletes all resources other users may be using.

    ```shell
    kubectl -n transporter-kafka-operator delete $(kubectl get strimzi -o name -n transporter-kafka-operator)
    ```

    </details>

    <br/>

1.  Get the name of the ConfigMap in the `transporter-dp-provisioner` namespace:

    ```shell
    kubectl get cm -n transporter-dp-provisioner
    ```

1.  Open the ConfigMap for editing. Replace `<config_map_name>` with the name found in the previous step:

    ```shell
    kubectl edit cm transporter-dp-provisioner-<config_map_name> -n transporter-dp-provisioner
    ```

1.  Locate the `broker_number` field in the ConfigMap and change the value to your desired number of Kafka brokers (for example, `broker_number: 3`).

1.  Save the ConfigMap. The new configuration is reloaded and applied within about 10 seconds.

1.  You can start new data migrations that will use the changed broker capacity.
