---
title: Hybrid Manager disaster recovery
navTitle: Disaster recovery
description: Provides a step-by-step guide to perform a disaster recovery of your HM instance and Postgres clusters using Velero.
deepToC: true
---

The DR procedure is defined as the series of manual steps that you need to take from the deployment of a new HM instance to the manual recovery of your Postgres clusters using the restore procedure.

!!! Warning
    You must constantly test and update your organization's DR procedure for it to remain valid.

## Before you start

Before starting the DR procedure, ensure you have made yourself familiar with:

- [Best practices](./hadr)
- [Backup considerations](./backup_considerations)

## Prerequisites 

- A new HM instance deployed and running. It must be running the same version as the old one.

  - If you have configured [multi-DC](/edb-postgres-ai/preview/hybrid-manager/using_hybrid_manager/multi-dc/) in your old HM instance, ensure the same locations (`locations.beacon.enterprisedb.com` custom resource) are available in the new one. `locations` is currently an internal resource created during install and isn't available in the HM console. `managed-devspatcher` is the default value.

  - The container images used to build the clusters in the old HM instance are available to the new one.

- [Install the Velero CLI](https://velero.io/docs/v1.17/velero-install/).

- [Install the jq utility](https://jqlang.org/download/).

## 1. Make backups available in the new HM instance

The first step ensures the backups of the unavailable HM instance (“old backups”) are reachable from the new HM instance by copying the backups of the damaged HM instance to the linked storage of the new HM instance. 

1.  Obtain the name of the old and new buckets, the ID of the old backup, and the region of the new attached bucket and store these parameters in environment variables:

    ```shell
    export OLD_BUCKET=<old_bucket>
    export OLD_BACKUP_ID=<old_environment_internal_backup_id>
    export NEW_BUCKET=<new_bucket>
    export NEW_REGION=<region_of_the_new_bucket>
    ```

    <details><summary>How do I obtain the old bucket values?</summary> 

    To obtain the old bucket values: 
    
    1. Go to the console/dashboard of your CSP > buckets. 
    1. Find and select the bucket linked to the backups of your old HM instance.
    1. Browse through to the `edb-internal-backups` folder. Inside that folder you will find a subfolder with the backup ID, e.g. 4be7a1c8c9f0.

    </details> 

    <br/>

    <details><summary>EKS Example</summary> 

    This is an example for setting the environment variables for an HM instance deployed on EKS:
    
    ```shell
    export OLD_BUCKET=eks-1105143903-2511-edb-postgres
    export OLD_BACKUP_ID=a7462dbc7106
    export NEW_BUCKET=eks-1105155418-2511-edb-postgres
    export NEW_REGION=eu-west-3
    ```

    </details> 

    <br/>

1.  To copy the data from the old bucket to the new bucket, you first need to locate and note the names of the source and target folders. You need to copy the following folders and their content:

    - **Internal EDB backups folder** &mdash; The internal backups folder in the old bucket `edb-internal-backups/<random-string>` is different in the new HM instance, as it will have a different `<random-string>`.

    - **Postgres clusters backups folder** &mdash; `customer-pg-backups`.

    - **Folder corresponding to any defined custom storage locations** &mdash; if you have custom storage locations defined in the old HM instance, copy the corresponding folders as well.

1.  Copy the old backups to the new bucket using your preferred tools. Here are some examples using cloud service provider CLIs to move data between buckets:

    <TabContainer syncKey="CSP">
    <Tab title="AWS">

    ```shell
    aws s3 cp --recursive s3://${OLD_BUCKET}/edb-internal-backups/${OLD_BACKUP_ID} s3://${NEW_BUCKET}/edb-internal-backups
    aws s3 cp --recursive s3://${OLD_BUCKET}/customer-pg-backups s3://${NEW_BUCKET}/customer-pg-backups
    ```

    </Tab>

    <Tab title="GCP">

    ```shell
    gcloud storage cp gs://${OLD_BUCKET}/edb-internal-backups/${OLD_BACKUP_ID} gs://${NEW_BUCKET}/edb-internal-backups --recursive
    gcloud storage cp gs://${OLD_BUCKET}/customer-pg-backups gs://${NEW_BUCKET}/customer-pg-backups --recursive
    ```

    </Tab>
    </TabContainer>
    
    [Also, in these examples we don't specify how to move the custom storage locations, should we add that as an optional step?]: #

1.  Load the backups you just copied to your new HM instance by creating a new custom resource definition and applying it to the new HM instance:

    <TabContainer syncKey="CSP">
    <Tab title="AWS">

    ```yaml
    kubectl apply -f - <<EOF
    apiVersion: velero.io/v1
    kind: BackupStorageLocation
    metadata:
      annotations:
        appliance.enterprisedb.com/s3-prefixes: edb-internal-backups/velero
      labels:
        appliance.enterprisedb.com/storage-credentials: bound
      name: recovery
      namespace: velero
    spec:
      accessMode: ReadOnly
      config:
        insecureSkipTLSVerify: "false"
        region: ${NEW_REGION}
        s3ForcePathStyle: "true"
      default: false
      objectStorage:
        bucket: ${NEW_BUCKET}
        prefix: edb-internal-backups/velero
      provider: aws
    EOF
    ```

    </Tab>

    <Tab title="GCP">

    ```yaml
    kubectl apply -f - <<EOF
    apiVersion: velero.io/v1
    kind: BackupStorageLocation
    metadata:
      annotations:
        appliance.enterprisedb.com/s3-prefixes: edb-internal-backups/velero
      labels:
        appliance.enterprisedb.com/storage-credentials: bound
      name: recovery
      namespace: velero
    spec:
      accessMode: ReadOnly
      credential:
        key: gcp
        name: gcs-credentials
      default: false
      objectStorage:
        bucket: ${NEW_BUCKET}
        prefix: edb-internal-backups/velero
      provider: gcp
    EOF
    ```

    </Tab>
    </TabContainer>

1.  Confirm that the new storage location is available:

    ```shell
    velero get backup-locations
    ```
    If the status is not `Available`, check the Velero pod logs for permission errors on the S3 bucket.

1.  Confirm that the backups are available as well: 

    ```shell
    velero get backups --selector velero.io/storage-location=recovery
    ```

1.  Choose the backup you want to restore from. You can have multiple backups available, so choose the one that best suits your needs, e.g. the most recent backup before the disaster happened. Note the Velero backup name, as well as the date and time (UTC), as both are required for a restore, for example: 

    ```shell
    NAME                                      STATUS      ERRORS   WARNINGS   CREATED                         EXPIRES   STORAGE LOCATION   SELECTOR  
    velero-backup-kube-state-**20241216154403**   Completed   0        0          2024-12-16 16:44:03 \+0100 CET   5d        recovery           \<none\>
    ```

    !!! Note
        The timestamp value is referred to as the *recovery date* in the instructions that follow.

1.  (Optional) If you were using HM to manage AI workloads, e.g. with the GenAI Builder, also copy the object store files and CORS configuration from the old bucket to the new one:

    ```shell
    export OLD_BUCKET_DATALAKE=<old bucket>
    export NEW_BUCKET_DATALAKE=<new bucket>
    ```

    <TabContainer syncKey="CSP">
    <Tab title="AWS">

    ```shell
    # Copy data lake objects from old bucket to new bucket
    aws s3 cp --recursive s3://${OLD_BUCKET_DATALAKE}/ s3://${NEW_BUCKET_DATALAKE}/
    # Copy CORS configuration from old bucket to new bucket
    aws s3api get-bucket-cors --bucket ${OLD_BUCKET_DATALAKE} --output json > cors-config.json
    aws s3api put-bucket-cors --bucket ${NEW_BUCKET_DATALAKE} --cors-configuration file://cors-config.json
    ```

    </Tab>

    <Tab title="GCP">

    ```shell
    # Copy data lake objects from old bucket to new bucket
    gcloud storage cp "gs://${OLD_BUCKET_DATALAKE}/*" gs://${NEW_BUCKET_DATALAKE}/ --recursive
    # Copy CORS configuration from old bucket to new bucket
    gcloud storage buckets describe gs://rhos-uat-griptape-datalake --format="json" | jq .cors_config > cors-config.json
    gcloud storage buckets update gs://${NEW_BUCKET_DATALAKE} --cors-file=cors-config.json
    ```

    </Tab>
    </TabContainer>

## 2. Recovery steps

### Restore HM-internal databases

After the old backups are available, you can restore the HM-internal databases. These are back-end services used by HM, and are required to fully restore the HM instance. Depending on the HM version you are using, and on the installation scenario you have deployed, the list of databases may vary.

#### Identify the internal databases to restore

First, identify the databases you need to restore. You can look this up by listing all HM-internal database clusters that exist in the new HM instance (assuming that you used the same installation configuration for the new HM instance) and excluding those that start with `p-` (these are Postgres database clusters) and the `stats-collector-db` (not required to restore HM functionality):

```shell
kubectl get clusters.postgresql.k8s.enterprisedb.io -A -o json | jq -rc '.items[].metadata | select((.name | test("^p-") | not) and (.name != "stats-collector-db")) | .name'
```

The output will be a list of HM-internal database clusters to restore, for example:

```shell
mp-epas-16
mp-epas-17
mp-epas-18
transporter-db
app-db
beacondb
resourcedb
vectordb
```

!!!important
You list may differ based on the HM version and installation scenario. It may look much shorter. 
!!!

#### Restore each HM-internal database

Now, for each of the identified HM-internal database clusters, perform the following steps, one after the other:

1.  Save the HM-internal database cluster manifest to a yaml file: 

    ```shell
    kubectl get <cluster-name> -o yaml > <cluster-name>.yaml
    ```

    Where `<cluster-name>` is the name of the HM-internal database cluster to restore, e.g. `beacondb`.

1.  Edit the manifest yaml file, so the HM-internal database cluster is created from the backups:  

    - Replace the **init** section in bootstrap with a **recovery** section:  

      ```yaml
      recovery:  
        database: <database_name_as_in_the_init_section>  
        owner: <owner_name_as_in_the_init_section>  
        source: <cluster-name>  
        secret:  
          name: <secret_name_as_in_the_init_section>  
        recoveryTarget:  
          targetTime: "${BACKUP_TIMESTAMP}"  
      ```

      [The backup timestamp env variable is actually set up much later in the procedure, so I wonder if we should reorder things? Or just have them set up the timstamp manually here?]: #

    - Add the following section:  

      ```yaml
      externalClusters:  
       - barmanObjectStore:  
          destinationPath:  S3://${NEW_BUCKET}/edb-internal-backups/databases  
          s3Credentials:  
            inheritFromIAMRole: true  
          wal:  
            maxParallel: 8  
        name: <cluster-name>  
      ```

    - Add the following prefix to the `appliance.enterprisedb.com/s3-prefixes` annotation of the `inheritedMetdata` section (the list is comma separated): 

      [This used to be `edb-internal-backups/<old-backups-random-string>/databases/<db-name>`, please check below?]: #

      ```yaml
      edb-internal-backups/<old-backups-random-string>/databases/<cluster-name>  
      ```

1.  Delete the HM-internal database cluster that was created during installation of the new HM instance to make room for the HM-internal database cluster that will be recovered from the backup:

    ```shell
    kubectl delete cluster <cluster-name>  
    ```

1.  Clean the backup area that was created during the installation of the new HM instance to avoid confusion with the old backups that you want to restore:

    <TabContainer syncKey="CSP">
    <Tab title="AWS">

    ```shell
    aws s3 rm s3://${NEW_BUCKET}/edb-internal-backups/databases/<cluster-name> \ --recursive
    ```

    </Tab>

    <Tab title="GCP">

    ```shell
    gcloud storage rm gs://${NEW_BUCKET}/edb-internal-backups/databases/<cluster-name> \ --recursive
    ```

    </Tab>
    </TabContainer>

1.  Apply the yaml file for the cluster to be re-created:

    ```shell
    kubectl apply -f <cluster-name>.yaml
    ```

    You can monitor the restore progress using `kubectl get clusters -A`.

Now repeat the above steps for each HM-internal database cluster you need to restore.

#### Restart HM services

[am I right in assuming that this is a one-time step after all HM-internal databases are restored?]: #

After the cluster is successfully restored and in a healthy state, restart the `accm-server` in the namespace `upm-beaco-ff-base` to make sure the HM console is available again: 

```shell
kubectl delete pods $(kubectl get pods -n upm-beaco-ff-base | grep '^accm-server' | awk '{print $1}') -n upm-beaco-ff-base
```

At this point, the HM console on the new cluster is available again.

### Configure the Velero plugin

The Velero plugin helps restore the Kubernetes resources in a correct state, so only the custom managed storage locations are restored. The Postgres clusters resources are restored as deleted, so you can later restore data as desired.

1.  List the available backups in the new HM instance and choose the one you want to restore from:

    ```shell
    velero get backups -o json --selector velero.io/storage-location=recovery \
    | jq -rc '(["Name", "Timestamp"]), (.items // [.] | .[] | [.metadata.name, .metadata.creationTimestamp]) | @tsv' \
    | column -t -s "$(printf '\t')"
    ```

1.  Select a backup from this list and export the following environment variables with the corresponding values: 

    ```shell
    export BACKUP_TIMESTAMP=<recovery date in YYYY–MM-DDTHH:MM:SSZ format>
    export BACKUP_NAME=<selected name>
    # These environment variables should already be available in your terminal
    export OLD_BUCKET=<old bucket name>
    export NEW_BUCKET=<new bucket name>
    ```

1.  Create and apply a `ConfigMap` to configure the Velero plugin:

    ```yaml
    kubectl apply -f - <<EOF
    apiVersion: v1  
    kind: ConfigMap  
    metadata:  
      name: velero-plugin-for-edbpgai  
      namespace: velero  
      labels:  
        velero.io/plugin-config: ""  
        enterprisedb.io/edbpgai-plugin: RestoreItemAction  
    data:  
      # configure disaster recovery mode, so restored items are transformed as needed  
      drMode: "true"  
      # configure a date corresponding to the velero backup date. Note the format!  
      drDate: "${BACKUP_TIMESTAMP}"  
      # old and new buckets for internal custom storage locations  
      oldBucket: ${OLD_BUCKET}  
      newBucket: ${NEW_BUCKET}
    EOF
    ```

### Restore resources

1.  Restore custom managed storage locations by applying the following Velero:

    ```yaml
    kubectl apply -f - <<EOF
    apiVersion: velero.io/v1  
    kind: Restore  
    metadata:  
      name: restore-1-storagelocations  
      namespace: velero  
    spec:  
      backupName: "${BACKUP_NAME}" 
      includedResources:  
       - storagelocations.biganimal.enterprisedb.com  
      includeClusterResources: true  
      labelSelector:  
        matchLabels:  
          biganimal.enterprisedb.io/reserved-by-biganimal: "false"
    EOF
    ```

1.  Configure and apply the following Velero restore resource manifest to restore the cluster wrappers:

    ```yaml
    kubectl apply -f - <<EOF
    apiVersion: velero.io/v1  
    kind: Restore  
    metadata:  
      name: restore-2-clusterwrappers  
      namespace: velero  
    spec:  
      backupName: "${BACKUP_NAME}" 
      includedResources:  
       - clusterwrappers.beacon.enterprisedb.com  
      restoreStatus:  
        includedResources:  
         - clusterwrappers.beacon.enterprisedb.com
    EOF
    ```

1.  Monitor the restore progress. You must wait until `clusterwrappers` is restored first, because the following custom resources (CR) depend on it. If the corresponding `clusterwrapper` isn't found, HM could delete the other CRs.

    ```shell
    velero get restore restore-2-clusterwrappers
    ```

1.  After the cluster wrappers are restored, configure and apply the following Velero resource manifest to restore the backup wrappers:

    ```yaml
    kubectl apply -f - <<EOF
    apiVersion: velero.io/v1  
    kind: Restore  
    metadata:  
      name: restore-3-backupwrappers  
      namespace: velero  
    spec:   
      backupName: "${BACKUP_NAME}" 
      includedResources:  
       - backupwrappers.beacon.enterprisedb.com  
      restoreStatus:  
        includedResources:  
         - backupwrappers.beacon.enterprisedb.com
    EOF
    ```

1.  Configure and apply the following Velero resource manifest to restore Griptape, Lakekeeper and Dex secrets:

    ```shell
    kubectl apply -f - <<EOF
    apiVersion: velero.io/v1
    kind: Restore
    metadata:
      name: restore-4-required-secrets
      namespace: velero
    spec:
      backupName: "${BACKUP_NAME}"
      includedNamespaces:
      - upm-griptape
      - upm-lakekeeper
      - upm-dex
      includedResources:
      - secrets
      includeClusterResources: false
    EOF
    ```

1.  (Optional) If you are running AI workloads, configure and apply the following Velero restore resource manifest to restore kserve resources:

    ```shell
    kubectl apply -f - <<EOF
    apiVersion: velero.io/v1
    kind: Restore
    metadata:
      name: restore-5-kservecrs
      namespace: velero
    spec:
      backupName: "${BACKUP_NAME}"
      includedResources:
      - clusterservingruntimes.serving.kserve.io
      - inferenceservices.serving.kserve.io
    EOF
    ```

1.  Monitor all restores and wait for them to be completed:

    ```shell
    velero get restores
    ```

## 3. Restore Postgres clusters

The cluster metadata has been restored, but the HM-managed Postgres clusters must be manually re-provisioned to link back to your data.

1.  In the HM console, navigate to the databases section. You will see your original clusters listed with a status of **Deleted**.

1.  Select the desired cluster and locate the **Restore** button. Follow the prompts to create a new cluster.
    During this process, the system will use your previous backups to populate the new instance.

1.  After provisioning is complete, verify that the data matches your original state.

The same procedure can be applied to restore any Postgres cluster you had configured on a secondary location.

!!!Note
AI components (such as the GenAI Builder UI in the Launchpad section) will automatically reappear in the HM console once the restore is initiated. Due to the large size of container images and profiles, synchronization may take some time.
!!!

## 4. Validate the restore

The restoration procedure is now complete. To ensure a successful recovery, we recommend checking for data integrity. Log in to the newly provisioned Postgres cluster and run a few test queries to confirm your data is current and accessible.

!!!tip
If you are performing this as part of a DR drill, internally document the total "Time to Restore" (TTR) for both the database and AI layers to help refine your recovery objectives (RTO).
!!!
