---
title: 'Managing EDB Postgres Distributed databases'
originalFilePath: 'src/using_pgd.md'
---

As described in the [architecture document](architecture.md),
EDB Postgres Distributed for Kubernetes is an operator created to deploy
Postgres Distributed (PGD) databases.
It provides an alternative over deployment with TPA, and by leveraging the
Kubernetes ecosystem, it can offer self-healing and declarative control.
The operator is also responsible of the backup and restore operations
(see the [backup](backup.md) document.)

However, many of the operations and control of PGD clusters are not
managed by the operator.
The pods created by EDB Postgres Distributed for Kubernetes come with
[PGD CLI](https://www.enterprisedb.com/docs/pgd/latest/cli/) installed, and
this is the tool that can be used, for example, to execute a switchover.

## PGD CLI

!!! Warning
    The PGD CLI should not be used to create/delete resources. For example,
    the `create-proxy`, `delete-proxy` commands should be avoided.
    Provisioning of resources is under the control of the operator, and manual
    creation/deletion is not supported.

As an example, let's execute a switchover command.

It is recommendable to use the PGD CLI from proxy pods. Let's find them.
You can get a pod listing for your cluster:

```shell
kubectl get pods -n my-namespace

NAME                   READY   STATUS    RESTARTS      AGE
location-a-1-1         1/1     Running   0             2h
location-a-2-1         1/1     Running   0             2h
location-a-3-1         1/1     Running   0             2h
location-a-proxy-0     1/1     Running   0             2h
location-a-proxy-1     1/1     Running   0             2h
```

The proxy nodes have `proxy` in the name. Let's choose one and get a command
prompt in it:

```shell
kubectl exec -n my-namespace -ti location-a-proxy-0 -- bash
```

You should now have a bash session open with the proxy pod. The `pgd` command
is available:

```shell
pgd

Available Commands:
  check-health       Checks the health of the EDB Postgres Distributed cluster.
  <- snipped ->
  switchover         Switches over to new write leader.
  <- snipped ->
```

You can easily move your way through getting the information needed for the
switchover:

```shell
pgd switchover --help

  $ pgd switchover --group-name group_a --node-name bdr-a1
  switchover is complete
```

```shell
pgd show-groups

Group      Group ID   Type   Parent Group Location Raft Routing Write Leader 
-----      --------   ----   ------------ -------- ---- ------- ------------ 
world      3239291720 global                       true true    location-a-2 
location-a 2135079751 data   world                 true true    location-a-1 
```

```shell
pgd show-nodes 
Node         Node ID    Group      Type Current State Target State Status Seq ID 
----         -------    -----      ---- ------------- ------------ ------ ------ 
location-a-1 3165289849 location-a data ACTIVE        ACTIVE       Up     1      
location-a-2 3266498453 location-a data ACTIVE        ACTIVE       Up     2      
location-a-3 1403922770 location-a data ACTIVE        ACTIVE       Up     3     
```

## Accessing the database

In the [use cases document](use_cases.md) you can find a discussion on using the
database within the Kubernetes cluster vs. from outside, and in the
[connectivity document](connectivity.md), you can find a discussion on services,
which is relevant for accessing the database from applications.

However you implement your system, your applications should use the proxy
service to connect, in order to reap the benefits of Postgres Distributed, and
of the increased self-healing capabilities added by the EDB Postgres Distributed
for Kubernetes operator.

!!! Important
    Note that, as per the EDB Postgres for Kubernetes defaults, data nodes are
    created with a database called `app`, owned by a user named `app`, in
    contrast to the `bdrdb` database you'll find in the EDB Postgres
    Distributed documentation. This
    is configurable by the user, in the `cnp` section of the manifest.
    See the [EDB Postgres for Kubernetes bootstrapping document](https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/bootstrap/)
    for reference.

You may, however, want access to your PGD data nodes for administrative tasks,
using the `psql` CLI.

As we did in the previous section on using the PGD CLI, we can get a pod listing
for our PGD cluster, and `kubectl exec` into a data node:

```shell
kubectl exec -n my-namespace -ti location-a-1-1 -- psql
```

In the familiar territory of `psql`, you should remember that the default
created database is named `app` (see warning above).

```terminal
postgres=# \c app
You are now connected to database "app" as user "postgres".
app=# \x
Expanded display is on.
app=# select * from bdr.node_summary;
-[ RECORD 1 ]---------------------------------------
node_name              | location-a-1
node_group_name        | location-a
interface_connstr      | host=location-a-1-node user=streaming_replica sslmode=verify-ca port=5432 sslkey=/controller/certificates/streaming_replica.key sslcert=/controller/certificates/streaming_replica.crt sslrootcert=/controller/certificates/server-ca.crt application_name=location-a-1 dbname=app
peer_state_name        | ACTIVE
peer_target_state_name | ACTIVE

<- snipped ->
```

For your applications, of course, you should use the non-privileged role (`app`
by default).

You will need the user credentials, which are stored in a Kubernetes secret:

```shell
kubectl get secrets 

NAME                     TYPE                       DATA   AGE
<- snipped ->
location-a-app           kubernetes.io/basic-auth   2      2h
```

This secret contains the username and password needed for the postgres DSN,
encoded in base64:

```shell
kubectl get secrets location-a-app -o yaml

apiVersion: v1
data:
  password: <base64-encoded-password>
  username: <base64-encoded-username>
kind: Secret
metadata:
  creationTimestamp: <timestamp>
  labels:

<- snipped ->
```
