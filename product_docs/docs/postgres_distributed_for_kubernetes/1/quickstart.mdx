---
title: 'Quickstart'
originalFilePath: 'src/quickstart.md'
---

This section describes how to test an EDB Postgres Distributed (PGD) cluster on your
laptop/computer using EDB Postgres Distributed for Kubernetes (PG4K-PGD)
on a single local
Kubernetes cluster built with [Kind](https://kind.sigs.k8s.io/).

!!! Warning
    The instructions contained in this section are for demonstration,
    testing, and practice purposes only and must not be used in production.

By following the instructions on this page you should be able to start an EDB Postgres Distributed
cluster on your local Kubernetes installation and experiment with it.

!!! Important
    Make sure that you have `kubectl` installed on your machine in order
    to connect to the Kubernetes cluster. Please follow the Kubernetes documentation
    on [how to install `kubectl`](https://kubernetes.io/docs/tasks/tools/install-kubectl/).

## Part 1 - Setup the local Kubernetes playground

This section is about installing Kind, a tool for running local Kubernetes
clusters using Docker container "nodes" (Kind stands for "Kubernetes IN Docker"
indeed).
If you already have access to a Kubernetes cluster, you may skip to the next
section.

Install `kind` on your environment following the instructions in the [Kind Quickstart](https://kind.sigs.k8s.io/docs/user/quick-start),
then create a Kubernetes cluster with:

```sh
kind create cluster --name pgd
```

<!--
TODO: Shall we suggest creating different nodes?
-->

## Part 2 - Install EDB Postgres Distributed for Kubernetes

Now that you have a Kubernetes installation up and running on your laptop, you
can proceed with the installation of EDB Postgres Distributed for Kubernetes.

Please refer to the ["Installation"](installation_upgrade.md) section and then
proceed with the deployment of a PGD cluster.

## Part 3 - Deploy a PGD cluster

As with any other deployment in Kubernetes, to deploy a PGD cluster you need to
apply a configuration file that defines your desired `PGDGroup` resources that
make up a PGD cluster.

Some sample files are included (see [Examples of configuration](samples.md)). The
[flexible_3regions.yaml](../samples/flexible_3regions.yaml) manifest
contains the definition of a PGD cluster with 2 Data Groups and a global
witness node spread across 3 regions. Each Data Group consists of 2 data nodes
and a local witness node.

!!! Note "There's more"
    For more detailed information about the available options, please refer
    to the ["API Reference" section](api_reference.md).

You can deploy the `flexible-3-regions` example by saving it first and running:

```sh
kubectl apply -f flexible_3regions.yaml
```

You can check that the pods are being created with the `get pods` command:

```sh
kubectl get pods
```

The pods are being created as part of PGD nodes, and as described in the
[architecture document](architecture.md), they are implemented on top
of PG4K Clusters.

We can list the clusters then, which will give us the PGD nodes:

```sh
$ kubectl get clusters 
NAME         AGE     INSTANCES   READY   STATUS                     PRIMARY
region-a-1   2m50s   1           1       Cluster in healthy state   region-a-1-1
region-a-2   118s    1           1       Cluster in healthy state   region-a-2-1
region-a-3   91s     1           1       Cluster in healthy state   region-a-3-1
…
…
```

Ultimately, the PGD nodes are created as part of the PGD groups
that make up our PGD cluster.

```sh
$ kubectl get pgdgroups
NAME       DATA INSTANCES   WITNESS INSTANCES   PHASE                AGE
region-a   2                1                   PGDGroup - Healthy   4m50s
region-b   2                1                   PGDGroup - Healthy   4m50s
region-c   0                1                   PGDGroup - Healthy   4m50s
```

Notice how the region-c group is only a witness node.