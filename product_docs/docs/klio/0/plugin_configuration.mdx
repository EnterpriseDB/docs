---
title: The Klio Plugin
originalFilePath: >-
  https://github.com/EnterpriseDB/klio/blob/main/docs/documentation/web//versioned_docs/version-0.0.10/plugin_configuration.md
sidebar_position: 6
editTarget: originalFilePath

---

The Klio plugin for CloudNativePG allows you to leverage the backup and WAL
streaming capabilities of Klio for your PostgreSQL clusters managed by
CloudNativePG. It will add two containers to each PostgreSQL instance pod:

-   A `klio-plugin` container that handles backup creation and management
-   A `klio-wal` container that streams WAL files to the Klio server in real-time

## Configuration

The Klio plugin integrates with CloudNativePG through the CNPG-I (CloudNativePG
Interface) specification, enabling Klio to manage backups and WAL streaming for
your PostgreSQL clusters. To use Klio with a CloudNativePG cluster, you need to:

1.  Create a `PluginConfiguration` resource that defines how to connect to the
    Klio server
2.  Reference the plugin in your `Cluster` resource specification

## Prerequisites

Before configuring a cluster to use the Klio plugin, ensure you have:

-   A running Klio `Server` resource deployed in your namespace
-   Client credentials (username and password) stored in a Kubernetes Secret
-   The server's TLS certificate available in a Secret

## Creating a PluginConfiguration resource

The `PluginConfiguration` custom resource defines how the Klio plugin connects
to and communicates with the Klio server. This resource contains connection
details, authentication credentials, and optional configuration for metrics,
profiling, and backup retention policies.

### Basic example

Here's a minimal `PluginConfiguration` example:

```yaml
apiVersion: klio.enterprisedb.io/v1alpha1
kind: PluginConfiguration
metadata:
  name: klio-plugin-config
  namespace: default
spec:
  serverAddress: klio-server.default
  clientSecretName: client-sample-tls
  serverSecretName: klio-server-tls
```

### Client credentials secret

The client credentials must be stored in a Kubernetes Secret of type
`kubernetes.io/tls`, containing a secret to be presented to the Klio server.

This secret can be generated with cert-manager by following the [documentation
in the Klio server page](klio_server.mdx#creating-a-client-side-certificate).

### Server Address

The `serverAddress` field specifies where the Klio server can be reached. This
can be:

-   A Kubernetes service name: `klio-server.default` (within the same namespace)
-   A fully qualified domain name: `klio-server.default.svc.cluster.local`
-   An external address: `klio.example.com`

Connections will be done using the default ports of the Klio base and WAL
servers, respectively 51515 and 52000.

### TLS configuration

The `serverSecretName` field references a Secret containing the TLS certificate
used to secure communication with the Klio server. This is the same
certificate configured on the `Server` resource.

## Configuring a Cluster to use the Klio plugin

Once you have created a `PluginConfiguration`, reference it in your CloudNativePG
`Cluster` resource:

```yaml
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: my-postgres-cluster
  namespace: default
spec:
  instances: 3

  postgresql:
    pg_hba:
      - local replication all peer # Allow replication connections locally

  plugins:
    - name: klio.enterprisedb.io
      enabled: true # Activate the Klio plugin (default)
      parameters:
        pluginConfigurationRef: klio-plugin-config

  storage:
    size: 10Gi
```

To be able to stream WAL files, ensure that your PostgreSQL configuration
allows local replication connections. You can do this by adding an entry to the
`pg_hba` section, as shown in the example above.

### Plugin parameters

The `plugins` section in the `Cluster` specification requires:

-   **name**: Must be set to `klio.enterprisedb.io` to identify the Klio plugin
-   **enabled**: Set to `true` to activate the plugin. This is the default value.
-   **parameters.pluginConfigurationRef**: The name of your `PluginConfiguration` resource

!!!note

Even though the Klio plugin is used to archive WAL files on the Klio server,
it does not use the `archiveCommand` parameter in the PostgreSQL configuration,
as the WAL are streamed directly to the Klio server. Thus, you must not set
`isWALArchiver: true` in the plugin configuration.
!!!

## Advanced configuration options

The `PluginConfiguration` resource supports several advanced options to
customize the plugin's behavior.

### Retention policies

Define how long backups should be retained by configuring the retention policy:

```yaml
apiVersion: klio.enterprisedb.io/v1alpha1
kind: PluginConfiguration
metadata:
  name: klio-plugin-config
spec:
  serverAddress: klio-server.default
  clientSecretName: klio-client-credentials
  serverSecretName: klio-server-tls
  retention:
    keepLatest: 5
    keepHourly: 12
    keepDaily: 7
    keepWeekly: 4
    keepMonthly: 6
    keepAnnual: 2
```

Except for `keepLatest`, each option defines how many backups to retain
for the specified time period. For example, `keepDaily: 7` means that we should
retain at most one backup for each of the past 7 days.

If multiple backups exist within the same time bucket, the most recent one is
kept, unless preserved by a different *keep* rule. Backups that are not
retained by any rule are deleted. Rule evaluation is done when a new backup is
taken.

The Klio server will automatically delete WAL files that are no longer needed
for recovery by any retained backup.

All retention settings are optional. For each unspecified retention level,
the default Kopia value is applied:

```yaml
keepLatest: 10
keepHourly: 48
keepDaily: 7
keepWeekly: 4
keepMonthly: 24
keepAnnual: 1
```

Set a rule to `0` to disable that retention level.

### Cluster name override

By default, the plugin uses the name of the CloudNativePG `Cluster` resource.
You can override this if needed:

```yaml
spec:
  clusterName: my-custom-cluster-name
```

This can be useful working with backups from different clusters, for example
when restoring clusters or configuring replica clusters.

### Tier 2 restore

To enable restore from Tier 2 storage, set the `tier2` field to `true`:

```yaml
spec:
  tier2: true
```

When enabled, Klio will look for backups in both Tier 1 and Tier 2. If a backup
is available in both tiers, Tier 1 takes precedence as restore from it will be
faster.

See the [Architecture documentation](architectures.mdx#tier-2-secondary-storage-object-storage)
for more details on Tier 2 storage.

### Restore configuration

When performing a restore, you can specify which backup to use:

```yaml
spec:
  backupId: backup-YYYYMMDDHHMMSS
```

You can find the backup ID in the `Backup` resources status, or through the
Klio API server.

### Observability

See the [OpenTelemetry observability](opentelemetry.mdx) section for more
details on how to monitor the Klio plugin using OpenTelemetry.

### Performance profiling

Enable the pprof HTTP endpoint for performance profiling and troubleshooting:

```yaml
spec:
  pprof: true
```

When enabled, the pprof endpoint is exposed and can be used with Go's profiling
tools to analyze CPU usage, memory allocation, goroutines, and other runtime
metrics.

!!!warning

Only enable pprof in development or testing environments, or when actively
troubleshooting performance issues. It should not be enabled in production
unless necessary.
!!!

## Container customization

The `PluginConfiguration` resource allows you to customize the Klio sidecar
containers by providing base container specifications that are used as the
foundation for the sidecars. This feature enables you to add custom environment
variables, volume mounts, resource limits, and other container settings without
modifying the PostgreSQL container environment.

### Basic example

```yaml
apiVersion: klio.enterprisedb.io/v1alpha1
kind: PluginConfiguration
metadata:
  name: klio-plugin-config
spec:
  serverAddress: klio-server.default
  clientSecretName: klio-client-credentials
  serverSecretName: klio-server-tls
  containers:
    - name: klio-plugin
      env:
        - name: CUSTOM_ENV_VAR
          value: "my-value"
        - name: DEBUG_LEVEL
          value: "info"
    - name: klio-wal
      env:
        - name: WAL_BUFFER_SIZE
          value: "8192"
```

### How container merging works

The containers you define serve as the base for the Klio sidecars, with the
following merge behavior:

1.  **Your container is the base**: When you define a container (e.g., `klio-plugin`),
    your specification serves as the starting point
2.  **Klio enforces required values**: Klio sets its essential configuration:
    -   Container `name` (klio-plugin, klio-wal, or klio-restore)
    -   Container `args` (the command arguments needed for operation)
    -   `CONTAINER_NAME` environment variable
3.  **Your customizations are preserved**: All other fields you define remain intact
4.  **Template defaults fill gaps**: For fields you don't specify, Klio applies
    sensible defaults (image, security context, standard volume mounts, etc.)

**Important**: Klio's required values (name, args, CONTAINER_NAME env var) will
always override any conflicting values you set. All other customizations are
respected.

### Available sidecar containers

The following containers can be customized:

-   **`klio-plugin`**: Handles backup creation and management in PostgreSQL pods
-   **`klio-wal`**: Streams WAL files to the Klio server in PostgreSQL pods
-   **`klio-restore`**: Restores backups during recovery jobs

### Example: Resource limits and environment variables

```yaml
apiVersion: klio.enterprisedb.io/v1alpha1
kind: PluginConfiguration
metadata:
  name: klio-plugin-config
spec:
  serverAddress: klio-server.default
  clientSecretName: klio-client-credentials
  serverSecretName: klio-server-tls
  containers:
    - name: klio-plugin
      env:
        - name: LOG_LEVEL
          value: "debug"
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector:4317"
      resources:
        limits:
          memory: "512Mi"
          cpu: "1"
        requests:
          memory: "256Mi"
          cpu: "500m"
    - name: klio-wal
      env:
        - name: WAL_STREAM_TIMEOUT
          value: "30s"
      resources:
        limits:
          memory: "256Mi"
          cpu: "500m"
        requests:
          memory: "128Mi"
          cpu: "250m"
```

!!!warning

Be careful when customizing containers. While your customizations serve as the
base, Klio will override certain critical values (name, args, CONTAINER_NAME env var)
that are required for proper operation. Avoid setting these fields as they will be
replaced. Always test changes in a non-production environment first.
!!!
