---
title: "Completions"
navTitle: "Completions"
description: "Completions is a text completion model that enables use of any OpenAI API compatible text generation model."
---

Model name: `completions`

Model aliases:

* `openai_completions`
* `nim_completions`

## About Completions

Completions is a text completion model that enables use of any OpenAI API compatible text generation model.

It is suitable for chat/text transforms, text completion, and other text generation tasks.

Depending on the name of the model, the model provider will set defaults accordingly.

When invoked as `completions` or `openai_completions`, the model provider will default to using the OpenAI API.

When invoked as `nim_completions`, the model provider will default to using the NVIDIA NIM API.


## Supported aidb operations

* decode_text
* decode_text_batch

## Supported models

* Any text generation model that is supported by the provider.

## Supported OpenAI models

See a list of supported OpenAI models [here](https://platform.openai.com/docs/models#models-overview).

## Supported NIM models

* [ibm/granite-guardian-3.0-8b](https://build.nvidia.com/ibm/granite-guardian-3_0-8b)  
* [ibm/granite-3.0-8b-instruct](https://build.nvidia.com/ibm/granite-3_0-8b-instruct)  
* [ibm/granite-3.0-3b-a800m-instruct](https://build.nvidia.com/ibm/granite-3_0-3b-a800m-instruct)  
* [meta/llama-3.3-70b-instruct](https://build.nvidia.com/meta/llama-3_3-70b-instruct)  
* [meta/llama-3.2-3b-instruct](https://build.nvidia.com/meta/llama-3.2-3b-instruct)  
* [meta/llama-3.2-1b-instruct](https://build.nvidia.com/meta/llama-3.2-1b-instruct)  
* [meta/llama-3.1-405b-instruct](https://build.nvidia.com/meta/llama-3_1-405b-instruct)  
* [meta/llama-3.1-70b-instruct](https://build.nvidia.com/meta/llama-3_1-70b-instruct)  
* [meta/llama-3.1-8b-instruct](https://build.nvidia.com/meta/llama-3_1-8b-instruct)  
* [meta/llama3-70b-instruct](https://build.nvidia.com/meta/llama3-70b)  
* [meta/llama3-8b-instruct](https://build.nvidia.com/meta/llama3-8b)  
* [nvidia/llama-3.1-nemotron-70b-instruct](https://build.nvidia.com/nvidia/llama-3_1-nemotron-70b-instruct)  
* [nvidia/llama-3.1-nemotron-51b-instruct](https://build.nvidia.com/nvidia/llama-3_1-nemotron-51b-instruct)  
* [nvidia/nemotron-mini-4b-instruct](https://build.nvidia.com/nvidia/nemotron-mini-4b-instruct)  
* [nvidia/nemotron-4-340b-instruct](https://build.nvidia.com/nvidia/nemotron-4-340b-instruct)  
* [google/shieldgemma-9b](https://build.nvidia.com/google/shieldgemma-9b)  
* [google/gemma-7b](https://build.nvidia.com/google/gemma-7b)  
* [google/codegemma-7b](https://build.nvidia.com/google/codegemma-7b)

## Creating the default model

There is no default model for Completions. You can create any supported model using the `aidb.create_model` function.

## Creating an OpenAI model

You can create any supported OpenAI model using the `aidb.create_model` function.

In this example, we are creating a GPT-4o model with the name `my_openai_model`:

```sql
SELECT aidb.create_model(
  'my_openai_model',
  'openai_completions',
  '{"model": "gpt-4o"}'::JSONB,
  '{"api_key": "sk-abc123xyz456def789ghi012jkl345mn"}'::JSONB 
);
```

## Creating a NIM model

```sql
SELECT aidb.create_model(
          'my_nim_completions', 
          'nim_completions',
          '{"model": "meta/llama-3.2-1b-instruct"}'::JSONB,
          credentials=>'{"api_key": "sk-abc123xyz456def789ghi012jkl345mn"'::JSONB);
```

## Model configuration settings

The following configuration settings are available for OpenAI models:

* `model` - The model to use.
* `url` - The URL of the model to use. This is optional and can be used to specify a custom model URL.  
  * If `openai_completions` (or `completions`) is the `model`, `url` defaults to `https://api.openai.com/v1/chat/completions`. 
  * If `nim_completions` is the `model`, `url` defaults to `https://integrate.api.nvidia.com/v1/chat/completions`.
* `max_concurrent_requests` - The maximum number of concurrent requests to make to the OpenAI model. Defaults to `25`.

## Model credentials

The following credentials are required for these models:

* `api_key` - The API key to use for authentication.
