---
title: Query existing Apache Iceberg tables
navTitle: Query Iceberg tables
description: How to query existing Apache Iceberg tables from EDB Postgres Lakehouse clusters in Hybrid Manager.
---

# How to query existing Apache Iceberg tables

You can configure your EDB Postgres Lakehouse cluster in Hybrid Manager (HM) to query existing Apache Iceberg tables stored in object storage.

This enables you to run SQL queries on Iceberg tables created by other systems (Spark, Trino, Flink, PGD offload) using standard Postgres SQL.

## Prerequisites

- An HM-provisioned EDB Postgres Lakehouse cluster
- Existing Apache Iceberg tables in S3-compatible object storage
- Appropriate storage permissions

## Steps

1. Define a PGFS storage location pointing to your Iceberg object storage.

```sql
SELECT pgfs.create_storage_location(...);
```
Create an external table using the USING PGAA clause.

```sql
CREATE TABLE public.my_sales_iceberg_data ()
USING PGAA
WITH (
    pgaa.storage_location = 'my_s3_iceberg_data',
    pgaa.path = 'sales_records/iceberg_table_root',
    pgaa.format = 'iceberg'
);
```

Query the Iceberg table.

```sql
SELECT * FROM public.my_sales_iceberg_data WHERE sales_region = 'North America' LIMIT 100;
```
## Notes
For Iceberg tables not managed by a catalog, the pgaa.path typically points to a directory containing a version-hint.text file or directly to a vX.metadata.json file.

## Related topics
Configure an Iceberg REST catalog connection
Offload PGD data to Apache Iceberg
