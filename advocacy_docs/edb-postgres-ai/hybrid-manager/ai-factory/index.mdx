---
title: AI Factory in Hybrid Manager
navTitle: AI Factory
description: Learn how to use the AI Factory workload within Hybrid Manager (HCP), including Gen AI, model serving, pipelines, and vector search. Explore learning paths, use cases, and Hybrid Manager-specific capabilities.
---

# AI Factory in Hybrid Manager

The **AI Factory workload** in Hybrid Manager brings scalable AI, machine learning, and Gen AI capabilities to your Hybrid Control Plane (HCP). It enables you to operationalize AI across your Hybrid Manager-managed clusters and data — with deep integration across Postgres, vector search, model serving, and pipelines.

With AI Factory in Hybrid Manager, you can:

- **Deploy Gen AI assistants and agents** for internal or external-facing use
- **Serve AI models at scale** with integrated KServe-powered inferencing and GPU acceleration
- **Build pipelines** to prepare and transform data for AI and vector use cases
- **Create knowledge bases** and perform **retrieval-augmented generation (RAG)** with powerful vector search
- **Manage your model library** and deploy trusted models within Hybrid Manager governance

---

## Example AI Solutions You Can Build

Hybrid Manager AI Factory unlocks solutions across a wide range of real-world needs:

- **Enterprise search and knowledge assistants**
Build RAG-based assistants that integrate with corporate documents, databases, and intranet content.

- **Document intelligence and automation**
Process PDFs, scanned documents, web data, and structured sources — applying OCR, summarization, and classification pipelines.

- **Customer support chatbots**
Deploy assistants powered by your own data and domain-specific models, with response generation and retrieval.

- **AI-driven data apps**
Expose AI-powered endpoints for applications — such as semantic search, recommendations, similarity search, or NLP-based querying.

- **Operational AI for internal tools**
Build models and agents to assist with DevOps, customer success, HR automation, sales enablement, and more.

- **Domain-specific model serving**
Serve proprietary or fine-tuned models (LLMs, classification, ranking) as scalable inference services, integrated with business systems.

You can start small with a single assistant or inference service — and scale to full Gen AI applications that combine pipelines, vector search, model serving, and conversational agents.

---

## Learning Paths

Follow our curated learning paths based on your experience level:

- [AI Factory 101](/ai-factory/learn/paths/101) — Introductory concepts and usage
- [AI Factory 201](/ai-factory/learn/paths/201) — Building and managing Gen AI and AI Factory workloads
- [AI Factory 301](/ai-factory/learn/paths/301) — Advanced integration, scaling, governance, and optimization

---

## Use Cases and Solutions

We provide detailed guidance and patterns to help you build full solutions with AI Factory:

- [Common Use Cases](/ai-factory/learn/use-cases) — Start with proven patterns for AI Factory-powered applications
- [Industry Solutions](/ai-factory/learn/solutions) — Explore industry-specific ideas and recommended best practices

---

## AI Factory in Hybrid Manager Workloads

Hybrid Manager supports the full range of AI Factory capabilities, integrated into its control plane:

### Gen AI Workloads

- [Gen AI Workloads](./gen-ai/index.mdx) — Overview of capabilities in Hybrid Manager
- [Agent Studio](./gen-ai/agent-studio.mdx) — Assistants, tools, structures, and rulesets for Gen AI
- [Gen AI Builder](./gen-ai/builder.mdx) — Knowledge bases and data lakes

### Model Management and Serving

- [Model Library](./model/library.mdx) — Manage and govern your model assets
- [Model Serving](./model/serving.mdx) — Deploy and scale model inference services on Kubernetes
- [GPU Resource Management](./model/gpu.mdx) — Configure and allocate GPU capacity for serving

### Pipelines and Vector Engine

- [Pipeline Knowledge Base](./pipeline/knowledge-base/index.mdx) — Pipelines for data preparation and document intelligence
- [Vector Engine](./vector-engine/index.mdx) — Integrated vector search and similarity capabilities with Postgres

---

## Hybrid Manager Learn Content

In addition to AI Factory content in the Hub, Hybrid Manager provides additional **Learn** content for HM-specific usage:

- [AI Factory Concepts in Hybrid Manager](../learn/explained/ai-factory/index.mdx)
- [How-to guides for Hybrid Manager AI Factory](../learn/how-to/ai-factory/index.mdx)
- [Learning Paths in Hybrid Manager](../learn/paths/ai-factory/index.mdx)

---

## Get Started

To get started building with AI Factory in Hybrid Manager:

- Follow the [AI Factory learning paths](/ai-factory/learn/paths/index)
- Explore [use cases](/ai-factory/learn/use-cases) and [industry solutions](/ai-factory/learn/solutions)
- Read Hybrid Manager-specific [how-to guides](../learn/how-to/ai-factory/index.mdx)
- Deploy your first Gen AI assistant or model with [Agent Studio](./gen-ai/agent-studio.mdx) or [Model Serving](./model/serving.mdx)

AI Factory in Hybrid Manager gives you a scalable, secure platform to operationalize AI across your hybrid data estate. Start building today.

---

