---
title: AI Factory concepts
navTitle: Concepts
description: EDB’s vision, strategy, and technologies for delivering AI Factory capabilities in Postgres and Hybrid Manager environments.
---

AI Factory concepts explain how EDB integrates modern AI capabilities across its platform — including Postgres®, Hybrid Manager (HM), and the AI Factory services.

**Why it matters:**
AI is transforming data infrastructure, applications, and developer workflows. EDB’s AI Factory is designed to help you:

- Embed AI in Postgres and database-driven apps
- Build scalable AI-powered applications
- Operate AI workloads on modern cloud and hybrid infrastructure
- Simplify AI model serving and governance
- Support key patterns like Retrieval-Augmented Generation (RAG) and semantic search

---

## EDB’s vision for AI with Postgres and Hybrid Manager

EDB enables AI workloads in several complementary ways:

- **AI in databases:** Use AIDB to perform vector search, embeddings, and ML functions directly in Postgres.
- **AI-powered apps:** Build apps using Gen AI Builder (Griptape-based) integrated with Knowledge Bases and model serving.
- **AI infrastructure:** Operate models on cloud-native infrastructure via KServe with optimized GPU resources.
- **AI management:** Leverage Hybrid Manager for unified model lifecycle management and observability.

**Goal:** Make Postgres a first-class component of the modern AI stack, and provide a production-ready control plane for AI-driven applications.

[Related: AI Factory generic concepts](./generic-concepts)

---

## Core AI patterns supported

### Vector search and semantic search

Use vector databases and pgvector in Postgres to support:

- Semantic search
- Product recommendations
- Anomaly detection
- RAG pipelines

**Mapped to:**
[Vector search in AIDB](../hybrid-manager/ai-factory/vector_search) *(planned)*
[Vector search How-To guides](../hybrid-manager/ai-factory/learn/how-to/index) *(planned)*

---

### Retrieval-Augmented Generation (RAG)

Combine vector search with LLMs to enable:

- More accurate and grounded AI responses
- Domain-specific LLM applications
- Compliance-aware AI apps

**Mapped to:**
[Building RAG pipelines with HCP AI Factory](../hybrid-manager/ai-factory/rag_architecture) *(planned)*
[Deploying LLMs for RAG with KServe](../hybrid-manager/ai-factory/llm_serving) *(planned)*

---

### AI in database (In-DB ML and vector search)

AIDB enables:

- Vector similarity search inside Postgres
- Embedding pipelines integrated with Postgres data
- Future: in-database model scoring and ML operations

**Mapped to:**
[AIDB concepts](../hybrid-manager/ai-factory/aidb_concepts) *(planned)*
[AIDB How-To guides](../hybrid-manager/ai-factory/learn/how-to/index) *(planned)*

---

### Model serving and inference with KServe

Run AI models as scalable inference services:

- LLMs, embedding models, vision models
- GPU-accelerated inference
- KServe-backed InferenceServices with optional Transformers and Explainers

**Mapped to:**
[KServe model serving in HCP AI Factory](../hybrid-manager/ai-factory/kserve_concepts) *(planned)*
[Deploying models with KServe](../hybrid-manager/ai-factory/learn/how-to/deploy_kserve_model) *(planned)*

---

### Gen AI Builder (Griptape-based app development)

Rapidly build AI applications that:

- Use LLMs with tools, memory, and control
- Integrate with AIDB Knowledge Bases
- Call external APIs and databases
- Support modular and maintainable AI workflows

**Mapped to:**
[Gen AI Builder concepts](../hybrid-manager/ai-factory/genai_builder_concepts) *(planned)*
[Building apps with Gen AI Builder](../hybrid-manager/ai-factory/learn/how-to/build_genai_app) *(planned)*

---

## Key architectural principles

### Modular architecture

AI Factory is designed to:

- Run on hybrid infrastructure (on-prem, cloud, multi-cloud)
- Integrate with Postgres and cloud-native services
- Provide composable building blocks for AI workloads

### Open standards and interoperability

- **LLM support:** KServe with open model formats
- **Vector search:** pgvector and Postgres, or external vector stores
- **Framework flexibility:** Griptape enables LLM-agnostic app development
- **Data portability:** Support for RAG patterns, LLM fine-tuning, and model swapping

---

## Summary of capabilities and mapped components

| Capability | EDB AI Factory Component | Planned HM Spoke Page |
|------------|--------------------------|----------------------|
| Vector search | AIDB (pgvector) | ../hybrid-manager/ai-factory/vector_search |
| RAG pipelines | AIDB + KServe + Griptape | ../hybrid-manager/ai-factory/rag_architecture |
| AI in database | AIDB | ../hybrid-manager/ai-factory/aidb_concepts |
| Model serving | KServe | ../hybrid-manager/ai-factory/kserve_concepts |
| Gen AI app dev | Gen AI Builder (Griptape) | ../hybrid-manager/ai-factory/genai_builder_concepts |
| AI-driven infra | GPUs + Kubernetes + KServe | ../hybrid-manager/ai-factory/infra_concepts |

---

## Next steps

- [AI Factory terminology](./terminology) — Definitions of key terms and components
- [AI Factory generic concepts](./generic-concepts) — Industry concepts that inform the AI Factory design
- [AI Factory learning guide](../learn/index) *(planned)*
- [AI Factory in Hybrid Manager](../hybrid-manager/ai-factory/index) *(planned spoke root)*

---

