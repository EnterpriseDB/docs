---
title: AI Factory Model Library Explained
navTitle: Model Library Explained
description: Understand the Model Library in AI Factory, how it works, and how it is powered by the Hybrid Control Plane Image and Model Library.
---

# AI Factory Model Library Explained

The **Model Library** in AI Factory is your central interface for discovering, managing, and deploying AI models for Model Serving within the Hybrid Control Plane (HCP) environment.

It is powered by the core **Image and Model Library** of HCP.
The Model Library presents a curated AI-focused view of model images from that broader Image Library.

## How does the Model Library work?

The Model Library:

- Surfaces a filtered view of **AI model images** available in the Image Library.
- Allows AI Factory users to deploy supported models to the **Model Serving (KServe)** layer.
- Ensures all model images pass through platform-wide governance and security policies.

It does not provide a separate registry or upload flow:

- All model images must flow through the Image Library.
- The Model Library reflects images that are marked as valid for AI model serving.

## Architecture flow

Container Registry → Image and Model Library → Model Library → Model Serving (KServe) → AI Factory Workloads

| Layer | Role |
|-------|------|
| Container Registry | Stores model container images (ex: NVIDIA NIM) |
| Image and Model Library | Single source of truth for all images |
| Model Library | Curated AI-focused UI for model images |
| Model Serving (KServe) | Runs deployed model instances |
| AI Factory Workloads | Gen AI Builder, Knowledge Base pipelines, Assistants |

## What does the Model Library provide?

- Browse available model images.

- View supported tags and versions.

- Deploy models to Model Serving infrastructure.

- Manage lifecycle of model deployments.

- Understand which models are powering your AI Factory experiences:

- Knowledge Bases (via AIDB).
- Gen AI Builder (for Assistants and pipelines).

## Why is it powered by Image Library?

- **Governance:** All images pass through the same governance flow.
- **Security:** Registry integration, tag selection, and auditability is unified.
- **Consistency:** Database and AI models share the same image management system.
- **Flexibility:** You can add your own model images (via Image Library path).

→ For a deeper understanding, see: [Image and Model Library Explained](../../../../hybrid-manager/learn/explained/model-image-library)

## Supported model types

In current AI Factory versions:

| Model Type | Example Image |
|------------|---------------|
| Text Completion | llama-3.3-nemotron-super-49b |
| Text Embedding | arctic-embed-l |
| Image Embedding | nvclip |
| OCR | paddleocr |
| Text Reranker | llama-3.2-nv-rerankqa-1b-v2 |

Future versions will expand supported model types and custom model support.

## Model Serving integration

Models deployed from the Model Library are served via **KServe**.

The Model Library provides a guided workflow to deploy models:

1. Select a model image and tag.
2. Configure model runtime settings (replicas, resources, etc.).
3. Deploy to KServe → creates an InferenceService in the HCP Kubernetes environment.
4. The model is now available for:
 - AIDB Knowledge Base ingestion.
 - Gen AI Builder usage.
 - Other AI Factory capabilities.

## Summary

- The Model Library is your entry point for managing AI models in AI Factory.
- It is powered by the core Image and Model Library of Hybrid Control Plane.
- All model images pass through this unified governance flow.
- Model Serving uses these images via KServe to power your AI workloads.

## Related Explained Pages

- [Image and Model Library Explained](../../../../hybrid-manager/learn/explained/model-image-library)

## Related How-Tos

- [Deploy AI Models](../../how-to/deploy-ai-models)
- [Integrate Private Registry](../../how-to/integrate-private-registry)
- [Define Repository Rules](../../how-to/define-repository-rules)
