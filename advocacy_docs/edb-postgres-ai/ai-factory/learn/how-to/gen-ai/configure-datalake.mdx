---
title: Configure the Data Lake in Gen AI Builder
description: How to configure the Data Lake in Gen AI Builder to support content storage and AI pipelines.
---

## Who is this for

Platform users setting up Gen AI Builder or Hybrid Manager with Griptape.
This includes platform administrators, DevOps engineers, and AI builders configuring backend storage for AI Factory.

## What you will accomplish

You will configure a **Data Lake** — the object storage backend required for Griptape services to function.
You will create and configure a storage bucket, set CORS policies, and provide required credentials.

## Why configure the Data Lake

- The Data Lake is used to store:
- Uploaded files from Data Sources
- Indexed data and embeddings
- Griptape Structures and Tools
- Temporary artifacts used by Griptape-powered services
- Without a Data Lake, Libraries, Knowledge Bases, and AI Assistants will not function.
- The Data Lake must be configured **before adding Data Sources or creating Knowledge Bases**.

For background, see:

- [Data Lake explained](../../../learn/explained/data-lake-explained)
- [AI Factory Concepts](../../../learn/explained/ai-factory-concepts)
- [Hybrid Manager: Using Gen AI Builder](../../../../hybrid-manager/ai-factory/gen-ai/builder/index)

## Complexity and time to complete

- **Complexity**: Moderate (object storage + configuration)
- **Estimated time**: 10–20 minutes

## Pre-requisites

- Access to an S3-compatible object storage provider:
- AWS S3
- Google Cloud Storage (GCS) with S3 interoperability enabled
- Other compatible services (MinIO, Ceph, etc.)
- Permissions to create buckets and manage CORS.
- Ability to obtain object storage credentials.

## How to configure the Data Lake

### 1. Create a dedicated bucket

Provision a new bucket **dedicated for Griptape / Gen AI Builder**.

**Best practice:** Do not reuse a general-purpose bucket.

#### AWS S3 or compatible

- Create a bucket (example: `docs-temp-hcp`).

#### Google Cloud Storage (GCS)

- Create a bucket.
- Enable **S3 interoperability** in GCS settings.
- Assign required roles:
- Storage Admin
- Service Account Token Creator
- Generate HMAC keys (used as Access Key ID and Secret Access Key).

### 2. Configure CORS policy

You must configure CORS (Cross-Origin Resource Sharing) to allow UI interactions with the Data Lake.

#### Example CORS for S3-compatible storage

```json
[
    {
        "AllowedHeaders": ["*"],
        "AllowedMethods": ["PUT", "POST", "DELETE", "GET", "HEAD"],
        "AllowedOrigins": ["https://<PORTAL_DOMAIN_NAME>"],
        "ExposeHeaders": []
    }
]
```
Example CORS for GCS
1. Create cors-config.json:

```json
[
  {
    "origin": ["https://<PORTAL_DOMAIN_NAME>"],
    "method": ["GET", "PUT", "POST", "DELETE", "HEAD"],
    "responseHeader": ["*"],
    "maxAgeSeconds": 3600
  }
]
```
2. Apply policy:
```shell
gsutil cors set cors-config.json gs://<your-gcs-bucket-name>
```
3. Obtain credentials
You will need the following for your Griptape deployment:

Bucket name

S3 Endpoint URL

Access Key ID

Secret Access Key

Region (if applicable)

For GCS: Use HMAC keys as your Access Key ID and Secret Access Key.

4. Provide credentials to deployment
Configure your Kubernetes deployment or backend:

Environment variables

Configuration files / secrets

Typical environment variables:


```shell
DATA_LAKE_BUCKET_NAME=docs-temp-hcp
DATA_LAKE_ENDPOINT_URL=https://<your-endpoint>
DATA_LAKE_ACCESS_KEY_ID=<access-key-id>
DATA_LAKE_SECRET_ACCESS_KEY=<secret-access-key>
DATA_LAKE_REGION=<region>  # If applicable
```

5. Verify connectivity
In Gen AI Builder, navigate to Data Lake.

You should see your configured bucket listed.

You can create folders or upload test files to verify permissions.

Example: docs-temp-hcp → Create Folder → Upload File

Troubleshooting
Bucket not visible in Gen AI Builder
Verify that credentials are correct and permissions are granted.

Check that CORS policy allows required methods.

Uploads or UI interactions fail
Confirm CORS settings.

Verify that bucket is dedicated to Griptape — avoid conflicting bucket policies.

Access denied errors
Ensure that the Access Key ID / Secret Access Key has the required permissions:

S3 or Storage Object Admin

Read / write / delete permissions on the bucket

Related topics
Data Lake explained

AI Factory Concepts

Configure Data Sources

Configure Knowledge Bases

Hybrid Manager: Using Gen AI Builder

