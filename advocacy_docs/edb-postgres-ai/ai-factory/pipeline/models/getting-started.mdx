---
title: Model Serving Quickstart
navTitle: Quickstart
description: Get started with Model Serving in AI Factory. This quickstart provides a guided path for new and experienced users with links to essential resources.
---

# Model Serving Quickstart

This page helps you quickly understand how to start using **Model Serving** within the AI Factory and where to find supporting documentation.

Model Serving in AI Factory enables you to deploy AI models (such as NVIDIA NIM containers) as scalable, production-grade inference services. It is powered by **KServe**, a Kubernetes-native model serving engine.

## Where to start

### 1. Learn the concepts

Before deploying models, it's useful to understand how Model Serving works and how it fits into the AI Factory ecosystem:

-   [Model Serving Concepts](/edb-postgres-ai/ai-factory/learn/explained/ai-factory-concepts/#model-serving)
-   [Model Serving Terminology](/edb-postgres-ai/ai-factory/learn/explained/terminology/)

### 2. Understand how AI Factory integrates Model Serving

Model Serving interacts with:

-   **Model Library**: Browse and manage model images for deployment (coming soon)
-   **Knowledge Bases (AIDB)**: Vector stores that may use embedding models served by Model Serving
-   **Gen AI Builder**: Applications may call into Model Serving endpoints for inferencing

### 3. Follow the How-To Guides

If you're ready to deploy or manage models:

-   [How-To Guides: Model Serving](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/)

* * *

## Getting started checklist

Use this checklist to guide your progress depending on your experience level.

### For new users (101 level)

-   Read the [Model Serving Concepts](/edb-postgres-ai/ai-factory/learn/explained/ai-factory-concepts/#model-serving)
-   Review key [Model Serving Terminology](/edb-postgres-ai/ai-factory/learn/explained/terminology/)
-   Understand [What KServe is](/edb-postgres-ai/ai-factory/learn/explained/ai-factory-concepts/#model-serving) and how it powers Model Serving
-   Understand [How Model Library relates to Model Serving](/edb-postgres-ai/ai-factory/model/library/) (coming soon)

[Follow Learning Path 101 for Model Serving](/edb-postgres-ai/ai-factory/learn/paths/101)

* * *

### For existing users familiar with Kubernetes (101 level)

-   Verify your Kubernetes access in your HCP project
-   Review the [Concepts](/edb-postgres-ai/ai-factory/learn/explained/ai-factory-concepts/#model-serving) and [Terminology](/edb-postgres-ai/ai-factory/learn/explained/terminology/)
-   Prepare your cluster prerequisites:


-   GPU node pools (if needed)
-   NVIDIA device plugin (if needed)
-   Access to your container registry for model images


-   Configure basic KServe resources:


-   [Deploy NVIDIA NIM Container](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/deploy-nim-container/)
-   [Configure ClusterServingRuntime](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/configure-servingruntime/)
-   [Create InferenceService](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/create-inferenceservice/)


* * *

### For advanced users (201 level)

-   Tune deployed InferenceService resource usage:


-   [Update GPU Resources](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/update-gpu-resources/)


-   Monitor deployed models:


-   [List deployed InferenceServices](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/monitor-inferenceservice/)
-   [Monitor KServe deployments](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/monitor-inferenceservice/) (coming soon)


-   Understand traffic routing, canary rollouts, and scaling:


-   [Model serving scaling patterns](/edb-postgres-ai/ai-factory/learn/explained/ai-factory-concepts/#model-serving)
-   Future: Advanced How-Tos


* * *

### For expert users (301 level)

-   Manage your own custom model images
-   Build and configure custom ServingRuntime definitions
-   Use Transformers and Explainers in KServe (coming soon)
-   Build CI/CD pipelines for deploying models in KServe
-   Instrument InferenceServices for advanced observability

[Follow Learning Path 301 for Model Serving](/edb-postgres-ai/ai-factory/learn/paths/301)

* * *

## Next steps

-   [Model Serving Concepts](/edb-postgres-ai/ai-factory/learn/explained/ai-factory-concepts/#model-serving)
-   [Model Serving How-To Guides](/edb-postgres-ai/ai-factory/learn/how-to/model-serving/)
-   [Model Library (future hub)](/edb-postgres-ai/ai-factory/model/library/)

* * *

Use this quickstart as your launch point into Model Serving within AI Factory.
