---
title: Preparing Oracle source databases
navTitle: Preparing Oracle source

---

<div id="preparing_oracle_sources" class="registered_link"></div>

## Oracle configuration

Configuring Oracle for EDB Data Migration Services (EDB DMS) requires `sysdba` privileges.

Configure an Oracle source database to:
-  Enable archive log mode.
-  Enable supplemental logging for the database and tables of interest.
-  Prepare tablespaces for migration user
-  Create a migration user and grant necessary privileges to carry out the data migration.
-  Grant SELECT on source tables.
-  (Optional) Ensure adequate redo log space is available for better performance.
-  Validate configuration.

### Step1: Enable archive log mode

Debezium captures database changes by reading the database's redo logs. To ensure a complete and reliable history of all transactions without risk of data loss, Oracle must be configured in Archive Log Mode. This process saves a copy of every redo log before it is reused, providing Debezium with an unbroken stream of changes.

Log in to oracle **CDB** as sysdba:

```shell
sqlplus <DBA_USER>/<PASSWD>@<HOST>:<PORT>/<CDB_NAME> as sysdba
```

Where:

- `<DBA_USER>` is an oracle user that can log in to the cdb as sysdba.
- `<PASSWD>` is the password of dba_user.
- `<HOST>` is the oracle db hostname.
- `<PORT>` is the oracle db port.
- `<CDB_NAME>` is the oracle CDB name.

Run the following sql to check whether archive mode is enabled:

```sql
archive log list;
```

The returned content indicates the database mode:

```sql
-- below output indicates archive log mode is enabled
Database log mode 	Archive Mode -- (or "Archive Log Mode" in new versions of oracle)
-- or below output indicates archive log mode is not enabled
Database log mode 	No Archive Mode
```

If your archive mode is already enabled, you can skip this step. Otherwise, log out from previous sql session first, then run the following command:

```shell
ORACLE_SID=<CDB_NAME> sqlplus /nolog
```

Where

- `<CDB_NAME>` is the oracle CDB name.

After entering sql session, run the following SQLs one by one:

```sql
CONNECT <DBA_USER>/<PASSWD> AS sysdba;
-- Set the location and size for the Fast Recovery Area (FRA)
alter system set db_recovery_file_dest_size = <RECOVERY_FILE_DEST_SIZE>;
alter system set db_recovery_file_dest = '<RECOVERY_FILE_DEST>' scope=spfile;
-- Restart the database in the correct state to enable archiving
shutdown immediate
startup mount
-- Enable archive log mode and open the database for use
alter database archivelog;
alter database open;
-- Verify the change was successful
archive log list;
exit;
```

Where

- `<DBA_USER>` is an oracle user that can log in to the cdb as sysdba.
- `<PASSWD>` is the password of dba_user.
- `<RECOVERY_FILE_DEST>` is the directory path of your FRA, where oracle redo logs will locate.
- `<RECOVERY_FILE_DEST_SIZE>` is the space allocated to FRA, for example, 100G means 100 gigabytes.

!!!note
   db_recovery_file_dest and db_recovery_file_dest_size configure Oracle's **Fast Recovery Area (FRA)**, a vital storage area for the archived logs that Debezium needs. Correctly setting them is essential for database stability, therefore, **always consult your DBA for production settings.**

### Step2: Enable supplemental logging for the database and tables of interest

Supplemental logging refers to the capture of additional information in Oracle redo logs, such as "before" state. This extra redo log information is needed for some log-based applications, such as EDB DMS, to capture change events. See [Supplemental Logging](https://docs.oracle.com/en/database/oracle/oracle-database/19/sutil/oracle-logminer-utility.html#GUID-D857AF96-AC24-4CA1-B620-8EA3DF30D72E) in the Oracle documentation for more information.

You need to enable supplemental logging at the database level as well as for those tables you want to migrate, they're crucial for debezium to run data migrations:
* Database level supplemental logging is the foundation. It ensures every CDC message has a Tracking Number (the Primary Key), so you can uniquely identify which order was changed.
* Table level Logging is the detail. It ensures the CDC message includes a full copy of the original order form (the "before" image of all columns), not just the item that was updated.

First Log in to oracle **CDB** as sysdba:

```shell
sqlplus <DBA_USER>/<PASSWD>@<HOST>:<PORT>/<CDB_NAME> as sysdba
```

Where:

- `<DBA_USER>` is an oracle user that can log in to the cdb as sysdba.
- `<PASSWD>` is the password of dba_user.
- `<HOST>` is the oracle db hostname.
- `<PORT>` is the oracle db port.
- `<CDB_NAME>` is the oracle CDB name.

Run the following SQL to enable supplemental logging at the entire database level:

```sql
ALTER DATABASE ADD SUPPLEMENTAL LOG DATA;
```

Then switch to the ***PDB*** you want to migrate:

```sql
ALTER SESSION SET CONTAINER = <PDB_NAME>;
```

Where:

- `<PDB_NAME>` is the PDB you want to migrate

And enable supplemental logging for all the tables you want to migrate:

```sql
ALTER TABLE <SCHEMA_NAME>.<TABLE_NAME> ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;
```

Where:

- `<SCHEMA_NAME>` is the schema to which your table belongs
- `<TABLE_NAME>` is the name of a table you want to migrate

!!!note
   In oracle, a schema is identical to a user, so remember to set schema name correctly when running the above sql, otherwise data migration might encounter errors.

### Step3: Prepared tablespaces for migration user

DMS and the underlying library it relies on(Debezium) requires a ***common user*** to carry out data migration. But before creating such a migration user, we need to first create dedicated tablespaces for it. Two tablespaces are needed:
* A CDB level tablespace for debezium's internal log mining and management processes that operate at the container level.
* A PDB level tablespace for operations related to specific tables you're capturing within that PDB.

First Log in to oracle **CDB** as sysdba:

```shell
sqlplus <DBA_USER>/<PASSWD>@<HOST>:<PORT>/<CDB_NAME> as sysdba
```

Where:

- `<DBA_USER>` is an oracle user that can log in to the cdb as sysdba.
- `<PASSWD>` is the password of dba_user.
- `<HOST>` is the oracle db hostname.
- `<PORT>` is the oracle db port.
- `<CDB_NAME>` is the oracle CDB name.

Run the following SQL to create a ***CDB*** tablespace:

```sql
CREATE TABLESPACE <TABLESPACE_NAME> DATAFILE '<CDB_TABLESPACE_PATH>.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;
```

Where:

- `<TABLESPACE_NAME>` is the name of the CDB tablespace, any valid name is ok
- `<CDB_TABLESPACE_PATH>.dbf` is the file path of this tablespace. Consult your DBA for the correct value.

Then switch to the ***PDB*** you want to migrate:

```sql
ALTER SESSION SET CONTAINER = <PDB_NAME>;
```

Where:

- `<PDB_NAME>` is the PDB you want to migrate

And create a tablespace for PDB:

```sql
CREATE TABLESPACE <TABLESPACE_NAME> DATAFILE '<PDB_TABLESPACE_PATH>.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;
-- continue adding more datafiles if necessary
-- CREATE TABLESPACE <TABLESPACE_NAME> DATAFILE '<PDB_TABLESPACE_PATH>.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;
```

Where:

- `<TABLESPACE_NAME>` is the name of the PDB tablespace, for convenience we use the same name as the CDB tablespace.
- `<PDB_TABLESPACE_PATH>.dbf` is the file path of this tablespace. Consult your DBA for the correct value.

If you're using a non-CDB database, the PDB realted tablespace setup can be omitted.

### Step4: Create a migration user and grant necessary privileges to carry out the data migration

As previous step mentioned, DMS requires a common user. First log in to ***CDB*** as sysdba:

```shell
sqlplus <DBA_USER>/<PASSWD>@<HOST>:<PORT>/<CDB_NAME> as sysdba
```

Where:

- `<DBA_USER>` is an oracle user that can log in to the cdb as sysdba.
- `<PASSWD>` is the password of dba_user.
- `<HOST>` is the oracle db hostname.
- `<PORT>` is the oracle db port.
- `<CDB_NAME>` is the oracle CDB name.

Run the following SQLs one by one to create a migration user and grant necessary permissions:

```sql
CREATE USER <MIGRATION_USER> IDENTIFIED BY <MIGRATION_USER_PASSWORD>
        DEFAULT TABLESPACE <TABLESPACE_NAME>
        QUOTA UNLIMITED ON <TABLESPACE_NAME>
        CONTAINER=ALL;
    GRANT CREATE SESSION TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SET CONTAINER TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ON V_$DATABASE to <MIGRATION_USER> CONTAINER=ALL;
    GRANT FLASHBACK ANY TABLE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ANY TABLE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT_CATALOG_ROLE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT EXECUTE_CATALOG_ROLE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ANY TRANSACTION TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ANY DICTIONARY TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT LOGMINING TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT CREATE TABLE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT LOCK ANY TABLE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT CREATE SEQUENCE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT EXECUTE ON DBMS_LOGMNR TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT EXECUTE ON DBMS_LOGMNR_D TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ON V_$LOGMNR_LOGS TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ON V_$LOGMNR_CONTENTS TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ON V_$LOGFILE TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ON V_$ARCHIVED_LOG TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ON V_$ARCHIVE_DEST_STATUS TO <MIGRATION_USER> CONTAINER=ALL;
    GRANT SELECT ON V_$TRANSACTION TO <MIGRATION_USER> CONTAINER=ALL;
```

Where:

- `<MIGRATION_USER>` is the name of the common user you want to create for DMS to use.
- `<MIGRATION_USER_PASSWORD>` password of migration user.
- `<TABLESPACE_NAME>` is the name of the CDB tablespace you created in previous step. Remember for convenience we use the same tablespace name for CDB and PDB.

If in step3, you used different names for CDB and PDB, then apart from the above SQLs, you'll have to log in to the ***PDB*** and run the following SQL:

```sql
ALTER USER <MIGRATION_USER> DEFAULT TABLESPACE <PDB_TABLESPACE_NAME>
```

If you're using a non-CDB database, run following SQL instead:

```sql
    CREATE USER <MIGRATION_USER> IDENTIFIED BY <MIGRATION_USER_PASSWORD>
        DEFAULT TABLESPACE <TABLESPACE_NAME>
        QUOTA UNLIMITED ON <TABLESPACE_NAME>;
    GRANT CREATE SESSION TO <MIGRATION_USER>;
    GRANT SELECT ON V_$DATABASE to <MIGRATION_USER>;
    GRANT FLASHBACK ANY TABLE TO <MIGRATION_USER>;
    GRANT SELECT ANY TABLE TO <MIGRATION_USER>;
    GRANT SELECT_CATALOG_ROLE TO <MIGRATION_USER>;
    GRANT EXECUTE_CATALOG_ROLE TO <MIGRATION_USER>;
    GRANT SELECT ANY TRANSACTION TO <MIGRATION_USER>;
    GRANT SELECT ANY DICTIONARY TO <MIGRATION_USER>;
    GRANT LOGMINING TO <MIGRATION_USER>;
    GRANT CREATE TABLE TO <MIGRATION_USER>;
    GRANT LOCK ANY TABLE TO <MIGRATION_USER>;
    GRANT CREATE SEQUENCE TO <MIGRATION_USER>;
    GRANT EXECUTE ON DBMS_LOGMNR TO <MIGRATION_USER>;
    GRANT EXECUTE ON DBMS_LOGMNR_D TO <MIGRATION_USER>;
    GRANT SELECT ON V_$LOGMNR_LOGS TO <MIGRATION_USER>;
    GRANT SELECT ON V_$LOGMNR_CONTENTS TO <MIGRATION_USER>;
    GRANT SELECT ON V_$LOGFILE TO <MIGRATION_USER>;
    GRANT SELECT ON V_$ARCHIVED_LOG TO <MIGRATION_USER>;
    GRANT SELECT ON V_$ARCHIVE_DEST_STATUS TO <MIGRATION_USER>;
    GRANT SELECT ON V_$TRANSACTION TO <MIGRATION_USER>;
```

### Step5: Grant SELECT on source tables

First Log in to oracle **PDB** as sysdba:

```shell
sqlplus <DBA_USER>/<PASSWD>@<HOST>:<PORT>/<PDB_NAME> as sysdba
```

Where:

- `<DBA_USER>` is an oracle user that can log in to the cdb as sysdba.
- `<PASSWD>` is the password of dba_user.
- `<HOST>` is the oracle db hostname.
- `<PORT>` is the oracle db port.
- `<PDB_NAME>` is the oracle PDB name

For each table you want to migrate under this PDB, grant its select permission to the MIGRATION_USER you just created:

```sql
GRANT SELECT ON <SCHEMA_NAME>.<TABLE_NAME> TO <MIGRATION_USER>
```

Where:

- `<SCHEMA_NAME>` is the schema to which your table belongs.
- `<TABLE_NAME>` is the name of a table you want to migrate.
- `<MIGRATION_USER>` is the name of the common user you created in previous step.

!!!note
   In oracle, a schema is identical to a user, so remember to set schema name correctly when running the above sql, otherwise data migration might encounter errors.

### (Optional)Step6: Ensure adequate redo log space is available for better performance

The migration process involves two phases. The first is a consistent snapshot. The second is continuous streaming of database changes. This stream of database changes is powered by LogMiner and the Oracle DB redo logs.

Database changes have a limited lifetime on the redo logs before the change is no longer present in the log history. This lifetime depends on the size of the redo logs, the number of redo logs, and the change throughput to the database. Also, undersized logs cause frequent log switching and affect migration performance.

To examine the state of the database redo logs, log in to ***CDB*** first:

```shell
sqlplus <DBA_USER>/<PASSWD>@<HOST>:<PORT>/<CDB_NAME> as sysdba
```

Then run following sqls:

```sql
SELECT GROUP#, TYPE, MEMBER FROM V_$LOGFILE;

    GROUP# TYPE    MEMBER
---------- ------- --------------------------------------------------
         1 ONLINE  /opt/oracle/oradata/ORCLCDB/redo03.log
         2 ONLINE  /opt/oracle/oradata/ORCLCDB/redo01.log
         3 ONLINE  /opt/oracle/oradata/ORCLCDB/redo04.log

SELECT GROUP#, ARCHIVED, BYTES/1024/1024 MB, STATUS FROM V_$LOG;

    GROUP# ARC  MB STATUS
---------- --- --- ----------------
         1 YES 2000 INACTIVE
         3 YES 2000 INACTIVE
         3 NO  2000 CURRENT
```

This example uses three log groups of size 2000MB. Each group has one file member. This might be too
small for many production databases. You can safely adjust the redo logs with synchronous commands such as the following:

```sql
  ALTER DATABASE ADD LOGFILE GROUP 4 ('/opt/oracle/oradata/ORCLCDB/redo04.log') SIZE 8G;
  ALTER DATABASE ADD LOGFILE GROUP 5 ('/opt/oracle/oradata/ORCLCDB/redo05.log') SIZE 8G;
  ALTER DATABASE ADD LOGFILE GROUP 6 ('/opt/oracle/oradata/ORCLCDB/redo06.log') SIZE 8G;
  ALTER DATABASE ADD LOGFILE GROUP 7 ('/opt/oracle/oradata/ORCLCDB/redo07.log') SIZE 8G;
  ALTER SYSTEM ARCHIVE LOG CURRENT;
  ALTER SYSTEM CHECKPOINT;
  ALTER SYSTEM ARCHIVE LOG CURRENT;
  ALTER SYSTEM CHECKPOINT;
  ALTER SYSTEM ARCHIVE LOG CURRENT;
  ALTER SYSTEM CHECKPOINT;
  ALTER DATABASE DROP LOGFILE GROUP 1;
  ALTER DATABASE DROP LOGFILE GROUP 2;
  ALTER DATABASE DROP LOGFILE GROUP 3;
```

These commands result in four new 8GB log groups. Each group has a single log file.

Consult your DBA for appropriate production sizing.

### Step7: Validate configuration

The EDB DMS Reader installation (packaged as `cdcreader`) and DMS Agent installation (packaged as `cdcagent`) come with a helper script that validates the Oracle configuration and helps you identify any issues. After you configure the database, we recommend running the script to ensure all checks pass.

Run the script without arguments to print the usage:

```shell
# run this command if you're using cdcagent
/opt/cdcagent/reader/oracleConfigValidation.sh
# run this command if you're using cdcreader:
/opt/cdcreader/oracleConfigValidation.sh
```

## SSL configuration

Ensure you configure your source database server to accept SSL connections to allow the EDB DMS Reader or DMS Agent to connect to it. You must create a server certificate and a server private key, for example, with OpenSSL, to enable this configuration.

## More information

Your database is ready for CDC migration.

For more information, see the [Debezium Oracle Connector](https://debezium.io/documentation/reference/2.2/index.html) documentation.
